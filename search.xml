<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>博客内容归档和英文博客</title>
    <url>/202111/%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9%E5%BD%92%E6%A1%A3%E5%92%8C%E8%8B%B1%E6%96%87%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<div class="tag-plugin note" ><div class="body"><p>从2019年开始尝试搭建自己的博客，到现在已经本科毕业。这三年的时间虽然没有坚持更新博客，但是一直在坚持记录。无论是理论知识的学习、Debug的记录，还是读书健身笔记和感慨万千时的随笔，他们都散落在各种在线笔记软件和手机的备忘录中。</p><p>随着时间的推移，我对博客的认识也发生了很多变化。“记录”对我来说仍然具有非常大的意义，但是“博客”最重要的价值不应该是“记录”，而是“分享”——传递有价值的信息。我把平时的日常生活和学习经历记录在各种笔记中，过一段时间再去回顾和整理，选取其中有价值的东西去分享。</p><p>过去的一年再次参加了美赛，加入了几个和区块链有关的项目，也完成了不少专利和论文。更多的时间忙于运用知识，以需求为导向迫使自己进行广泛而不深刻的学习。对我来说真正有价值的输入变少了，输出和表达的欲望也降低了很多。</p><p>   我在原先的博客域名之下又建立了一个英文博客<a href="https://blog.crocodilezs.top/eysblog_en/">BLOG-EN</a>，旨在整理自己过去一年经历的各种项目。同时也将原博客中的内容进行整理归档，便于自己和访客的查阅。</p></div></div>
<span id="more"></span>
<h2 id="课程设计与实验"><a href="#课程设计与实验" class="headerlink" title="课程设计与实验"></a>课程设计与实验</h2><p><a href="/201911/Linux开发环境及应用作业%2020191031/" itemprop="url"> Linux文本处理作业 </a> &emsp;&emsp;<br><a href="/categories/操作系统/" itemprop="url"> 《30天自制操作系统》实验合辑 </a> &emsp;&emsp;<br><a href="/201909/周宇洋_「学生宿舍管理系统」实验报告/" itemprop="url"> 学生宿舍管理系统Python开发 </a> &emsp;&emsp;<br><a href="/201911/KNN与Naive_Bayes代码实现/" itemprop="url"> KNN和朴素贝叶斯的代码实现 </a> &emsp;&emsp;<br><a href="/201911/Price_Suggestion_Chanllenge/" itemprop="url"> 商品价格预测挑战 </a> &emsp;&emsp;<br><a href="/201911/Fisher算法&SVM&K-Means及其优化/" itemprop="url"> Fisher算法 &amp; SVM &amp; K-Means的实现和优化 </a> &emsp;&emsp;<br><a href="/201910/FINDS算法和ID3算法/" itemprop="url"> FINDS算法和ID3算法 </a> &emsp;&emsp;<br><a href="/201904/插入排序归并排序和快速排序/" itemprop="url"> 算法设计之排序 </a> &emsp;&emsp;<br><a href="/201904/循环赛赛程安排/" itemprop="url"> 算法设计之循环赛赛程安排 </a> &emsp;&emsp;</p>
<h2 id="展示和汇报"><a href="#展示和汇报" class="headerlink" title="展示和汇报"></a>展示和汇报</h2><p><a href="/201904/基于链接内容的社区发现（一）/" itemprop="url"> 基于链接内容的社区发现（一） </a> &emsp;&emsp;<br><a href="/201904/基于链接内容的社区发现（二）/" itemprop="url"> 基于链接内容的社区发现（二） </a> &emsp;&emsp;</p>
<h2 id="学习笔记"><a href="#学习笔记" class="headerlink" title="学习笔记"></a>学习笔记</h2><p><a href="/201908/「迁移学习简明手册」学习笔记（1）/" itemprop="url"> 《迁移学习简明手册》学习笔记 </a> &emsp;&emsp;<br><a href="/201909/实验室苦逼搬砖暑假生活纪实/" itemprop="url"> 用户对齐（实验室搬砖纪实） </a> &emsp;&emsp;</p>
<h2 id="读书笔记"><a href="#读书笔记" class="headerlink" title="读书笔记"></a>读书笔记</h2><p><a href="/202005/《苏东坡传》摘录/" itemprop="url"> 《苏东坡传》 </a> &emsp;&emsp;<br><a href="/202002/祭亡妻程氏文/" itemprop="url"> 《祭亡妻程氏文》 </a> &emsp;&emsp; </p>
]]></content>
  </entry>
  <entry>
    <title>[ICM 2021] Music Never Stops: Cracking the Secret of Musical Influence</title>
    <url>/202102/2021-02-10-2021ICM-Music/</url>
    <content><![CDATA[<p>We participated in ICM 2021 during Feb 5th - Feb 9th and finally honored <strong>Meritorious Winner(Top 7%)</strong>😆. Because we 3 people are all music enthusiasts, we choosed the problem D about data mining in music similarity and influence. We thought we could do better in this field. It turns out that we were right. Here is our thinking and solution to this problem.</p>
<h1 id="Topic-and-Datasets"><a href="#Topic-and-Datasets" class="headerlink" title="Topic and Datasets"></a>Topic and Datasets</h1><p>Here are <a href="https://www.mathmodels.org/Problems/2021/ICM-D/2021_ICM_Problem_D.pdf">the topic and the datasets</a>. You can also see them on <a href="https://www.mathmodels.org/Problems/2021/ICM-D/index.html">COMAP</a>.</p>
<p>In short, our team has been identified by an organization to develop a model that measures musical influence. This problem asks us to examine evolutionary and revolutionary trends of artists and genres. We has been given 4 data sets:</p>
<ol>
<li><code>influence_data.csv</code> represents musical influencers and followers, as reported by the artists themselves, as well as the opinions of industry experts. These data contains influencers and followers for 5,854 artists in the last 90 years.</li>
<li><code>full_music_data.csv</code> provides 16 variable entries, including musical features such as <code>danceability</code>, <code>tempo</code>, <code>loudness</code>, and <code>key</code>, along with <code>artist_name</code> and <code>artist_id</code> for each of 98,340 songs. These data are used to create two summary data sets, including: mean values by artist - <code>data_by_artist.csv</code>, means across years <code>data_by_year.csv</code>.</li>
</ol>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><blockquote>
<p>Music has been a necessary part of human life and history since we human have consciousness. At the same time of human evolution, music is constantly changing new forms and contents. Music itself doesn’t evolve, and there’s no doubt that it’s done by a group of people called “artists”. It’s a common sense that a new form of music occurs under the action of many factors, such as artists’ innate creativity, current social or political events, access to new instruments or tools, or other personal experiences.</p>
</blockquote>
<center><img src="/eysblog_en/imgsource/icm2021-figure-1.png" alt="The architecture of our model" width="80%"/>
<p><font size=3 color="black">Figure 1: The architecture of our model</font></p></center>

<p>Based on some basic musical attributes, our aim in this report is to build a model to quantify musical evolution. We are expected to provide a measurement mechanism to observe how the previous music affects the later music and musicians. So two major models are established to finish that job.</p>
<p>For the model 1, we analyzed <strong>the relationships</strong> between genre, artist and music from the perspective of influence and similarity. We use the <strong>BA model</strong> to explained the influence network, which connects the influencers and followers. Based on the influence relationships between artists, we use <strong>the directed edge of the model</strong> to construct an influence-index. And then based on this index, we use <strong>the improved Louvain algorithm</strong> to in <strong>community partition</strong> to get The partition based on influence.</p>
<p>On the other hand, from the perspective of the similarity between artists, we use <strong>Pearson correlation coefficient</strong> to remove the redundant of music attributes, and construct the measure index of similarity. Based on this index, we use <strong>the improved K-Means algorithm</strong> in community partition, and finally obtain The partition based on similarity.</p>
<p>We creatively proposed to <strong>combine these two networks</strong>, and <strong>the NMI index</strong> is used to analyze the relationship between similarity and influence. Finally, we prove that the influencers actually affect the music created by the followers.</p>
<p>For the model 2, we took <strong>time</strong> into consideration. In order to analyze the musical evolution process, We use <strong>ARIMA model</strong> to create an ideal evolution curve. We compare the real curve with the ideal evolution curve to find how the social, culture and technology affect the music. We give an example of electronic music. Symbols and Definitions show in the Table 1.</p>
<center><img src="/eysblog_en/imgsource/icm2021-table-1.png" alt="" width="100%" /></center>

<h1 id="🌟Model-1🌟-BA-Model-and-Optimized-Louvain-KMeans-Algorithm"><a href="#🌟Model-1🌟-BA-Model-and-Optimized-Louvain-KMeans-Algorithm" class="headerlink" title="🌟Model 1🌟: BA Model and Optimized Louvain-KMeans Algorithm"></a><strong>🌟Model 1🌟</strong>: BA Model and Optimized Louvain-KMeans Algorithm</h1><p>Model 1 we analyze social networks from the perspective of influence and similarity, and then analyze the influence and similarity relationship among genres, artists and music.</p>
<p>In this model, we use directed graph to construct influence network and BA model to explain the influence propagation relationship in the network. First, we analyzed the influence relationship between artists. We propose the influence index by using the indegree and outdegree parameters inthe directed graph, and use the improved Louvain algorithm in community partition to get the “The partition based on influence”.</p>
<p>Then we analyze the similarity among the music, we use <strong>Pearson correlation coefficient</strong> to delete redundant attributes, and propose the measure of “similarity”. Through similarity measurement, the improved KMeans algorithm is used in community partition to obtain “The partition based on “similarity”.</p>
<p>After that, we innovatively combine the above two networks, and perfectly explain the relationship between music influence and similarity by using NMI parameters. We call this innovative method Optimized Louvain KMeans Algorithm.</p>
<h2 id="Analysis-of-Music-Influence"><a href="#Analysis-of-Music-Influence" class="headerlink" title="Analysis of Music Influence"></a>Analysis of Music Influence</h2><h3 id="The-influence-of-network-BA-model"><a href="#The-influence-of-network-BA-model" class="headerlink" title="The influence of network (BA model)"></a>The influence of network (BA model)</h3><p>In Model 1 we analyze social networks from the perspective of influence and similarity, and then analyze the influence and similarity relationship between genres, artists and music.</p>
<p><code>Influence_data.csv</code> includes 5854 artists in the past 90 years according to the artists themselves and industry experts. <strong>We construct 42770 influence relationships among the 5854 artists through the data set, and the directed edges in the network point from the follower to the influencer</strong>. In the Figure3.1.1, artists of different genres are represented by different colors. There are <strong>19 genres of music (except unknown) in the dataset</strong>.</p>
<p>Through the Figure2, we can roughly know the influence relationship between different genres. For example, we can easily see that Pop/Rock music has influence on all other genres, which is also determined by the characteristics of Pop/Rock music itself. Based on this network, the later content of this paper will further analyze the relationship between the influence of music characteristics and social network, age, policy and so on.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-2.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 2: Directed network of musical influence</font></p></center>

<p>In network theory, scale-free network is a kind of complex network. Its typical feature is that most nodes in the network are only connected with a few nodes, and a few nodes are connected with a lot of nodes. In reality, many networks have scale-free characteristics, such as Internet, financial system network, social network and so on.</p>
<p>According to the influence direct graph, we guess that the influence network is a scale-free network, and then we will verify it by BA model.This model is based on two assumptions.</p>
<ul>
<li>Growth model: many real networks are constantly expanding and growing, such as the birth of new web pages in the Internet, the publication of new papers and so on. Obviously, the musical influence network is also expanding through the increasing influence relationship.</li>
<li>Priority connection mode: when new nodes join, they tend to connect with nodes with more connections. For example, new web pages usually have connections to well-known Web sites, and new papers tend to cite well-known literatures that have been widely cited, etc. In reality, the same is true of influence. New musicians are more likely to be influenced by<br>influential influencers.</li>
</ul>
<p>Based on the above two hypotheses, we randomly selected 500 followers from the data set, removed them from the established social network, and then connected them back to the influence network by building a scale-free network with BA model.</p>
<p>There are \(N<em>a\) nodes in the original network, we will add a new artist \(a_i\) to the network. When \(a_i\) is a new node, \(m\) edges are connected from the new node to the original node, and the connection mode is the node with priority given to the high heights. For the original artist \(a_j\) in the network,the number of degree in the original network is recorded as \(idg</em>{a<em>j}\). Then the probability \(p</em>{a_i,a_j}\) of the new node can be canculate as follows:</p>
<script type="math/tex; mode=display">
P_{a_i,a_j}=\frac{idg_{a_j}}{\sum_{K \in artist_{id}}idg_{a_k}}
\tag{1}</script><p>By choosing the appropriate probability threshold, we add these 500 nodes back to the influence network, and create related directed edges. According to the real influence network, we calculate the connection accuracy of each new node(\(a_i\)) and the original node. The accuracy of the connection betweennew node(\(a_i\)) and the original node is 81.74%. This shows that the influence network basically conforms to the BA model.</p>
<p>According to the properties of BA model, we can know that the distribution of the number of the followers of artists can be approximately described by a power function with a power exponent of 3. For artist \(a_i\), the distribution function of the number of people affected is:</p>
<script type="math/tex; mode=display">
p(idg_{a_i}) \propto 2idg^3_{a_i}
\tag{2}</script><p>The distribution function can help us better explain the spread of influence, and can also be used to predict which artists are more attractive to the new artists.</p>
<h3 id="Analysis-of-music-influence-from-the-perspective-of-genre"><a href="#Analysis-of-music-influence-from-the-perspective-of-genre" class="headerlink" title="Analysis of music influence from the perspective of genre"></a>Analysis of music influence from the perspective of genre</h3><p>To quantify the influence of music genres, based on the previous social network, we counted the number of directed edges between genres as the influence parameter, and built the heat map between genres. In order to show the heat map better, we take logarithm of the number of directed edges.</p>
<p>As can be seen from the below Figure 3, the influence of all artists is mainly reflected in the genre itself. Jazz has an impact on all other genres of music. Pop / Rock, R&amp;B and Vocal also have a great impact on other fields.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-3.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 3: Heat map between genres</font></p></center>

<h3 id="Influence-index"><a href="#Influence-index" class="headerlink" title="Influence-index"></a>Influence-index</h3><p>In order to evaluate the music influence of artists better, we introduce the following evaluation measures. On the basis of the number of followers, we construct the comprehensive measure of influence index, which combines the influence of artists in and out of their genres to give an objective evaluation of the influence of artists.</p>
<script type="math/tex; mode=display">
Influence-index_i=F_{in_i}+logG_i * F_{out_i}
\tag{3}</script><p>We choose pop / rock artists as a sub network to investigate the influence of all artists. According to the influence index we set, we find out the top ten artists of this genre.The music genres and influence-index influenced by the ten artists are shown in the following table.</p>
<center><img src="/eysblog_en/imgsource/icm2021-table-2.png" alt="" width="100%"/></center>

<p>It is easy to check the influencer and followers of each artist in the network we built. Taking The Beatles as an example, the influence network chart of its music is shown in the Figure 4.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-4.png" alt="" width="90%"/>
<p><font size=3 color="black">Figure 4: The influence network chart of The Beatles</font></p></center>

<h2 id="Analysis-of-Music-Similarity"><a href="#Analysis-of-Music-Similarity" class="headerlink" title="Analysis of Music Similarity"></a>Analysis of Music Similarity</h2><h3 id="The-similarity-index"><a href="#The-similarity-index" class="headerlink" title="The similarity index"></a>The similarity index</h3><p>In order to establish the music similarity measurement model, we can compare the similarity degree of each parameter between different music. In this question, there are 7 characteristics of the music and 5 types of vocals, a total of 12 parameters to reflect the characteristics of music (<code>danceability</code>, <code>energy</code>, <code>valence</code>, <code>tempo</code>, <code>loudness</code>, <code>mode</code>, <code>key</code>, <code>acousticenss</code>, <code>instrumentalness</code>, <code>livenss</code>, <code>speechiness</code>, <code>explicit</code>).</p>
<p>By calculating Pearson correlation coefficients between 12 music parameters, the correlation co-efficient matrix is obtained, and the redundant parameters with high correlation can be eliminated.</p>
<p>Energy and valence data in <code>full-music-data.csv</code> were taken as an example to calculate the correlation coefficient, and the data could be expressed as: \( e:\{e<em>{m_1}, e</em>{m<em>2}, e</em>{m<em>3}, …, e</em>{m<em>{N_n}}\} \), \( v:\{v</em>{m<em>1}, v</em>{m<em>2}, v</em>{m<em>3},…, v</em>{m_{N_n}}\} \).</p>
<script type="math/tex; mode=display">
\begin{align}
&Mean Value: E(e) = \frac{\sum_{i=1}^ne_{m_i}}{n}, E(v)=\frac{\sum_{i=1}^nv_{m_i}}{n}, \\
&Covariance: Cov(e, v) = \frac{\sum_{i=1}^n(e_{m_i}-E(e))(v_{m_i}-E(v))}{n}, \\
&Standard Deviation: \delta_e=\sqrt{\frac{\sum_{i=1}^n(e_{m_i}-E(e))^2}{n}}, \delta_v=\sqrt{\frac{\sum_{i=1}^n(v_{m_i}-E(v))^2}{n}}, \\
&Pearson = \rho_{ev} = \frac{Cov(e, v)}{\delta_e\delta_v}=\frac{\frac{\sum_{i=1}^n(e_{m_i}-E(e))(V_{m_i}-E(v))}{\delta_e\delta_v}}{n}
\end{align}
\tag{4}</script><p>Using the data in full-music-data.csv, the correlation coefficient between each index can be calculated. Its correlation coefficient matrix is shown in Figure 5.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-5.png" alt="" width="100%"/>
<p><font size=3 color="black">Figure 5: The correlation coefficient between each index</font></p></center>

<p>In order to reduce the influence of the correlation between indicators, indicators in each group with the absolute value of correlation coefficient greater than 0.3 were selected. Then, one of the two indicators of each group was selected, and the index used to evaluate music similarity was as follows:<code>danceability</code>, <code>energy</code>, <code>mode</code>, <code>key</code>, <code>liveness</code>, <code>speechiness</code> and <code>explicit</code>.</p>
<p>The values of <code>mode</code> and <code>explict</code> are Boolean values, so they are excluded from the music similarity model. The similarity of songs was evaluated by comparing the degree of differentiation of the remaining five indicators between different songs. We defined a numerical quantity called similarity to indicate the degree of difference between songs, and the higher the similarity value is, the more similar the songs are.</p>
<p>For example, calculate the similarity of song j and song k in full-musci-data file, and its data can be expressed as: \(M<em>j{d</em>{m<em>j}, e</em>{m<em>j}, l</em>{m<em>j}, s</em>{m<em>j}, k</em>{m<em>j}}, M_k{d</em>{m<em>k}, e</em>{m<em>k}, l</em>{m<em>k}, s</em>{m<em>k}, k</em>{m_k}}\).<br>The similarity of the two songs is defined as:</p>
<script type="math/tex; mode=display">
def: Similarity = \frac{1}{\sqrt{(d_{m_j}-d_{m_k})^2+(e_{m_j}-e_{m_K})^2+...+(k_{m_j}-k_{m_k})^2}}
\tag{5}</script><h3 id="Similarity-analysis-between-music-genres"><a href="#Similarity-analysis-between-music-genres" class="headerlink" title="Similarity analysis between music genres"></a>Similarity analysis between music genres</h3><p>We selected 12 music genres in the data set to analyze their music similarity. For each genre, we selected 50 artists with the highest influence index, and calculated the music style similarity between these 500 artists. Then the music similarity between different genres is calculated according to the same genre and different genres. The results are shown in the Figure 6 below.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-6.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 6: Music similarity between different genres</font></p></center>

<p>The darker the color in the figure 6 is, the higher the similarity between genres. For example, the similarity between Blues and Pop/Rock,jazz and Country is very high, while the similarity between R&amp;B and Vocal is very low. Similar conclusions can be drawn directly from the figure.</p>
<p>In order to better distinguish the characteristics of music genres, we use radar chart to intuitively show the prominent characteristics of each genre.The musical characteristics of these 12 genres are shown in the Figure 7.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-7.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 7: Music characteristics</font></p></center>

<h3 id="The-analysis-of-the-factors-that-influence-the-spread-of-music"><a href="#The-analysis-of-the-factors-that-influence-the-spread-of-music" class="headerlink" title="The analysis of the factors that influence the spread of music"></a>The analysis of the factors that influence the spread of music</h3><p>Using the data, the correlation coefficients between 12 indexes and the popularity of music are calculated.</p>
<p>In this question, we assume that if the absolute value of the correlation coefficient is greater than 0.3, we can think that there is a strong correlation between the data. When the absolute value of the correlation coefficient is between 0.1 and 0.3, we can think that there is a correlation between the data.</p>
<p>The characteristics of music communication can be reflected from the popularity of music, so from the correlation coefficient, it can be concluded that the communicability of music is positively correlated with the dancebility, energy, loudness and explicit, and negatively correlated with the instrumental, acoustic and other indicators, and is most affected by the dancebility, loudness and acoustic.</p>
<h2 id="Optimized-Louvain-KMeans-Algorithm-and-NMI"><a href="#Optimized-Louvain-KMeans-Algorithm-and-NMI" class="headerlink" title="Optimized Louvain-KMeans Algorithm and NMI"></a>Optimized Louvain-KMeans Algorithm and NMI</h2><p>Through the heat map of influence and similarity, we can qualitatively observe the relationship between music influence and similarity. </p>
<p>Next, we innovatively propose the optimized louvain-kmeans algorithm to quantitatively analyze the relationship between music influence and similarity with the help of NMI.The architecture of this model is shown in the figure 8.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-8.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 8: Flow chart of the model</font></p></center>

<h3 id="The-community-partition-based-on-influence"><a href="#The-community-partition-based-on-influence" class="headerlink" title="The community partition based on influence"></a>The community partition based on influence</h3><p>The Louvain method for community detection is a method to extract communities from large networks created by Blondel et al. from the University of Louvain (the source of this method’s name). The method is a greedy optimization method that appears to run in time \(O(n · log_2n)\) if \(n\) is the number of nodes in the network.We will use the Louvain algorithm to divide the influence network.</p>
<p>Before using Louvain, we need to introduce the concept of modularity. We use the Louvain algorithm to make as many edges as possible in the community and as few as possible between the communities. The measure of this index is modularity. </p>
<p>The number of nodes in the network is \(N<em>a\), the number of edges is \(N</em>{infl}\), and the indegree of node \(a<em>i\) is \(idg</em>{a<em>i}\). The adjacency matrix of the network is expressed as A, \(A</em>{a_i,a_j}=0\) means there is no edge between \(a_i\) and \(a_j\). \(AVW = 1\) means there are edges between the two nodes. </p>
<p>Define variable s, and \(s<em>{a_ia_j}\) means that \(a_i\) and \(a_j\) belong to the same partition. \(s</em>{a<em>ia_j}=-1\) means that the two nodes belong to different partition. Then we can use \(\delta</em>{a<em>ia_j} = 1/2(s</em>{a_ia_j} + 1) \) to verify if \(a_i\) and \(a_j\) belong to the same partition in a quantitive way. If the result equals one, we can say the two nodes belong to the same partition. If not, the result equals zaro. Then the probability expectation of modularity can be expressed as:</p>
<script type="math/tex; mode=display">
\overline{Q} = 1/2\frac{\sum_{a_ia_j}A_{a_ia_j}}{N_{infl}} \delta_{a_ia_j}
\tag{6}</script><p>Modularity can be finally expressed as:</p>
<script type="math/tex; mode=display">
Q=\frac{1}{2m}\sum_{a_ia_j}(A_{a_ia_j}-\frac{idg_{a_i}idg_{a_j}}{2N_{infl}})\delta_{a_ia_j}
\tag{7}</script><p>Through greedy algorithm, the modularity is continuously optimized to achieve “community partition based on influence”,The schematic diagram of the improved Louvain algorithm is shown in the Figure 9.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-9.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 9: Optimized louvain algorithm</font></p></center>

<p>In the process of optimization, we select the artist with the biggest influence factor among 19 music genres, and prevent them from being divided into a module, so as to improve the efficiency of community partition. The community partition results are shown in the Figure 10.(different colors represent different communities)</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-10.png" alt="" width="50%"/>
<p><font size=3 color="black">Figure 10: The partition based on influence</font></p></center>

<h3 id="The-communiy-partition-based-on-similarity"><a href="#The-communiy-partition-based-on-similarity" class="headerlink" title="The communiy partition based on similarity"></a>The communiy partition based on similarity</h3><p>We use KMeans to divide all the artist nodes into communities, so that the music similarity within the community is higher, and the music similarity between the communities is lower. Similar to the Louvain algorithm, we use the artist with the largest influence factor in the same 19 music genres, and prevent them from being divided into a module, so as to improve the efficiency of community partition.The community partition results are shown in the Figure 11(different colors represent different communities)</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-11.png" alt="" width="50%"/>
<p><font size=3 color="black">Figure 11: The partition based on similarity</font></p></center>

<h3 id="The-relationship-between-influence-and-similarity-was-analyzed-through-NMI"><a href="#The-relationship-between-influence-and-similarity-was-analyzed-through-NMI" class="headerlink" title="The relationship between influence and similarity was analyzed through NMI"></a>The relationship between influence and similarity was analyzed through NMI</h3><p>NMI is often used to detect the difference between the results of the partition and the true partition of the network and calculate the correct rate. Here we use the NMI index to evaluate the similarity between the influence-based and similarity-based social partitions.The higher the NMI index is, the more similar the two partitions are, which indicates that the influencers actually affect the music created by the followers.</p>
<p>In our model,\(P<em>{SC}\) stands for “similarity-based community partition” and \(P</em>{IC}\) for “influence-based community partition”, and the NMI index of these two can be expressed by the following formula:</p>
<script type="math/tex; mode=display">
\mathrm{NMI}=\frac{-2 \sum_{i=1}^{C_{P_{I C}}} \sum_{j=1}^{C_{P_{S C}}} C_{i j} \cdot \log \left(\frac{C_{i j} \cdot N}{C_{i} \cdot C_{j}}\right)}{\sum_{i=1}^{C_{P_{I C}}} C_{i} \cdot \log \left(\frac{C_{i}}{N}\right)+\sum_{j=1}^{C_{P S C}} C_{i j} \cdot \log \left(\frac{C_{j}}{N}\right)}
\tag{8}</script><p>where N is the number of nodes, C is a confusion matrix, the element \(C<em>{ij}\) in the matrix indicates the number that the nodes belonging to the community i in the SC partition also belong to communities j in the IC partition. \(P</em>{IC}(P_{SC})\) is the number of communities in IC(SC) partition, \(C_i(C_j)\) is the sum of elements in matrix C. The grater the value of NMI,the more similarity between SC and IC partition, when the NMI value is 1, it indicates that SC and IC are the same partition of the network.</p>
<p>Finally, the NMI value we calculated is 0.6237, indicating that the influencers actually affect the music created by the followers.</p>
<h1 id="🌟Model-2🌟-Time-Series-Analysis"><a href="#🌟Model-2🌟-Time-Series-Analysis" class="headerlink" title="🌟Model 2🌟: Time-Series Analysis"></a><strong>🌟Model 2🌟</strong>: Time-Series Analysis</h1><p>It is a normal process that music genres emerge, evolve, and disappear. Our team member managed to observe big turns over time, and identify the key revolutionary artist of each genre. Whenever a music genre is about to leap, there will always be clues to change. As for a music genre, it is obvious that the explosive growth in the number of new artists and new songs indicates the prevalence and significant leap of the genre. So our team counted the number of artists and songs in the history of ten major music genres, and found the time of change in the visual image. According to the influence network, the most influential artists in these years were identified as the pioneers of the music revolution, that is, the so-called music revolutionaries. The details are shown below.</p>
<h2 id="The-evolution-of-genres-over-time"><a href="#The-evolution-of-genres-over-time" class="headerlink" title="The evolution of genres over time"></a>The evolution of genres over time</h2><p>We have studied the evolution of ten genres over time. In the text, we choose Jazz, R&amp;B and Country as three genres to illustrate their evolution over time.</p>
<h3 id="New-Artists"><a href="#New-Artists" class="headerlink" title="New Artists"></a>New Artists</h3><p>First of all, look at the number of artists added from the genre.According to the data given, the statistical changes of the number of people in the three schools from 1930 to 2010 are shown in Figure 12.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-12.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 12: The number of artists in different musical genres</font></p></center>

<p>It can be seen from the figure that jazz, R&amp;B and country all rose in the United States in the 1930s. Jazz flourished from the 1930s to the 1950s, and the number of new artists reached 102 in the 1950s. After the 1950s, jazz began to decline rapidly, and the number continued to decline. By the 2010s, there was no jazz New artists are included in the statistics.</p>
<p>R&amp;B music developed slowly from 1930’s to 1940’s, and the number of artists increased slowly. However, as time went into 1940’s, R&amp;B music genres developed rapidly, and the number of new artists increased from 17 in 1940 to 104 in 1950 in just 10 years. When R&amp;B developed into 1950s, the number of artists still maintained a steady growth momentum, and reached the peak in 1960 From the 1960s to the 21st century, R&amp;B declined as a whole. The number of new artists has been decreasing except for the growth in the 1980s. In 2010, the number of new artists fell back to the level of the early 1940s.</p>
<p>The number of artists in the country music genre increased slowly, showing a fluctuating upward trend from 1930 to 1990. The number of new artists reached the peak of 74 in 1990. However, compared with the peak of jazz and R&amp; B genre, the number of artists was still small. After 90 years, the country music genre began to decline, and the number of new artists fell back to the<br>beginning of the genre The number of musicians.</p>
<h3 id="The-release-of-songs"><a href="#The-release-of-songs" class="headerlink" title="The release of songs"></a>The release of songs</h3><p>In terms of the number of songs released, in the data used, we exclude the songs jointly released by multiple artists, and all the songs included in the calculation are published by artists alone, which can avoid that a song may be released by artists of multiple genres.</p>
<p>According to the given data, the changes of the number of songs released by the three genres from 1920 to 2020 are counted, as shown in Figure 13.</p>
<p>Compared with the broken line trend in Figure 1 and Figure 2, we can conclude that the increase of new generation artists will significantly affect the number of songs released, and this effect is often ahead of the increase in the number of songs released, and there is a cumulative effect. Taking jazz music genre as an example, the number of new generation artists in the genre was at a high growth level from 1930 to 1960. In 1950, the number of new generation artists reached its peak. During this period, the genre accumulated a large number of excellent artists. These artists matured in the 1950s and 1960s, and a large number of music works emerged. During this period, the music circulation of jazz music was much higher than that of any other period, reaching the peak of 486 songs in 1957. The same is true of R&amp;B music. In 1960, the number of new generation artists<br>reached its peak, and then in 1972, the number of R&amp;B music released reached its peak of 339.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-13.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 13: Total number of songs released each year by different genre</font></p></center>

<h3 id="Genre-popularity"><a href="#Genre-popularity" class="headerlink" title="Genre popularity"></a>Genre popularity</h3><p>From the perspective of popularity, we first give the definition of genre popularity. Gene popularity: based on the active-Start, the arithmetic mean value of the popularity of all artists of the same genre is defined as genre popularity.</p>
<p>For example: jazz music genre, active- There are 45 artists who started in 1930, according to the data table-by-artist.csv We can know the popularity value of artists who meet the conditions, and we can get the popularity of jazz music in 1930 by taking the arithmetic average of these values.</p>
<p>According to the above definition, we can get the change curve of the three genres from 1930 to<br>2010, as shown in Figure 14.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-14.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 14: Grnre popularity</font></p></center>

<p>From the trend of the line chart, the value of Genre popularity is increasing over time. The reason for the decline of jazz curve from 2000 to 2010 is the lack of 2010 active-Start’s Jazz artist data, so its value was zero in 2010. Because the popularity of songs is calculated by algorithm, and the result largely depends on the total number of tracks played and the time of the most recent track played. Generally speaking, as time goes on, the frequency of playing the track will increase significantly, and it has a higher popularity. Therefore, the popularity of genres will increase with<br>the passage of time.</p>
<h2 id="The-influence-of-external-factors-on-the-development-trend-of-genres"><a href="#The-influence-of-external-factors-on-the-development-trend-of-genres" class="headerlink" title="The influence of external factors on the development trend of genres"></a>The influence of external factors on the development trend of genres</h2><p>We divide the ideal evolution of music genres into four stages: initial stage, development stage, booming stage and recession stage. We use the number of songs of a genre in a certain period to express the prosperity of the genre in that period. Based on the number curve of 10 genres, we use ARIMA model to fit an ideal evolution curve of genres.</p>
<p>Without the influence of social environment, scientific and technological development and other factors, genres will evolve according to the ideal curve.</p>
<p>ARIMA model(Auto regressive Integrated Moving Average model ) is one of the time series prediction methods. In ARIMA (P, D, q), AR is “autoregressive”, P is the number of autoregressive terms; Ma is “moving average”, q is the number of moving average terms, and D is the difference order of making it a stationary sequence.</p>
<p>The ideal evolution curve of genres fitted by this model is shown in the Figure 15 (the light blue area is the error range). Compared with the ideal evolution curve and the actual evolution curve of music genre, when there is a significant difference between the two in a certain period, it shows that there are social and cultural factors that have a great impact on the genre at this time.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-15.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 15: The ideal evolution curve of genres</font></p></center>

<p>Taking electronic music as an example, the evolution curve of electronic music and the evolution curve of the genre in the ideal state are shown in the Figure 16.</p>
<center><img src="/eysblog_en/imgsource/icm2021-figure-16.png" alt="" width="60%"/>
<p><font size=3 color="black">Figure 16: The evolution curve of electronic</font></p></center>

<p>In fact,following the emergence of raving, pirate radios, and an upsurge of interest in club culture. Electronic music achieved widespread mainstream popularity in Europe. Meanwhile, MIDI devices, which has been the musical instrument industry standard interface since the 1980s through to the present day, became commercially available in 1980s.These cultural and technological factors have promoted the rapid development of electronic music.</p>
<h1 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h1><p>To understand and measure the influence of previously poducted music on new music and musical artists, we proposed a series of novel models to address the sub-issues from creating the influence network based on the similarity between artists. The proposed model achieves high accuracy and robustness.</p>
<ul>
<li>We create the directed network based on music influence and use BAmodel to explain how the influence network expend. Thenwe propose Influence-Index to analyze the influence between genres and artists. We select the most 10 influential artists and show their influence-index.</li>
<li>In order to analyze the similarity between genres, artists and music, we use correlation analysis to remove redundant attributes. We finally select 7 attributes which actually infect the similarity. They are danceability, energy, key, liveness, speechiness, mode and explicit. Based on these attributes, we propes similirity index.</li>
<li>To find the relationship between the music similarity and the influence, we propose a Optimized LOUVAIN-KMeans Algorithm and use it to community partition. By participating artists into different community through Louvain algorithm and KMeans algorithm, we can obtain 2 different partition. Then we use NMI to estimate the similarity between these 2 partions. Finally we get the conclusion that influencers actually affect the music created by followers.</li>
<li>We analyze the influence processes of musical evolution that occoured over time. We use ARIMA model to create an ideal evolution curve. By comparing with the ideal evolution curve, we can find how the social, culture and technology affect the music. We give an example about electronic music.</li>
</ul>
<h1 id="Strength-and-weaknesses"><a href="#Strength-and-weaknesses" class="headerlink" title="Strength and weaknesses"></a>Strength and weaknesses</h1><h2 id="Strengths"><a href="#Strengths" class="headerlink" title="Strengths"></a>Strengths</h2><p>-We creatively proposed Optimized LOUVAIN-KMeans Algorithm and use the partition to explain the relationship between the influence and music similarity. The community network is as a bridge between them, and the model can reflect the relationship effectively.</p>
<ul>
<li>We proposse Influence-Index to estimate the influence of the artists objectively. It’s not accuracy to use only the number of followers or the number of music.</li>
<li>When analyzing the similarity between music and artists, our model is simple and convenient. Among the 12 music attributes given in the original data set, we remove the redundant attributes through correlation analysis, so that our model can calculate the similarity more efficiently and maintain a higher accuracy.</li>
<li>We creatively use ARIMA model to generate an ideal evolution curce of the genre. It make our model more robust, and can be used in many other situation. The ideal evolution curve reveal the process of the evolution in these genres.</li>
</ul>
<h2 id="Weakness"><a href="#Weakness" class="headerlink" title="Weakness"></a>Weakness</h2><ul>
<li>We don’t consider the influence between genres when we construct the ideal evolution curve. And new genres will appear at any time, so the curve may not that accuracy.</li>
<li>The interpretability of the influence and similarity model is not strong. We only find the relationship between similarity and influence. But we don’t know how it operates indetail.</li>
<li>The amount of data of some minority genres is too small, the prediction result of the model for minority genres is not good.</li>
</ul>
]]></content>
      <categories>
        <category>Mathematical Modeling</category>
      </categories>
  </entry>
  <entry>
    <title>A Renewable Energy Certificate Trading System Based on Blockchain</title>
    <url>/202110/2021-10-02-REC-trading/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>At present, the cumbersome issuing process of renewable energy certificate (REC) and inflexible pricing mechanism consume a lot of manpower and material resources. In order to solve this problem, this paper proposes a hybrid REC trading system based on Consortium Blockchain. The paper introduces the operation mode of the system in detail and changes the view replacement protocol in the Practical Byzantine Fault Tolerance (PBFT) Algorithm to improve the stability of the system. It also introduces the bidding rules of Continuous Double Auction (CDA) used in the system, and designs the bidding strategies to maximize the user’s profit and the success rate of transaction. Finally, ARIMA model is also used to forecast the price of RECs to provide guidance for both buyers and sellers. </p>
<ul>
<li><strong>Index Terms</strong><br>REC transaction, Consortium Blockchain, Continuous Double Auction, ARIMA</li>
</ul>
<h1 id="PDF"><a href="#PDF" class="headerlink" title="PDF"></a>PDF</h1><p><iframe style="height: 1000px; width: 100%; display: block" frameborder="0"  scrolling="no" src="/eysblog_en/objectsource/BDRA-13.pdf"> </iframe><br><br /></p>
<p>Accepted by TrustCom 2021: International Conference on Trust, Security and Privacy in Computing and Communications, Jul.2021.</p>
]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
  </entry>
  <entry>
    <title>Netizen Sentiment Recognition During COVID-19</title>
    <url>/202006/2020-06-18-Netizen-Sentiment/</url>
    <content><![CDATA[<p>The emergence of the COVID-19 has disrupted our normal life. People’s psychological state can also receive a great negative impact. We chose such a topic with humanistic concern in <code>Data Warehouse and Data Mining</code> course, hoping that through Weibo posts we can gain more insight into people’s emotional state during the COVID-19. We are awarded the best project (1/23) in this course, and we think we could do more in psychological care during COVID-19.</p>
<h1 id="Data-Source-and-Data-Structure"><a href="#Data-Source-and-Data-Structure" class="headerlink" title="Data Source and Data Structure"></a>Data Source and Data Structure</h1><p>This data comes from a data mining competition organized by DataFountain. The data set is a collection of Weibo crawled during the COVID-19. The link to the dataset is <a href="https://www.datafountain.cn/competitions/423/datasets">here</a>.</p>
<blockquote>
<p>The dataset cannot be downloaded directly from the official website because the competition has ended, the dataset can also be found on <a href="https://www.kaggle.com/liangqingyuan/chinese-text-multi-classification?select=nCoV_100k_train.labled.csv">Kaggle</a>.</p>
</blockquote>
<p>We used 100,000 posts from the training set provided by the competition website, but considering the time and computational cost, I only used the first 10,000 posts with annotations, and divided them into a training set and a test set in a 7/3 ratio. This dataset was based on 230 keywords related to the topic of “新冠肺炎”, which means COVID-19 in Chinese. </p>
<p>1,000,000 Weibo posts were collected from January 1, 2020 to February 20, 2020, and 100,000 Weibo posts were labeled with three categories: 1 (positive), 0 (neutral) and -1 (negative). The data is stored in csv format in <code>nCoV-100k.labeled.csv</code> file. The original dataset contains 100,000 user-labeled posts in the following format: <code>[post id, posting time, posting account, content, photos, videos, sentiment]</code>.</p>
<p>The original dataset has six attributes: <code>post id</code> (hashcode), <code>posting time</code> (Date), <code>posting account</code> (String), <code>content</code> (String), <code>photos</code> (String), and <code>videos</code> (String). Predicting <code>sentiment</code>(Int) by the above attributes. The purpose of this project is to use <strong>word bag preprocessing</strong>, <strong>TF-IDF preprocessing</strong>, <strong>word2vec</strong> and compare their effects, focusing on text processing and text sentiment analysis. So we only chose <code>content</code> attribute to predict the sentiment. (It was hard for us to read the emotion from photos and videos.)</p>
<p>Here is the statistical information of the dataset from Kaggle.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-1.png" alt="" width="80%"/></center>

<p>The bar chart shows that the number of positive, neutral and negative posts varies considerably, with the highest number of neutral posts.</p>
<p>Here is the first post in dataset.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-2.png" alt="" width="80%"/></center>

<p>We found this posts in Weibo APP.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-3.png" alt="" width="80%"/></center>

<h1 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h1><p>We Used Kaggle Kernel. Kaggle provides free access to the Nvidia K80 GPU in the kernel. This benchmark shows that using the GPU for your kernel can achieve a 12.5x speedup in the training of deep learning models.</p>
<p>ref: <a href="https://www.cnblogs.com/pinard/p/6744056.html">https://www.cnblogs.com/pinard/p/6744056.html</a></p>
<h2 id="Data-import-and-turncut"><a href="#Data-import-and-turncut" class="headerlink" title="Data import and turncut"></a>Data import and turncut</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd filepath = <span class="string">&#x27;/kaggle/input/chinese-text-multi-classification/nCoV_100k_train.labled.cs v&#x27;</span> file_data = pd.read_csv(filepath)</span><br><span class="line">data = file_data.head(<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># chose content and sentiment</span></span><br><span class="line">data = data[[<span class="string">&#x27;微博中⽂内容&#x27;</span>, <span class="string">&#x27;情感倾向&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<h2 id="Handling-missing-values"><a href="#Handling-missing-values" class="headerlink" title="Handling missing values"></a>Handling missing values</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># handling missing values</span></span><br><span class="line">data.isnull().<span class="built_in">sum</span>()</span><br><span class="line">data = data.dropna()</span><br></pre></td></tr></table></figure>
<h2 id="Remove-meaningless-symbols"><a href="#Remove-meaningless-symbols" class="headerlink" title="Remove meaningless symbols"></a>Remove meaningless symbols</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean_zh_text</span>(<span class="params">text</span>): </span><br><span class="line">    <span class="comment"># keep English, digital and Chinese </span></span><br><span class="line">    comp = re.<span class="built_in">compile</span>(<span class="string">&#x27;[^A-Z^a-z^0-9^\u4e00-\u9fa5]&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> comp.sub(<span class="string">&#x27;&#x27;</span>, text)</span><br><span class="line">data[<span class="string">&#x27;微博中⽂内容&#x27;</span>] = data.微博中⽂内容.apply(clean_zh_text)</span><br></pre></td></tr></table></figure>
<h2 id="Word-Cut"><a href="#Word-Cut" class="headerlink" title="Word Cut"></a>Word Cut</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># word cut </span></span><br><span class="line"><span class="keyword">import</span> jieba </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chinese_word_cut</span>(<span class="params">mytext</span>): </span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(jieba.cut(mytext))</span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;cut_comment&#x27;</span>] = data.微博中⽂内容.apply(chinese_word_cut)</span><br><span class="line"></span><br><span class="line"><span class="comment"># divided them into a training set and a test set in a 7/3 ratio.</span></span><br><span class="line">lentrain = <span class="built_in">int</span>((<span class="number">10000</span>-<span class="number">30</span>)*<span class="number">0.7</span>) </span><br><span class="line">lentest = <span class="built_in">int</span>((<span class="number">10000</span>-<span class="number">30</span>)*<span class="number">0.3</span>) </span><br><span class="line">x_train = data.head(lentrain)[<span class="string">&#x27;微博中⽂内容&#x27;</span>] </span><br><span class="line">y_train = data.head(lentrain)[<span class="string">&#x27;情感倾向&#x27;</span>] </span><br><span class="line">x_test = data.tail(lentest)[<span class="string">&#x27;微博中⽂内容&#x27;</span>]</span><br><span class="line">y_test = data.tail(lentest)[<span class="string">&#x27;情感倾向&#x27;</span>]</span><br></pre></td></tr></table></figure>
<center><img src="/eysblog_en/imgsource/covid-figure-4.png" alt="" width="80%"/></center>

<center><img src="/eysblog_en/imgsource/covid-figure-5.png" alt="" width="80%"/></center>

<h2 id="Import-Stop-Words"><a href="#Import-Stop-Words" class="headerlink" title="Import Stop Words"></a>Import Stop Words</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># import stop words</span></span><br><span class="line">stpwrdpath = <span class="string">&quot;/kaggle/input/stop-wordstxt/stop_words.txt&quot;</span> </span><br><span class="line">stpwrd_dic = <span class="built_in">open</span>(stpwrdpath, <span class="string">&#x27;rb&#x27;</span>) </span><br><span class="line">stpwrd_content = stpwrd_dic.read() </span><br><span class="line"></span><br><span class="line"><span class="comment">#transform into list </span></span><br><span class="line">stpwrdlst = stpwrd_content.splitlines()</span><br><span class="line">stpwrd_dic.close()</span><br></pre></td></tr></table></figure>
<h2 id="Word-Bag-Preprocess"><a href="#Word-Bag-Preprocess" class="headerlink" title="Word Bag Preprocess"></a>Word Bag Preprocess</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text </span><br><span class="line"><span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># CountVectorizer initialize</span></span><br><span class="line">count_vec = CountVectorizer(stop_words=stpwrdlst) </span><br><span class="line">x_train_list = x_train.tolist() </span><br><span class="line">x_train_cv = count_vec.fit_transform(x_train_list).toarray() </span><br><span class="line">x_test_list = x_test.tolist()</span><br><span class="line">x_test_cv = count_vec.fit_transform(x_test_list).toarray()</span><br></pre></td></tr></table></figure>
<center><img src="/eysblog_en/imgsource/covid-figure-6.png" alt="" width="80%"/></center>

<h2 id="TF-IDF-Preprocess"><a href="#TF-IDF-Preprocess" class="headerlink" title="TF-IDF Preprocess"></a>TF-IDF Preprocess</h2><p>ref:<a href="https://blog.csdn.net/blmoistawinde/article/details/80816179">https://blog.csdn.net/blmoistawinde/article/details/80816179</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer </span><br><span class="line">tfidf_vec = TfidfVectorizer(token_pattern=<span class="string">r&quot;(?u)\b\w+\b&quot;</span>, max_df=<span class="number">0.6</span>, stop_words=stpwr dlst) </span><br><span class="line">x_train_tiv = tfidf_vec.fit_transform(x_train_list).toarray()</span><br><span class="line">x_test_tiv = tfidf_vec.fit_transform(x_test_list).toarray()</span><br></pre></td></tr></table></figure>
<center><img src="/eysblog_en/imgsource/covid-figure-7.png" alt="" width="80%"/></center>

<h2 id="word2vec-embedding"><a href="#word2vec-embedding" class="headerlink" title="word2vec embedding"></a>word2vec embedding</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># word2vec </span></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec </span><br><span class="line">model = Word2Vec(x_train_list, hs=<span class="number">1</span>,min_count=<span class="number">1</span>,window=<span class="number">10</span>,size=<span class="number">100</span>)</span><br><span class="line"><span class="keyword">from</span> gensim.test.utils <span class="keyword">import</span> common_texts, get_tmpfile </span><br><span class="line">path = get_tmpfile(<span class="string">&quot;word2vec.model&quot;</span>) </span><br><span class="line">model.save(<span class="string">&quot;word2vec.model&quot;</span>)</span><br><span class="line"><span class="comment"># model = Word2Vec.load(&quot;word2vec.model&quot;)</span></span><br></pre></td></tr></table></figure>
<center><img src="/eysblog_en/imgsource/covid-figure-8.png" alt="" width="80%"/></center>

<p>The corpus of 10,000 training data is still a bit small, but the results are slightly more productive. For example, if we look at the close synonyms of “开心”(happy), we can see that the results returned are more positive.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-9.png" alt="" width="80%"/></center>

<h1 id="Data-Mining-Algorithm"><a href="#Data-Mining-Algorithm" class="headerlink" title="Data Mining Algorithm"></a>Data Mining Algorithm</h1><p>In this section, we will use <code>SVM</code>, <code>decision tree</code> and <code>RNN</code> algorithms to achieve classification. The embedding obtained by <code>BOW</code> and <code>TF-IDF</code> will be classified by SVM and decision tree algorithms, respectively, while the embedding obtained by Word2Vec will be classified by RNN.</p>
<p>The embedding obtained from Word2Vec will be classified using RNN. The detailed algorithm flow is as follows.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-10.png" alt="" width="80%"/></center>

<h2 id="BOW-SVM"><a href="#BOW-SVM" class="headerlink" title="BOW + SVM"></a><code>BOW</code> + <code>SVM</code></h2><p>The 35596-dimensional embedding of the Weibo posts obtained by <code>BOW</code> is used as the input of the <code>SVM</code> in the <code>sklearn</code> package.<br>The parameters are as follows.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clf = svm.SVC(C=<span class="number">0.8</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">20</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler </span><br><span class="line">scale = StandardScaler() </span><br><span class="line">scale_fit = scale.fit(x_cv) </span><br><span class="line"><span class="comment">#x = scale_fit.transform(x) </span></span><br><span class="line">lentrain = <span class="built_in">int</span>((<span class="number">10000</span>-<span class="number">30</span>)*<span class="number">0.7</span>) </span><br><span class="line">lentest = <span class="built_in">int</span>((<span class="number">10000</span>-<span class="number">30</span>)*<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">x_train_cv = scale_fit.transform(x_cv[:lentrain]) </span><br><span class="line">y_train = y[:lentrain] </span><br><span class="line">x_test_cv = scale_fit.transform(x_cv[(-<span class="number">1</span>)*lentest-<span class="number">1</span>:-<span class="number">1</span>]) </span><br><span class="line">y_test = y[(-<span class="number">1</span>)*lentest-<span class="number">1</span>:-<span class="number">1</span>] </span><br><span class="line"><span class="built_in">print</span>(x_train_cv.shape) </span><br><span class="line"><span class="built_in">print</span>(y_train.shape) </span><br><span class="line"><span class="built_in">print</span>(x_test_cv.shape)</span><br><span class="line"><span class="built_in">print</span>(y_test.shape)</span><br></pre></td></tr></table></figure>
<p><strong>TIPS:</strong></p>
<ul>
<li><code>SVM</code> and <code>Decision Tree</code> algorithms for 10,000 of 30,000-dimensional data can take a lot of time, and sklearn does not support GPU computing.</li>
<li>When you encounter a very large dataset, you should first use a small demo to check the correctness of the code, and then run a large demo with a large amount of data.</li>
<li><code>BOW</code> and <code>TF-IDF</code> should be used first before dividing the test and training sets, otherwise the test and training sets will not have the same dimensionality! It took a lot of time to fix this error.</li>
<li>Due to the excessive number of dimensions, remember to normalize the data before <code>SVM</code>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># prepare the data</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scale = StandardScaler()</span><br><span class="line">scale_fit = scale.fit(x_cv)</span><br><span class="line"><span class="comment">#x = scale_fit.transform(x)</span></span><br><span class="line">lentrain = <span class="built_in">int</span>((<span class="number">10000</span>-<span class="number">30</span>)*<span class="number">0.7</span>)</span><br><span class="line">lentest = <span class="built_in">int</span>((<span class="number">10000</span>-<span class="number">30</span>)*<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">x_train_cv = scale_fit.transform(x_cv[:lentrain])</span><br><span class="line">y_train = y[:lentrain]</span><br><span class="line">x_test_cv = scale_fit.transform(x_cv[(-<span class="number">1</span>)*lentest-<span class="number">1</span>:-<span class="number">1</span>])</span><br><span class="line">y_test = y[(-<span class="number">1</span>)*lentest-<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(x_train_cv.shape)</span><br><span class="line"><span class="built_in">print</span>(y_train.shape)</span><br><span class="line"><span class="built_in">print</span>(x_test_cv.shape)</span><br><span class="line"><span class="built_in">print</span>(y_test.shape)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#test bow+svm</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x_train_cv.shape, <span class="string">&#x27;and &#x27;</span>, y_train.shape)</span><br><span class="line">clf = svm.SVC(C=<span class="number">0.8</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">20</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>)</span><br><span class="line">cv_model = clf.fit(x_train_cv, y_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score, f1_score, accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Precision_score: &#x27;</span>, precision_score(y_hat_cv, y_test, average=<span class="string">&#x27;weighted&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Recall_score: &#x27;</span>, recall_score(y_hat_cv, y_test, average=<span class="string">&#x27;weighted&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;F1_score: &#x27;</span>, f1_score(y_hat_cv, y_test, average=<span class="string">&#x27;weighted&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy_score: &#x27;</span>, accuracy_score(y_hat_cv, y_test))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># roc_curve:真正率（True Positive Rate , TPR）或灵敏度（sensitivity）</span></span><br><span class="line"><span class="comment"># 横坐标：假正率（False Positive Rate , FPR）</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> interp</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"></span><br><span class="line">nb_classes = <span class="number">3</span></span><br><span class="line"><span class="comment"># Binarize the output</span></span><br><span class="line">Y_valid = label_binarize(y_test, classes=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_classes)])</span><br><span class="line">Y_pred = label_binarize(y_hat_cv, classes=[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_classes)])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Compute ROC curve and ROC area for each class</span></span><br><span class="line">fpr = <span class="built_in">dict</span>()</span><br><span class="line">tpr = <span class="built_in">dict</span>()</span><br><span class="line">roc_auc = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_classes):</span><br><span class="line">    fpr[i], tpr[i], _ = roc_curve(Y_valid[:, i], Y_pred[:, i])</span><br><span class="line">    roc_auc[i] = auc(fpr[i], tpr[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute micro-average ROC curve and ROC area</span></span><br><span class="line">fpr[<span class="string">&quot;micro&quot;</span>], tpr[<span class="string">&quot;micro&quot;</span>], _ = roc_curve(Y_valid.ravel(), Y_pred.ravel())</span><br><span class="line">roc_auc[<span class="string">&quot;micro&quot;</span>] = auc(fpr[<span class="string">&quot;micro&quot;</span>], tpr[<span class="string">&quot;micro&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute macro-average ROC curve and ROC area</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># First aggregate all false positive rates</span></span><br><span class="line">all_fpr = np.unique(np.concatenate([fpr[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_classes)]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Then interpolate all ROC curves at this points</span></span><br><span class="line">mean_tpr = np.zeros_like(all_fpr)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_classes):</span><br><span class="line">    mean_tpr += interp(all_fpr, fpr[i], tpr[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Finally average it and compute AUC</span></span><br><span class="line">mean_tpr /= nb_classes</span><br><span class="line"></span><br><span class="line">fpr[<span class="string">&quot;macro&quot;</span>] = all_fpr</span><br><span class="line">tpr[<span class="string">&quot;macro&quot;</span>] = mean_tpr</span><br><span class="line">roc_auc[<span class="string">&quot;macro&quot;</span>] = auc(fpr[<span class="string">&quot;macro&quot;</span>], tpr[<span class="string">&quot;macro&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot all ROC curves</span></span><br><span class="line">lw = <span class="number">2</span></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(fpr[<span class="string">&quot;micro&quot;</span>], tpr[<span class="string">&quot;micro&quot;</span>],</span><br><span class="line">         label=<span class="string">&#x27;micro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span></span><br><span class="line">               <span class="string">&#x27;&#x27;</span>.<span class="built_in">format</span>(roc_auc[<span class="string">&quot;micro&quot;</span>]),</span><br><span class="line">         color=<span class="string">&#x27;deeppink&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>, linewidth=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(fpr[<span class="string">&quot;macro&quot;</span>], tpr[<span class="string">&quot;macro&quot;</span>],</span><br><span class="line">         label=<span class="string">&#x27;macro-average ROC curve (area = &#123;0:0.2f&#125;)&#x27;</span></span><br><span class="line">               <span class="string">&#x27;&#x27;</span>.<span class="built_in">format</span>(roc_auc[<span class="string">&quot;macro&quot;</span>]),</span><br><span class="line">         color=<span class="string">&#x27;navy&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>, linewidth=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">colors = cycle([<span class="string">&#x27;aqua&#x27;</span>, <span class="string">&#x27;darkorange&#x27;</span>, <span class="string">&#x27;cornflowerblue&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(nb_classes), colors):</span><br><span class="line">    plt.plot(fpr[i], tpr[i], color=color, lw=lw,</span><br><span class="line">             label=<span class="string">&#x27;ROC curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span></span><br><span class="line">             <span class="string">&#x27;&#x27;</span>.<span class="built_in">format</span>(i, roc_auc[i]))</span><br><span class="line"></span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>, lw=lw)</span><br><span class="line">plt.xlim([<span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Some extension of Receiver operating characteristic to multi-class&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>Here’s the result:</p>
<center><img src="/eysblog_en/imgsource/covid-figure-11.png" alt="" width="80%"/></center>

<center><img src="/eysblog_en/imgsource/covid-figure-12.png" alt="" width="80%"/></center>

<p>The reason for the coincidence of the ROC curve and the X-axis is that most of the predictions are zero. The reasons are as follows: </p>
<ol>
<li>The two embedding methods, <code>BOW</code> and <code>TF-IDF</code>, do not work well as <code>SVM</code>, and even after normalizing the input word (frequency) vector matrix, most of the predictions are still the same. </li>
<li>The number of “neutral” labels in the sample is much higher than the number of “positive” and “negative” labels, which is also a problem in the sample selection process.</li>
<li>The parameters of <code>SVM</code> can be adjusted more precisely to make the classification better.</li>
</ol>
<p>Instead of further tuning this model, we tried other algorithms first.</p>
<h2 id="TF-IDF-SVM"><a href="#TF-IDF-SVM" class="headerlink" title="TF-IDF+SVM"></a><code>TF-IDF</code>+<code>SVM</code></h2><p>The 38473-dimensional embedding of the <code>TF-IDF</code> derived posts is used as the input to the <code>SVM</code> in the sklearn package.</p>
<p>The source code is similar to the model above, so I will not repeat it here. The results are shown below.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-13.png" alt="" width="80%"/></center>

<p>The parameters are as follows.<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clf = svm.SVC(C=<span class="number">0.8</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">20</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="BOW-Decision-Tree-amp-amp-TF-IDF-Decision-Tree"><a href="#BOW-Decision-Tree-amp-amp-TF-IDF-Decision-Tree" class="headerlink" title="BOW + Decision Tree &amp;&amp; TF-IDF + Decision Tree"></a><code>BOW</code> + <code>Decision Tree</code> &amp;&amp; <code>TF-IDF</code> + <code>Decision Tree</code></h2><p>The source code is similar to the model above, so I will not repeat it here.</p>
<p>Here’s the result for <code>BOW</code> + <code>Decision Tree</code>.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-14.png" alt="" width="80%"/></center>

<p>Here’s the result for <code>TF-IDF</code> + <code>Decision Tree</code></p>
<center><img src="/eysblog_en/imgsource/covid-figure-15.png" alt="" width="80%"/></center>

<h2 id="Word2Vec-RNN"><a href="#Word2Vec-RNN" class="headerlink" title="Word2Vec + RNN"></a><code>Word2Vec</code> + <code>RNN</code></h2><p>Embedding Weibo content using Word2Vec, then the resulting 400-dimensional vector is fed into a 10<em>200</em>1 recurrent neural grid with one hidden layer.</p>
<p>Parameters:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">100</span> </span><br><span class="line">n_iters = <span class="number">20000</span> </span><br><span class="line">seq_dim = <span class="number">20</span> </span><br><span class="line">input_dim = <span class="number">20</span> <span class="comment"># input dimension</span></span><br><span class="line">hidden_dim = <span class="number">200</span> <span class="comment"># hidden layer dimension </span></span><br><span class="line">layer_dim = <span class="number">1</span> <span class="comment"># number of hidden layers</span></span><br><span class="line">output_dim = <span class="number">3</span> <span class="comment"># output dimension</span></span><br></pre></td></tr></table></figure></p>
<p>So far we have obtained the embedding of all words, the key problem is how to represent the sentences. I referred to the information below and chose to try it with <code>word2vec</code> using Gensim.</p>
<p>ref1: <a href="https://www.zhihu.com/question/29978268">https://www.zhihu.com/question/29978268</a></p>
<p>ref2: <a href="https://blog.csdn.net/John_xyz/article/details/79424284">https://blog.csdn.net/John_xyz/article/details/79424284</a></p>
<p>ref3: <a href="https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch">https://www.kaggle.com/kanncaa1/recurrent-neural-network-with-pytorch</a></p>
<p>At the first time we try, there is exploding gradient.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-16.png" alt="" width="80%"/></center>

<p>After adjusting the learning rate to 0.03, the results after 60,000 generations of training are shown below.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-17.png" alt="" width="80%"/></center>

<center><img src="/eysblog_en/imgsource/covid-figure-18.png" alt="" width="80%"/></center>

<p>After adjusting hidden layers, the results after 20,000 generations are shown below.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-19.png" alt="" width="80%"/></center>

<center><img src="/eysblog_en/imgsource/covid-figure-20.png" alt="" width="80%"/></center>

<h1 id="Analysis-of-Results"><a href="#Analysis-of-Results" class="headerlink" title="Analysis of Results"></a>Analysis of Results</h1><p>This is a triple classification problem on the emotion of NLP. The results are shown as follow.</p>
<center><img src="/eysblog_en/imgsource/covid-figure-21.png" alt="" width="80%"/></center>

<p>As can be seen from the above graphs, the <code>SVM</code> and <code>Decision Tree</code> algorithms have very little impact on the actual results, and the most important factor affecting the prediction results is the Embedding method. In this dataset, <code>TF-IDF</code> is more effective than <code>BOW</code>. In the end, the results of <code>TF-IDF</code>+<code>SVM</code>, <code>TF-IDF</code>+<code>Decision Tree</code> and <code>Word2Vec</code>+<code>RNN</code> are similar. The reasons for this result are as follows: </p>
<ol>
<li>The original dataset is not evenly distributed, and there are more “neutral” comments than “positive” and “negative” posts, so in the predictive classification process, most of the postss are not evenly distributed. The majority of posts tend to be classified as “neutral” in the prediction classification process, which is of course consistent with the actual situation. This is why the Embedding method has a greater impact on the results than the classification method.</li>
<li>The dataset is not large enough. I thought that a data set of about 10,000 would take a lot of training time, but Kaggle can use GPUs and the CPU speed of Kaggle is not slow, so I could have done it directly with the original data set of 10W, and the result would be better.</li>
<li>Parameter optimization. It is only fair to use the optimal parameters of each model for comparison of results.</li>
</ol>
]]></content>
      <categories>
        <category>NLP (Natural Language Processing)</category>
      </categories>
  </entry>
  <entry>
    <title>[MCM 2020] Data Analysis for Sunshine Company&#39;s New Product</title>
    <url>/202003/2020-03-10-MCM-Grocery/</url>
    <content><![CDATA[<p>This is my second time for MCM &amp; ICM. I teamed up with two friends respectively from computer science major and electronic information major. This is how we divide the work: one of my friends collecting information and the other writing the essay. I was responsible for modeling and coding. We finally got <strong>Meritorious Winner(Top 5%)</strong>. I’m so proud of it. This is our entry experience.</p>
<h1 id="Topic-amp-Dataset"><a href="#Topic-amp-Dataset" class="headerlink" title="Topic &amp; Dataset"></a>Topic &amp; Dataset</h1><blockquote>
<p>In the online marketplace it created, Amazon provides customers with an opportunity to rate and review purchases. Individual ratings - called “star ratings” - allow purchasers to express their level of satisfaction with a product using a scale of 1 (low rated, low satisfaction) to 5 (highly rated, high satisfaction). Additionally, customers can submit text-based messages - called “reviews” - that express further opinions and information about the product. Other customers can submit ratings on these reviews as being helpful or not - called a “helpfulness rating” - towards assisting their own product purchasing decision. Companies use these data to gain insights into the markets in which they participate, the timing of that participation, and the potential success of product design feature choices.</p>
<p>Sunshine Company is planning to introduce and sell three new products in the online marketplace: a microwave oven, a baby pacifier, and a hair dryer. They have hired your team as consultants to identify key patterns, relationships, measures, and parameters in past customer-supplied ratings and reviews associated with other competing products to 1) inform their online sales strategy and 2) identify potentially important design features that would enhance product desirability. Sunshine Company has used data to inform sales strategies in the past, but they have not previously used this particular combination and type of data. Of particular interest to Sunshine Companyare time-based patterns in these data, and whether they interact in ways that will help the company craft successful products.</p>
<p>To assist you, Sunshine’s data center has provided you with three data files for this project: hair_dryer.tsv, microwave.tsv, and pacifier.tsv. These data represent customer-supplied ratings and reviews for microwave ovens, baby pacifiers, and hair dryers sold in the Amazon marketplace over the time period(s) indicated in the data. A glossary of data label definitions is provided as well. </p>
</blockquote>
<p>The three data sets provided contain product user ratings and reviews extracted from the Amazon Customer Reviews Dataset thru Amazon Simple Storage Service (Amazon S3).</p>
<ul>
<li><code>hair_dryer.tsv</code></li>
<li><code>microwave.tsv</code></li>
<li><code>pacifier.tsv</code></li>
</ul>
<p>Data Set Definitions: Each row represents data partitioned into the following columns.</p>
<pre><code>- marketplace (string): 2 letter country code of the marketplace where the review was written.
- customer_id (string): Random identifier that can be used to aggregate reviews written by a single author.
- review_id (string): The unique ID of the review.
- product_id (string): The unique Product ID the review pertains to.
- product_parent (string): Random identifier that can be used to aggregate reviews for the same product.
- product_title (string): Title of the product.
- product_category (string): The major consumer category for the product.
- star_rating (int): The 1-5 star rating of the review.
- helpful_votes (int): Number of helpful votes.
- total_votes (int): Number of total votes the review received.
- vine (string): Customers are invited to become Amazon Vine Voices based on the trust that they have earned in the Amazon community for writing accurate and insightful reviews. Amazon provides Amazon Vine members with free copies of products that have been submitted to the program by vendors. Amazon doesn&#39;t influence the opinions of Amazon Vine members, nor do they modify or edit reviews.
- verified_purchase (string): A &quot;Y&quot; indicates Amazon verified that the person writing the review purchased the product at - Amazon and didn&#39;t receive the product at a deep discount.
- review_headline (string): The title of the review.
- review_body (string): The review text.
- review_date (bigint): The date the review was written.
</code></pre><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>Through data mining and modeling, we analyze the three types of products and provide a marketing strategy for Sunshine Company.</p>
<p>First of all, we preprocess the data. We fully analyze the 15 attributes in microwaves, pacifiers and hair dryers, filter them and syntheze three new attributes: review_text, popularity and reputation. We deal with missing values in the data set and remove those meaningless reviews. Through the Tokenization algorithm, we cut the sentence of the review headline and the review body into single words, which is convenient for us to analyze the emotion of the user and understand the relationship between reviews and star ratings. </p>
<p>Furthermore, we use the TF-IDF(Term FrequencyInverse Document Frequency) algorithm and MLP(Multi-layer Perceptron) to build a model and try to discover the relationship between reviews and star ratings. We use reviews to evaluate the products and use helpful votes to evaluate reviews, through this way we build a multidimension evaluation system. The TF-IDF algorithm uses the segmented words to generate a word frequency matrix, which is used as the input of the MLP. And the products’ star ratings are used as the output. We build models for the three types of products respectively, for the reviews of the three types of products have some differences, which may affect the accuracy of the results. The data set is divided into training set and test set. When the model training is completed, the effect of the model is tested with the test set. After the practice, our prediction is very similar to the ground truth. Then we get the relationship between star ratings and reviews. The traditional MLP model has poor interpretability, so we continue to do lexical analysis and syntax analysis on this basis, which enhances the interpretability of the whole model.</p>
<p>Eventually , we analyze the time-based popularity changes of the product, and make marketing suggestions to the Sunshine Company from the customer’s perspective. Through analysis, we found that the products’ popularity always reach the highest at the beginning and middle of each year, so the company could make promotional activities at that time to raise their profile. In this way, we found the relationship between period and popularity. From the perspective of customers, we observe that those users who score 5 stars or 1 star often quite emotional when giving reviews. We recommend three types of the most valuable users and select their reviews for the sunshine company. They are AmazonVine Voices Members, users who have purchased multiple similar products and users who have given one-star rate to the product. By analyzing the WordCloud of reviews of those who have given one-star rates, we can know how to improve the products.</p>
<h1 id="Preparation-for-the-modeling"><a href="#Preparation-for-the-modeling" class="headerlink" title="Preparation for the modeling"></a>Preparation for the modeling</h1><p>For the data mining problems that have large quantity and types of data, there are often a large number of default values, which may affect the efficiency and accuracy of the model. Therefore, the processing of these default values is of vital importance. In addition, in this data set, there is a large amount of text information in attributes such as prouct_title, and review_headline. Thus our team choose the tokenization algorithm to classify and organize the text information.</p>
<h2 id="Default-Value-Preprocessing"><a href="#Default-Value-Preprocessing" class="headerlink" title="Default Value Preprocessing"></a>Default Value Preprocessing</h2><p>Through our analysis, in all of the given data sets, only the review_headline and review_body attributes are default. The Amazon website stipulates that when a review is submitted, its star_rating, review_headline and review_body must be filled in, otherwise the review cannot be submitted. so the lack of data is not caused by user behavior, but created during the collection, transmission or storage of these reviews. Therefore the “default” here doesnt contain customers opinions towards the product.<br>In this case our team deal with the default records in this way.</p>
<ul>
<li>When only one of the review_headline or review_body is default, we will keep this data. Because it still contains a large amount of information;</li>
<li>When both of the review_headline and review_body are default, We will abandon this data. Because review is an essential part of our following analysis, in this case when both of them are default, this data is of little significance for data<br>mining.</li>
</ul>
<h2 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h2><p>The main goal of Tokenization is to normalize our texts, that is, to process a paragraph of text into short, non-redundant text information. Our tokenization process<br>includes the following steps:</p>
<p>a. Lowercase the values.<br>Because the text_market, product_title and other text attributes have a kind of phenomenon that some values with the same meaning have different capitalization. For example, the marketplace attribute contains ’US’ and ’us’, which is not convenient for our subsequent classification of products. Therefore we convert all text to lower<br>case.<br>b. Break the sentences into token<br>c. Remove punctuation and stop words<br>In computing, stop words are words which are filtered out before or after processing of natural language data (text).</p>
<p>We give an example in Figure 1.</p>
<center><img src="/eysblog_en/imgsource/mcm2020-figure-1.png" alt="" width="100%"/>
<p><font size=3 color="black">Figure 1: An example about Tokenization in Microwave Product Data Set</font></p></center>

<h2 id="Data-Selection-and-Synthesis"><a href="#Data-Selection-and-Synthesis" class="headerlink" title="Data Selection and Synthesis"></a>Data Selection and Synthesis</h2><p>In these 15 attributes that come from the provided data sets, some of them are not valuable. So we need to select the relatively more essential attributes. For the marketplace attribute, all evaluations in the dataset are from the US, so there is no reason to do data mining on this attribute, similarly in product_cetegory. Review_id is only used to distinguish different reviews, so we delete their corresponding data as well.</p>
<p>Before introducing product_id and product_parent, we need to learn more about parent-child relationships. </p>
<p>Each parent product may contain multiple child products, and each child parents may be different in sizes, colors, or prices. Each parent product corresponds to a product_parent, and each child product corresponds to a product_id. In the following data analysis, we mainly analyze the parent product and inspect these three types of products from a macro level. Take the microwave as an example, the parent-child product relationship as shown below. </p>
<p>In Figure 2 , we can find the four child products have different product_ids and they may have different sizes, colors or prices. However, they have the same product_parent. Please notice that we don’t know the specific information about these four child products.Their colors and sizes in Figure 2 are just for example. </p>
<p>We choose these following basic attributes in Table 1 to create the Customer Profile. Additionally, some synthetic variables are used in our model. These variables are described in Table 2.</p>
<center><img src="/eysblog_en/imgsource/mcm2020-figure-2.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 2: The Parent-Child Relationship in Microwave Products</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-table-1.png" alt="" width="100%"/></center>

<center><img src="/eysblog_en/imgsource/mcm2020-table-2.png" alt="" width="100%"/></center>
<br />

# Competing Products Analysis

First we visualize the data sets to show the profiles of the three products. The number of reviews and parent products are shown in Table 3. 

Here is the products profile of microwave, the other two products are attached to the appendix. Figure 3 shows the star ratings and the number of reviews of every parent products. The horizontal axis reprensents the product titles. 

For Microwaves, we select the product that has the most reviews - "Danby 0.7 cu.ft. Countertop Microwave" to analyze its reviews. Before we create the wordcloud of review_text, we take stemming operations. Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root formgenerally a written word form. 

In Figure 5, High frequency words has bigger font size. In Figure 6, horizontal axis represents the review headline. 

In addition to the above analysis from the perspective of the product itself, we also try to delete the click farmers or construct Customer Profile from the user’s perspective. Through the Customer Profile, we can have a better understanding toward the interests of the target users, and thus we could provide better product services.

We observe that a large number of users have bought more than one products. So we check out several reviews and found that many of them are click farmers, and their invalid reviews cannot be checked out through the helpful_votes, so eventually we manually deleted these reviews. For others who have really bought many products, we think their opinions are as valuable as those of Amazon Vine Voices Members. Therefore we filtered out 53 reviews from 9 users who have purchased more than 5 products and sent these comments to Sunshine Company for their reference. These 9 user comments are detailed in the appendix.

<center><img src="/eysblog_en/imgsource/mcm2020-table-3.png" alt="" width="100%"/></center>
<br />

<center><img src="/eysblog_en/imgsource/mcm2020-figure-3.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 3: The Star Ratings and the Number of Reviews of Microwave</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-4.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 4: The proportion of People Who Were in Amazon Vine and People Who Had Bought the Product</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-5.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 5: The Wordcloud of Microwave</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-6.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 6: The Reviews' Total Votes and Helpful Votes of Danby 0.7 cu.ft. Countertop Microwave</font></p></center>

<h1 id="Model-Construction"><a href="#Model-Construction" class="headerlink" title="Model Construction"></a>Model Construction</h1><p>In the previous data preprocessing, we have processed a series of reviews_text through the Tokenization algorithm. Next, we will process the data through the TF-IDF (Term FrequencyInverse Document Frequency) algorithm and the MLP (Multi-Layer Perception) model to get the relationship between star_rating and review. </p>
<p>The keywords in different product reviews are quite different and will affect each other, so we build three prediction models for the products: microwave, pacifier, and hair dryer. We first use the TF-IDF algorithm to obtain the term frequency matrix. TF-IDF is a commonly used weighting technique for information retrieval and data mining. The algorithm can simply and efficiently find keywords in articles.</p>
<h2 id="Compute-the-TF-IDF-Matrix"><a href="#Compute-the-TF-IDF-Matrix" class="headerlink" title="Compute the TF-IDF Matrix"></a>Compute the TF-IDF Matrix</h2><p>TF-IDF consists of two parts, one is “Term Frequency” (abbreviated as TF), and the other is “Inverse Document Frequency” (abbreviated as IDF). </p>
<p>TF part will create a Term Frequency Matrix. We use the review_text in Figure 1 to<br>illustrate the process. The procession is shown in Figure 7.</p>
<center><img src="/eysblog_en/imgsource/mcm2020-figure-7.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 7: TF Procession</font></p></center>

<script type="math/tex; mode=display">
f_i=\frac{c_i}{\sum^s_{i=1}c_i}
\tag{1}</script><p>In Equation 1, \(f_i\) is the frequency of the \(i\)th word. \(c_i\) is the occurrence number in a review_text of the ith word. s is the amount of words in the review_text. we find out that in Figure 7 the word frequencies of ’look’, ’good’ and ’long’ are the highest. However, this does not mean these three words are equally important in the analysis process. We need to multiply this word frequency matrix by IDF (Inverse Document Frequency) to get the TF-IDF values of these words.</p>
<p>In Equation 2, \(d_i\) is the IDF value of the ith word. \(m\) is total number of articles in Corpus. \(n_i\) is the number of articles containing the ith word in Corpus. \(v_i\) is the TF-IDF value of the \(i\)th word.</p>
<script type="math/tex; mode=display">
d_i=log \left( \frac{m}{n_i+1} \right)
\tag{2}</script><script type="math/tex; mode=display">
v_i=f_i*d_i
\tag{3}</script><p>We give Figure 8 as an example for the TF-IDF values. After that, we will construct the TF-IDF matrix of the review based on the TF-IDF values of these words corresponding dictionaries. It is worth mentioning that we apply helpful<em>votes as a reference to the TF-IDF matrix. In Equation 4, \(M\) is the TF-IDF matrix for the product. The \(k\)th review’s \(i\)th word’s TF-IDF value is \(v</em>{ki}\).</p>
<script type="math/tex; mode=display">
M_{ki}=v_{ki}
\tag{4}</script><center><img src="/eysblog_en/imgsource/mcm2020-figure-8.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 8: TF-IDF Values</font></p></center>

<h2 id="Contrust-the-MLP-Model"><a href="#Contrust-the-MLP-Model" class="headerlink" title="Contrust the MLP Model"></a>Contrust the MLP Model</h2><p>We divide three data sets into training sets and test sets by a ratio of 3:1 respectively. Then we use the input and output of the training set to train MLP(Multi-Layer Perception). The core formulas of the MLP are show below.</p>
<p>Multi-Layer Perception made up of a lot of artificial neurons. The artificial neuron uses a nonlinear activation function to output an activity value.The training process of MLP can be divided into the following three steps:</p>
<ol>
<li>Calculate the state and activation value of each layer, until the last layer;</li>
<li>Calculate the error of each layer by backward propagation;</li>
<li>Calculate the partial derivative of each layer’s parameters, and update the parameters.</li>
</ol>
<p>Suppose neurons accept our TF-IDF Matrix \(X = (x1, x2, . . . , xn)\). State \(z\) is used to represent the weighted sum of input signal \(x\) obtained by a neuron, and the output is the activity value a of the neuron, which is defined as follows:</p>
<script type="math/tex; mode=display">
z=W^TX+b
\tag{5}</script><script type="math/tex; mode=display">
a=f(z)
\tag{6}</script><script type="math/tex; mode=display">
z^{(l)}=W^{(l)} \cdot f_{l}\left(z^{(l-1)}\right)+b^{(l)}
\tag{7}</script><p>In the process of forward propagation, we use notations as folloowing Table 4.</p>
<center><img src="/eysblog_en/imgsource/mcm2020-table-4.png" alt="" width="100%"/></center>
<br />

$$
X=a^{(0)} \rightarrow z^{(1)} \rightarrow a^{(1)} \rightarrow z^{(2)} \rightarrow \cdots \rightarrow a^{(L-1)} \rightarrow z^{(L)} \rightarrow a^{(L)}=y
\tag{8}
$$

In the process of back propagation, given a set of samples \\((X(i), y(i)), 1 ≤ i ≤ N\\), the output of feedforward neural network whose objective function is \\(f(X(i)|W, b)\\) is as follows.

$$
\begin{aligned}
J(W, b) &=\sum_{i=1}^{N} L\left(y^{(i)}, f\left(X^{(i)} \mid W, b\right)\right)+\frac{1}{2} \lambda\|W\|_{F}^{2} \\
&=\sum_{i=1}^{N} J\left(W, b ; X(i), y^{(i)}\right)+\frac{1}{2} \lambda\|W\|_{F}^{2}
\end{aligned}
\tag{9}
$$

$$
\|W\|_{F}^{2}=\sum_{l=1}^{L} \sum_{j=1}^{n^{l+1}} \sum_{1=1}^{n^{l}} W_{i j}^{(l)}
\tag{10}
$$

We use gradient descent to minimize the Equation 9, finally we get \\(l\\)th layer's error in Equation 11.

$$
\begin{aligned}
\delta^{(l)} & \triangleq \frac{J(W, b ; X, y)}{\partial z^{(l)}} \\
&=\frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l+1)}}{\partial a^{(l)}} \cdot \frac{J(W, b ; X, y)}{\partial z^{(l+1)}} \\
&=\operatorname{diag}\left(f_{l}\left(z^{(l)}\right)\right) \cdot\left(W^{(l+1)}\right)^{T} \cdot \delta^{(l+1)} \\
&=f_{l}\left(z^{(l)}\right) \odot\left(\left(W^{(l+1)}\right)^{T} \delta^{(l+1)}\right)
\end{aligned}
\tag{11}
$$

Then we continue to iterate and get an error-stable model. Finally, we use the trained model to predict the test data. We set the fitting figure of Microwave in three products as Figure 9.

<center><img src="/eysblog_en/imgsource/mcm2020-figure-9.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 9: The fitting Figure of Hair Dryer</font></p></center>

<h2 id="Time-Based-Analysis"><a href="#Time-Based-Analysis" class="headerlink" title="Time-Based Analysis"></a>Time-Based Analysis</h2><p>Product reputation is composed of star rating and popularity. Product quality is the determing factor of star rating and review content. We will analyze popularity based on time to provide suggestions for sunshine company.</p>
<p>We analyze the 8 products with the highest popularity, and observed their popularity changes over time. It can be seen from the Figure 10 that five of the eight products have peak popularity only at the beginning of each year, and the other three products will have peak popularity at the beginning and middle of each year. There are three reasons for this:</p>
<p>a. At the beginning of the year, it’s just the time for people to purchase in the new year. People’s desire for shopping is strong, while microwave, pacifier and hair dryer are durable products, which can be used for a long time. No one will buy twice in a short time.</p>
<p>b. Amazon or merchants have promotional activities at the beginning of the year to improve product popularity.</p>
<p>c. The data retrieving process is not objective, we only get the data at a certain period.</p>
<center><img src="/eysblog_en/imgsource/mcm2020-figure-10.png" alt="" width="80%"/>
<p><font size=3 color="black">Figure 10: The Number of Reviews of the 10 Most Popularity Products</font></p></center>

<p>A products reputation consists the product’s praise and popularity, and the decisive factor that influences a products star ratings and the content of its reviews is its quality. In the following discussion we will offer a proposal for Sunshine Company from the perspective of the products popularity. </p>
<p>We analyze the top eight popular products and observe their popularity changes over time. To our surprise, 5 of these 8 products have popularity peaks only at the beginning of each year, and the remaining three products have popularity peaks at the beginning and middle of the year. There why This phenomenon happens are as follows:</p>
<ol>
<li>In the beginning of the year, everyone is buying goods for the coming of new year. So people’s desire for shopping is strong. On the other hand, the microwave, pacifier and hair dryer are all durable commodities, which can be used for a long time. So there will be no repurchase in a short time. Therefore, there will be peaks of popularity in only particular times.</li>
<li>Amazon or sellers have promotional campaign at the beginning of the year in order to increase the products popularity.</li>
<li>The data collection process is not objective. Only data of the beginning and middle of the year were collected.</li>
</ol>
<h1 id="Sales-Strategy"><a href="#Sales-Strategy" class="headerlink" title="Sales Strategy"></a>Sales Strategy</h1><p>Our goal is to allow Sunshine Company to expand market influence, continuously improve products and win a good corporate reputation among the public. We will make recommendations for Sunshine Company from two perspectives: How to Enhance the Reputation and How to Improve the Product.</p>
<h2 id="How-to-Enhance-the-Reputation"><a href="#How-to-Enhance-the-Reputation" class="headerlink" title="How to Enhance the Reputation"></a>How to Enhance the Reputation</h2><p>Reputation consists of two parts: popularity and star rating. First of all, from the perspective of popularity, we hope more people could pay attention to the company’s products. The most direct way to do this is to choose the right time to advertise and promote this product. we recommended that Sunshine Company are supposed to enhance propaganda and increase the discount at the beginning and middle of each year to increase product sales and popularity.</p>
<h2 id="How-to-Improve-the-Product"><a href="#How-to-Improve-the-Product" class="headerlink" title="How to Improve the Product"></a>How to Improve the Product</h2><p>On the other hand, for Star rating, the most fundamental influence of it is the product itself. By analyzing the content of the review, we could comprehend the relationship between star rating and review, furthermore, we could improve the product through the content review. Therefore, analyzing the content of the review is of vital importance. </p>
<p>From the previous model, we believe that there are three types of customers that worth pay attention to. Their reviews and attitude towards the product can effectively help us to improve the product.</p>
<ul>
<li>Amazon Vine Voices Members</li>
</ul>
<p>These people are selected by Amazon. They are the most trusted reviewers on Amazon to post opinions about new and pre-release items to help their fellow<br>customers make informed purchase decisions.</p>
<ul>
<li>People who have bought a lot of different products.</li>
</ul>
<p>These people have experienced more similar products than common customers, and they have a deeper understanding of this type of product. We have selected<br>nine such customers for Sunshine Company, their reviews are in the appendix.</p>
<ul>
<li>One-star rating customer</li>
</ul>
<p>our products or services may not meet the needs of all customers, so some of these customers give a one-star rating. Compared with five-star users who have very low-information reviews, these one-star rating users often directly mention the shortcomings of the product. So It is often helpful to look at these reviews<br>carefully.</p>
<p>we give the word cloud of one-star rating user of the microwave reviews below. There are words such as “service” and “warranty” in the word cloud. So we conclude that these users are dissatisfied with the product services and product warranty of the<br>microwave. In this way we can make specfic measures toward this issue. The word cloud of one-star rating users reviews by Pacifier and hair dryer is in the appendix. At the same time, we can find that users who give one star and users who give five stars tend to have more emotional reviews.</p>
<h1 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h1><p>Sunshine Company want to launch three new products in online marketplacemicrowave, pacifier and hair dryer. And they hire our team to help them to analyze the relevant products in the current market and make suggestions for their product sales.</p>
<p>At first,we process the dataset.We delete some data with missing values.At the same time,we find some data of click farmers.We also remove these useless data.We screen and integrate 15 attributes of the data set,leaving 11 basic attributes and 3 synthetic attributes.For a large number of texts in the review,we use the tokenization algorithm to cut the complex texts into simple words for our subsequent ananlysis.</p>
<p>Then,we analyze and visualize the attributes of the data set.In this way,we have a full understanding of the whole data set. We use the multi-demension evaluation system of “reviews evaluation products” and “helpful votes evaluation reviews”, through TF-IDF technology and MLP model to analyze the relationship between star rating, review and helpful votes,to help sunshine company to have a deeper understanding of products in the market.</p>
<p>Finally,on the basis of time ,we analyze the product heat,get a deeper understanding of customer review ,and provide a way for sunshine company to increase its products’popularity.</p>
<h1 id="Strenghths-and-Weaknesses"><a href="#Strenghths-and-Weaknesses" class="headerlink" title="Strenghths and Weaknesses"></a>Strenghths and Weaknesses</h1><h2 id="Strengths"><a href="#Strengths" class="headerlink" title="Strengths"></a>Strengths</h2><ul>
<li>Our model has strong interpretability</li>
</ul>
<p>The traditional MLP model has poor interpretability,and we continue to do lexical analysis and grammatical analysis on this basis, which enhances the interpretability of the whole model.</p>
<ul>
<li>We look at the product from the customer’s perspective</li>
</ul>
<p>We analyze the user’s emotion and build the user’s portrait through the user’s comments. At the same time, we find some customers who are meaningful to sunshine company.</p>
<h2 id="Weaknesses"><a href="#Weaknesses" class="headerlink" title="Weaknesses"></a>Weaknesses</h2><ul>
<li>There is a lack of analysis at the time level.</li>
</ul>
<p>At the time level, we only analyze the changes of product popularity, and there are a lot of contents that can be mined between time and review.</p>
<ul>
<li>We don’t build relationship among the three products.</li>
</ul>
<p>If our model can fully break the sales relationship among the three products in the market, it will be more helpful for sunshine company which sells the microwave, pacifier and hair dryer at the same time.</p>
<h1 id="Appendix-Product-Profile"><a href="#Appendix-Product-Profile" class="headerlink" title="Appendix: Product Profile"></a>Appendix: Product Profile</h1><center><img src="/eysblog_en/imgsource/mcm2020-figure-11.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 11: The Star Ratings and the Number of Reviews of Pacifier</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-12.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 12: The Proportion of People Who Were in Amazon Vine and People Who Had Bought the Product</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-13.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 13: The Wordcloud of Pacifier</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-14.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 14: The Reviews’ Total Votes and Helpful Votes of a Pacifier Product</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-15.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 15: The Star Ratings and the Number of Reviews of Pacifier</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-16.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 16: The Proportion of People Who Were in Amazon Vine and People Who Had Bought the Product</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-17.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 17: The Wordcloud of Pacifier</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-18.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 18: The Reviews’ Total Votes and Helpful Votes of a Pacifier Product</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-19.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 19: The WordCloud of Reviews with One Star about Pacifier</font></p></center>

<center><img src="/eysblog_en/imgsource/mcm2020-figure-20.png" alt="" width="70%"/>
<p><font size=3 color="black">Figure 20: The WordCloud of Reviews with One Star about Hair Dryer</font></p></center>]]></content>
      <categories>
        <category>Mathematical Modeling</category>
        <category>NLP (Natural Language Processing)</category>
      </categories>
  </entry>
  <entry>
    <title>Price Suggestion Challenge - A ML Algorithms Survey</title>
    <url>/201911/2019-11-12-price-prediction/</url>
    <content><![CDATA[<h1 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h1><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>Considering the number of products sold online, product pricing becomes more difficult at scale. Apparel has strong seasonal pricing trends and is heavily influenced by brands, while electronics prices fluctuate based on product specifications. It is a meaningful question to help merchants effectively sell their goods by making reasonable pricing based on past information.</p>
<h2 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h2><p>The product description, product category and brand information is given and combined with the product price from the training data to set the price for the new product. For example,</p>
<center><img src="/eysblog_en/imgsource/img-price-prediction/1-1.png" alt="" width="100%" /></center>

<p>Obviously Versace’s clothes should be much higher in price than Metersbonwe’s clothes, and in the description of the goods, you can find a slight difference between the two descriptions. </p>
<blockquote>
<p>This project aims to analyze the text information, extract the important information from the text information and derive the potential relationship with the price。 </p>
</blockquote>
<h2 id="Analysis-of-atributes"><a href="#Analysis-of-atributes" class="headerlink" title="Analysis of atributes"></a>Analysis of atributes</h2><center><img src="/eysblog_en/imgsource/img-price-prediction/1-2.png" alt="" width="100%" /></center>

<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><ul>
<li><code>train.csv</code> training dataset (Include <code>price</code>)</li>
<li><code>test.csv</code> test dataset (Not include <code>price</code>) ; <code>label_test.csv</code> (Corresponding to the price of the test dataset)</li>
<li><code>f_test.csv</code> Final measurement data set (Not include <code>price</code>)</li>
</ul>
<h2 id="Evaluation-Indicators"><a href="#Evaluation-Indicators" class="headerlink" title="Evaluation Indicators"></a>Evaluation Indicators</h2><p>We used <code>Mean Squared Logarithmic Error</code> (MSLE) to evaluate the algorithm: </p>
<script type="math/tex; mode=display">
MSLE = \cfrac{1}{n}\sum_{i=1}^n(log(p_i+1)-log(\alpha_i+1))^2
\tag{1}</script><p>Which \(n\) means the number of samples in test dataset; \(p_i\)means the predicting price of sales; \(\alpha_i\) means the real price.</p>
<h1 id="Data-Process"><a href="#Data-Process" class="headerlink" title="Data Process"></a>Data Process</h1><h2 id="Learning-sample-code"><a href="#Learning-sample-code" class="headerlink" title="Learning sample code"></a>Learning sample code</h2><p>The sample code given was first tried to understand the general idea of solving this problem. The main processes to solve this price prediction problem are: importing data and data exploration, data pre-processing, model construction, price prediction and measurement.</p>
<h3 id="import-data-and-exploration"><a href="#import-data-and-exploration" class="headerlink" title="import data and exploration"></a>import data and exploration</h3><p>Import the data and get acknowledge with it.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = pd.read_csv(<span class="string">&#x27;../data/4/train.csv&#x27;</span>, sep=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">&#x27;../data/4/test.csv&#x27;</span>,sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">train_data.info()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span><br><span class="line">RangeIndex: 300000 entries, 0 to 299999</span><br><span class="line">Data columns (total 8 columns):</span><br><span class="line">train_id             300000 non-null int64</span><br><span class="line">name                 300000 non-null object</span><br><span class="line">item_condition_id    300000 non-null int64</span><br><span class="line">category_name        298719 non-null object</span><br><span class="line">brand_name           171929 non-null object</span><br><span class="line">price                300000 non-null float64</span><br><span class="line">shipping             300000 non-null int64</span><br><span class="line">item_description     300000 non-null object</span><br><span class="line">dtypes: float64(1), int64(3), object(4)</span><br><span class="line">memory usage: 18.3+ MB</span><br></pre></td></tr></table></figure>
<h3 id="Data-Preprocess"><a href="#Data-Preprocess" class="headerlink" title="Data Preprocess"></a>Data Preprocess</h3><p>First of all, we need to remove <code>price</code> from the training data, and then remove <code>train_id</code> or <code>test_id</code> which are not useful. By looking at the data attributes above, we can see that <code>category_name</code> and <code>brand_name</code> have missing data, so the sample code is filled with <code>missing</code> directly.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">featureProcessing</span>(<span class="params">df</span>):</span><br><span class="line">    <span class="comment"># delete the data that will not be used</span></span><br><span class="line">    df = df.drop([<span class="string">&#x27;price&#x27;</span>, <span class="string">&#x27;test_id&#x27;</span>, <span class="string">&#x27;train_id&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># deal with the missing value with a default value</span></span><br><span class="line">    df[<span class="string">&#x27;category_name&#x27;</span>] = df[<span class="string">&#x27;category_name&#x27;</span>].fillna(<span class="string">&#x27;missing&#x27;</span>).astype(<span class="built_in">str</span>)</span><br><span class="line">    df[<span class="string">&#x27;brand_name&#x27;</span>] = df[<span class="string">&#x27;brand_name&#x27;</span>].fillna(<span class="string">&#x27;missing&#x27;</span>).astype(<span class="built_in">str</span>)</span><br><span class="line">    df[<span class="string">&#x27;item_description&#x27;</span>] = df[<span class="string">&#x27;item_description&#x27;</span>].fillna(<span class="string">&#x27;No&#x27;</span>)</span><br><span class="line">    <span class="comment"># convert the data : int -&gt; str</span></span><br><span class="line">    df[<span class="string">&#x27;shipping&#x27;</span>] = df[<span class="string">&#x27;shipping&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">    df[<span class="string">&#x27;item_condition_id&#x27;</span>] = df[<span class="string">&#x27;item_condition_id&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>
<h3 id="Model-Construction"><a href="#Model-Construction" class="headerlink" title="Model Construction"></a>Model Construction</h3><p>First of all, the input of the model is done and the matrix of word frequencies is generated by <code>CountVectorizer</code> and <code>TfidfVectorizer</code>. <code>Tfidf</code> is better because the number of occurrences of each word in all field clocks is taken into account and the generated word frequency matrix is weighted.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vectorizer = FeatureUnion([</span><br><span class="line">    (<span class="string">&#x27;name&#x27;</span>, CountVectorizer(ngram_range=(<span class="number">1</span>, <span class="number">2</span>), max_features=<span class="number">50000</span>, preprocessor=build_preprocessor_1(<span class="string">&#x27;name&#x27;</span>))),</span><br><span class="line">    (<span class="string">&#x27;category_name&#x27;</span>, CountVectorizer(token_pattern=<span class="string">&#x27;.+&#x27;</span>, preprocessor=build_preprocessor_1(<span class="string">&#x27;category_name&#x27;</span>))),</span><br><span class="line">    (<span class="string">&#x27;brand_name&#x27;</span>, CountVectorizer(token_pattern=<span class="string">&#x27;.+&#x27;</span>, preprocessor=build_preprocessor_1(<span class="string">&#x27;brand_name&#x27;</span>))),</span><br><span class="line">    (<span class="string">&#x27;shipping&#x27;</span>, CountVectorizer(token_pattern=<span class="string">&#x27;\d+&#x27;</span>, preprocessor=build_preprocessor_1(<span class="string">&#x27;shipping&#x27;</span>))),</span><br><span class="line">    (<span class="string">&#x27;item_condition_id&#x27;</span>, CountVectorizer(token_pattern=<span class="string">&#x27;\d+&#x27;</span>, preprocessor=build_preprocessor_1(<span class="string">&#x27;item_condition_id&#x27;</span>))),</span><br><span class="line">    (<span class="string">&#x27;item_description&#x27;</span>, TfidfVectorizer(ngram_range=(<span class="number">1</span>, <span class="number">3</span>),max_features=<span class="number">100000</span>, preprocessor=build_preprocessor_1(<span class="string">&#x27;item_description&#x27;</span>))),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>Predict the price by Ridge Regression.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ridgeClassify</span>(<span class="params">train_data, train_label</span>):</span><br><span class="line">    ridgeClf = Ridge(</span><br><span class="line">        solver=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">        fit_intercept=<span class="literal">True</span>,</span><br><span class="line">        alpha=<span class="number">0.5</span>,</span><br><span class="line">        max_iter=<span class="number">500</span>,</span><br><span class="line">        normalize=<span class="literal">False</span>,</span><br><span class="line">        tol=<span class="number">0.05</span>)</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    ridgeClf.fit(train_data, train_label)</span><br><span class="line">    <span class="keyword">return</span> ridgeClf</span><br></pre></td></tr></table></figure>
<p>By understanding the dataset and studying the sample code, we learned that there are three angles to start with to optimize the answer to this question.</p>
<ol>
<li>data preprocessing: How to handle missing values? How should the attributes be combined?</li>
<li>optimization when forming the word frequency matrix: adjusting the parameters of <code>CountVectorizer</code> and <code>TfidfVectorizer</code>.</li>
<li>Model selection and optimization: try models other than ridge regression, adjust model parameters.</li>
</ol>
<h2 id="Try-more-models"><a href="#Try-more-models" class="headerlink" title="Try more models"></a>Try more models</h2><p>In the sample code above, the result obtained using the ridge regression model is about 3.01. After the hints from the previous class and the online search, we are ready to try the <code>MLP</code> model and the <code>Lgmb</code> model again. After roughly trying both models, we decided to further optimize the model using <code>MLP</code>.</p>
<h3 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a><code>MLP</code></h3><p>The result of <code>MLP</code> is shown below:</p>
<center><img src="/eysblog_en/imgsource/img-price-prediction/2-2.png" alt="" width="100%" /></center>


<h3 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a><code>LGBM</code></h3><p>The result of  <code>Lgbm</code> is shown below: </p>
<center><img src="/eysblog_en/imgsource/img-price-prediction/2-1.png" alt="" width="100%" /></center>



<h3 id="MLP-Combined-with-LGBM"><a href="#MLP-Combined-with-LGBM" class="headerlink" title="MLP Combined with LGBM"></a><code>MLP</code> Combined with <code>LGBM</code></h3><p><1> Preprocessing</p>
<ul>
<li>Import the data</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&#x27;data/train.csv&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;data/test.csv&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"><span class="comment"># train and test data are handled together</span></span><br><span class="line">df = pd.concat([train, test], axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>Handling missing value</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Handling missing values</span></span><br><span class="line">   df[<span class="string">&#x27;category_name&#x27;</span>] = df[<span class="string">&#x27;category_name&#x27;</span>].fillna(<span class="string">&#x27;MISS&#x27;</span>).astype(<span class="built_in">str</span>)</span><br><span class="line">   df[<span class="string">&#x27;brand_name&#x27;</span>] = df[<span class="string">&#x27;brand_name&#x27;</span>].fillna(<span class="string">&#x27;missing&#x27;</span>).astype(<span class="built_in">str</span>)</span><br><span class="line">   df[<span class="string">&#x27;item_description&#x27;</span>] = df[<span class="string">&#x27;item_description&#x27;</span>].fillna(<span class="string">&#x27;No&#x27;</span>)</span><br><span class="line">   <span class="comment"># modifying data structure</span></span><br><span class="line">   df[<span class="string">&#x27;shipping&#x27;</span>] = df[<span class="string">&#x27;shipping&#x27;</span>].astype(<span class="built_in">str</span>)</span><br><span class="line">   df[<span class="string">&#x27;item_condition_id&#x27;</span>] = df[<span class="string">&#x27;item_condition_id&#x27;</span>].astype(<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>Feature vectorization</li>
</ul>
<p>Use the <code>CountVectorizer</code> class in the <code>sklearn</code> library to vectorize the text features and use <code>FeatureUnion</code> for feature union.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vectorizer = FeatureUnion([</span><br><span class="line">        (<span class="string">&#x27;name&#x27;</span>, CountVectorizer(</span><br><span class="line">            ngram_range=(<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            max_features=<span class="number">100000</span>,</span><br><span class="line">            preprocessor=build_preprocessor(<span class="string">&#x27;name&#x27;</span>))),</span><br><span class="line">        (<span class="string">&#x27;category_name&#x27;</span>, CountVectorizer(</span><br><span class="line">            token_pattern=<span class="string">&#x27;.+&#x27;</span>,</span><br><span class="line">            preprocessor=build_preprocessor(<span class="string">&#x27;category_name&#x27;</span>))),</span><br><span class="line">        (<span class="string">&#x27;brand_name&#x27;</span>, CountVectorizer(</span><br><span class="line">            token_pattern=<span class="string">&#x27;.+&#x27;</span>,</span><br><span class="line">            preprocessor=build_preprocessor(<span class="string">&#x27;brand_name&#x27;</span>))),</span><br><span class="line">        (<span class="string">&#x27;shipping&#x27;</span>, CountVectorizer(</span><br><span class="line">            token_pattern=<span class="string">&#x27;\d+&#x27;</span>,</span><br><span class="line">            preprocessor=build_preprocessor(<span class="string">&#x27;shipping&#x27;</span>))),</span><br><span class="line">        (<span class="string">&#x27;item_condition_id&#x27;</span>, CountVectorizer(</span><br><span class="line">            token_pattern=<span class="string">&#x27;\d+&#x27;</span>,</span><br><span class="line">            preprocessor=build_preprocessor(<span class="string">&#x27;item_condition_id&#x27;</span>))),</span><br><span class="line">        (<span class="string">&#x27;item_description&#x27;</span>, TfidfVectorizer(</span><br><span class="line">            ngram_range=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">            max_features=<span class="number">200000</span>,</span><br><span class="line">            preprocessor=build_preprocessor(<span class="string">&#x27;item_description&#x27;</span>),</span><br><span class="line">            stop_words=<span class="string">&#x27;english&#x27;</span>)),</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>
<p><2> Model Construction</p>
<p>The features were trained using the ridge regression model, the <code>Lgbm</code> model and the <code>mlp</code> model, respectively, and the solutions obtained in local tests were 3.01, 3.00, and 0.26, respectively.</p>
<ul>
<li>Ridge Regression</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ridge_classify</span>(<span class="params">train_data,train_label</span>):</span><br><span class="line">    <span class="comment">#model</span></span><br><span class="line">    model = Ridge(</span><br><span class="line">            solver=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">            fit_intercept=<span class="literal">True</span>,</span><br><span class="line">            alpha=<span class="number">0.4</span>,</span><br><span class="line">            max_iter=<span class="number">100</span>,</span><br><span class="line">            normalize=<span class="literal">False</span>,</span><br><span class="line">            tol=<span class="number">0.05</span>)</span><br><span class="line">    <span class="comment">#training</span></span><br><span class="line">    model.fit(train_data, train_label)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<ul>
<li><code>lgbm</code> Model</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lgbm_classify</span>(<span class="params">train_data,train_label</span>):</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.75</span>,</span><br><span class="line">        <span class="string">&#x27;application&#x27;</span>: <span class="string">&#x27;regression&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">3</span>,</span><br><span class="line">        <span class="string">&#x27;num_leaves&#x27;</span>: <span class="number">100</span>,</span><br><span class="line">        <span class="string">&#x27;verbosity&#x27;</span>: -<span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;metric&#x27;</span>: <span class="string">&#x27;RMSE&#x27;</span>,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    train_X, valid_X, train_y, valid_y = train_test_split(train_data, train_label, test_size=<span class="number">0.1</span>, random_state=<span class="number">144</span>)</span><br><span class="line">    d_train = lgb.Dataset(train_X, label=train_y)</span><br><span class="line">    d_valid = lgb.Dataset(valid_X, label=valid_y)</span><br><span class="line">    watchlist = [d_train, d_valid]</span><br><span class="line"></span><br><span class="line">    model = lgb.train(params, train_set=d_train, num_boost_round=<span class="number">2200</span>, valid_sets=watchlist, \</span><br><span class="line">                      early_stopping_rounds=<span class="number">50</span>, verbose_eval=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<ul>
<li><code>mlp</code> Model</li>
</ul>
<p>The <code>MLP</code> model consists of two fully connected layers and a dropout layer, which is essentially a network of multiple hidden layers.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mlp_model</span>(<span class="params">train_data,train_label,row_train</span>):</span><br><span class="line">    model = Sequential()</span><br><span class="line">    <span class="comment"># fully connected layer</span></span><br><span class="line">    model.add(Dense(<span class="number">64</span>, input_shape=(row_train,), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment"># DropOut layer</span></span><br><span class="line">    model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">    <span class="comment"># fully connected layer + classifier</span></span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_logarithmic_error&#x27;</span>,</span><br><span class="line">                  optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">                  )</span><br><span class="line"></span><br><span class="line">    model.fit(train_data, train_label,</span><br><span class="line">              batch_size=<span class="number">300</span>,</span><br><span class="line">              epochs=<span class="number">1</span>,</span><br><span class="line">              )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model.predict(X_test)</span><br></pre></td></tr></table></figure>
<h2 id="Optimization-when-forming-word-frequency-matrix"><a href="#Optimization-when-forming-word-frequency-matrix" class="headerlink" title="Optimization when forming word frequency matrix"></a>Optimization when forming word frequency matrix</h2><p>In the sample code we tried to replace all <code>CountVectorizer</code> with <code>TdidfVectorizer</code> and then use the Ridge model for prediction, but the result is not much optimized, only up to 2.9.<br>Later, when using the <code>MLP</code>, we completely discarded the <code>CountVectorizer</code> and used only the <code>TdidfVectorizer</code>.</p>
<h2 id="Optimize-the-data-pre-processing-process"><a href="#Optimize-the-data-pre-processing-process" class="headerlink" title="Optimize the data pre-processing process"></a>Optimize the data pre-processing process</h2><p>The way we optimize the <code>MLP</code>, which is basically perfected above, is to <strong>try different combinations of features</strong>.</p>
<h3 id="Analysis-of-the-attributes"><a href="#Analysis-of-the-attributes" class="headerlink" title="Analysis of the attributes"></a>Analysis of the attributes</h3><p>First I analyzed the attributes:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">item_condition_id    300000 non-null int64</span><br><span class="line">shipping             300000 non-null int64</span><br><span class="line"></span><br><span class="line">name                 300000 non-null object</span><br><span class="line">category_name        298719 non-null object</span><br><span class="line">brand_name           171929 non-null object</span><br><span class="line">item_description     300000 non-null object</span><br><span class="line"></span><br></pre></td></tr></table></figure><br><code>item_condition_id</code> and <code>shipping</code> are considered directly as inputs, while <code>name</code>, <code>category_name</code>, <code>brand_name</code>, <code>item_description</code> are considered for different combinations to try.</p>
<p>Before that, we found an example tutorial on data visualization to analyze the attributes of the data.<br>The optimal combination of inputs is obtained by observing the data.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<center><img src="/eysblog_en/imgsource/img-price-prediction/1-3.png" alt="" width="100%" /></center>

<ol>
<li><code>price</code><br>By looking at the data after visualization we know why we have to do <code>log1p</code> on <code>price</code> to make the distribution of <code>price</code> better.</li>
</ol>
<center><img src="/eysblog_en/imgsource/img-price-prediction/1-4.png" alt="" width="100%" /></center>

<ol>
<li><code>category_name</code><br>Try to split the property into various subclasses and view the corresponding data.</li>
</ol>
<center><img src="/eysblog_en/imgsource/img-price-prediction/1-5.png" alt="" width="100%" /></center>

<ol>
<li><code>item_description</code><center><img src="/eysblog_en/imgsource/img-price-prediction/1-6.png" alt="" width="100%" /></center>

</li>
</ol>
<h3 id="Try-different-attributes-combination"><a href="#Try-different-attributes-combination" class="headerlink" title="Try different attributes combination"></a>Try different attributes combination</h3><ol>
<li>simply combine the attributes together in the sample code for text analysis, i.e. <code>name</code> + <code>item_condition_id</code> + <code>category_name</code> + <code>brand_name</code> + <code>shipping</code> + <code>item_description</code>. (6 inputs)</li>
<li>try <code>name</code>, <code>item_condition_id</code>, <code>shipping</code>,<code>category_name</code> + <code>item_description</code>, <code>brand_name</code>. (5 inputs)</li>
<li>try <code>name</code>, <code>item_condition_id</code>, <code>shipping</code>, <code>category_name</code> + <code>brand_name</code> + <code>item_description</code>. (4 inputs)</li>
<li>try <code>name</code>, <code>item_condition_id</code>, <code>shipping</code>, <code>name</code> + <code>category_name</code> + <code>brand_name</code> + <code>item_description</code>. (4 inputs)</li>
</ol>
<p>The results for the four combinations as input are very similar, except that combination 1 <code>MSLE</code> is around 0.4, combinations 2 and 3 are around 0.21, and combination 4 eventually runs to around 0.17. Combination 4 actually increases the weight of <code>name</code> to make the final result better.</p>
<h1 id="Final-source-code-and-experimental-results"><a href="#Final-source-code-and-experimental-results" class="headerlink" title="Final source code and experimental results"></a>Final source code and experimental results</h1><ol>
<li><p>Data preprocessing</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># data preprocessing</span></span><br><span class="line"><span class="comment"># There are 8 attributes, remove price, train_id will have no influence on the result.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_preprocess</span>(<span class="params">df</span>):</span><br><span class="line">    df[<span class="string">&#x27;name&#x27;</span>] = df[<span class="string">&#x27;name&#x27;</span>].fillna(<span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27; &#x27;</span> + df[<span class="string">&#x27;brand_name&#x27;</span>].fillna(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    df[<span class="string">&#x27;text&#x27;</span>] = (df[<span class="string">&#x27;item_description&#x27;</span>].fillna(<span class="string">&#x27;&#x27;</span>) + <span class="string">&#x27; &#x27;</span> + df[<span class="string">&#x27;name&#x27;</span>] + <span class="string">&#x27; &#x27;</span> + df[<span class="string">&#x27;category_name&#x27;</span>].fillna(<span class="string">&#x27;&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> df[[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;shipping&#x27;</span>, <span class="string">&#x27;item_condition_id&#x27;</span>]]</span><br></pre></td></tr></table></figure>
</li>
<li><p>Model Constructio</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit_predict</span>(<span class="params">xs, y_train</span>):</span><br><span class="line">    X_train, X_test = xs</span><br><span class="line">    <span class="comment"># Configure the operation method of tf.Session, such as gpu operation or cpu operation</span></span><br><span class="line">    config = tf.ConfigProto(</span><br><span class="line">        <span class="comment"># Set the number of threads for multiple operations in parallel</span></span><br><span class="line">        intra_op_parallelism_threads=<span class="number">1</span>, use_per_session_threads=<span class="number">1</span>, inter_op_parallelism_threads=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># Session provides the environment for Operation execution and Tensor evaluation.</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session(graph=tf.Graph(), config=config) <span class="keyword">as</span> sess, timer(<span class="string">&#x27;fit_predict&#x27;</span>):</span><br><span class="line">        ks.backend.set_session(sess)</span><br><span class="line">        model_in = ks.Input(shape=(X_train.shape[<span class="number">1</span>],), dtype=<span class="string">&#x27;float32&#x27;</span>, sparse=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># ks.layers.Dense means the dimension of output</span></span><br><span class="line">        <span class="comment"># Dense full connected layer, equals to add one layer directly.</span></span><br><span class="line">        <span class="comment"># activation is the activation function.</span></span><br><span class="line">        out = ks.layers.Dense(<span class="number">192</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(model_in)</span><br><span class="line">        out = ks.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(out)</span><br><span class="line">        out = ks.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(out)</span><br><span class="line">        out = ks.layers.Dense(<span class="number">1</span>)(out)</span><br><span class="line">        model = ks.Model(model_in, out)</span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=ks.optimizers.Adam(lr=<span class="number">3e-3</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            <span class="keyword">with</span> timer(<span class="string">f&#x27;epoch <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span>):</span><br><span class="line">                model.fit(x=X_train, y=y_train, batch_size=<span class="number">2</span> ** (<span class="number">11</span> + i), epochs=<span class="number">1</span>, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> model.predict(X_test)[:, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>Model training and prediction</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    vectorizer = make_union(<span class="comment"># Assemble all transformers into a FeatureUnion. n_jobs means it can be done simultaneously</span></span><br><span class="line">        <span class="comment"># FunctionTransformer implements a custom transformation with no input validation when validate=False</span></span><br><span class="line">        <span class="comment"># TfidfVectorizer function, consider only the words in the first max_feature bits by word frequency, token_pattern=&#x27;\w+&#x27; matches at least one word</span></span><br><span class="line">        make_pipeline(FunctionTransformer(itemgetter(<span class="string">&#x27;name&#x27;</span>), validate=<span class="literal">False</span>), TfidfVectorizer(max_features=<span class="number">100000</span>, token_pattern=<span class="string">&#x27;\w+&#x27;</span>)),</span><br><span class="line">        make_pipeline(FunctionTransformer(itemgetter(<span class="string">&#x27;text&#x27;</span>), validate=<span class="literal">False</span>), TfidfVectorizer(max_features=<span class="number">100000</span>, token_pattern=<span class="string">&#x27;\w+&#x27;</span>)),</span><br><span class="line">        make_pipeline(FunctionTransformer(itemgetter([<span class="string">&#x27;shipping&#x27;</span>, <span class="string">&#x27;item_condition_id&#x27;</span>]), validate=<span class="literal">False</span>),</span><br><span class="line">                      FunctionTransformer(to_records, validate=<span class="literal">False</span>), DictVectorizer()),</span><br><span class="line">        n_jobs=<span class="number">4</span>)</span><br><span class="line">    <span class="comment"># StandardScaler() performs data normalization. Save the parameters (mean, variance) from the training set directly using its object to transform the test set data.</span></span><br><span class="line">    y_scaler = StandardScaler()</span><br><span class="line">    <span class="comment"># The with statement is used when accessing resources to ensure that the necessary &quot;cleanup&quot; operations are performed to release resources regardless of exceptions during use, such as automatic closure of files after use, automatic acquisition and release of locks in threads, etc.</span></span><br><span class="line">    <span class="keyword">with</span> timer(<span class="string">&#x27;process train&#x27;</span>):</span><br><span class="line">        train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        test = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="comment"># remove &#x27;price&#x27;</span></span><br><span class="line">        train = train[train[<span class="string">&#x27;price&#x27;</span>] &gt; <span class="number">0</span>].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># normalization of price</span></span><br><span class="line">        y_train = y_scaler.fit_transform(np.log1p(train[<span class="string">&#x27;price&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">        X_train = vectorizer.fit_transform(data_preprocess(train)).astype(np.float32)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;X_train: <span class="subst">&#123;X_train.shape&#125;</span> of <span class="subst">&#123;X_train.dtype&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> timer(<span class="string">&#x27;process valid&#x27;</span>):</span><br><span class="line">        X_test = vectorizer.transform(data_preprocess(test)).astype(np.float32)</span><br><span class="line">    <span class="keyword">with</span> ThreadPool(processes=<span class="number">4</span>) <span class="keyword">as</span> pool:</span><br><span class="line">        Xb_train, Xb_test = [x.astype(np.<span class="built_in">bool</span>).astype(np.float32) <span class="keyword">for</span> x <span class="keyword">in</span> [X_train, X_test]]</span><br><span class="line">        xs = [[Xb_train, Xb_test], [X_train, X_test]] * <span class="number">2</span></span><br><span class="line">        <span class="comment"># prediction</span></span><br><span class="line">        y_pred = np.mean(pool.<span class="built_in">map</span>(partial(fit_predict, y_train=y_train), xs), axis=<span class="number">0</span>)</span><br><span class="line">    y_pred = np.expm1(y_scaler.inverse_transform(y_pred.reshape(-<span class="number">1</span>, <span class="number">1</span>))[:, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># print(type(y_pred))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Export prediction results to csv</span></span><br><span class="line">    test_id = np.array(<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(y_pred)))</span><br><span class="line">    dataframe = pd.DataFrame(&#123;<span class="string">&#x27;test_id&#x27;</span>: test_id, <span class="string">&#x27;price&#x27;</span>: y_pred&#125;)</span><br><span class="line">    dataframe.to_csv(<span class="string">&quot;res.csv&quot;</span>, index=<span class="literal">False</span>, sep=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(&#x27;Valid MSLE: &#123;:.4f&#125;&#x27;.format(mean_squared_log_error(valid[&#x27;price&#x27;], y_pred)))</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The final experimental result reached 0.179.</p>
<h1 id="Other-optimization-directions-in-the-MLP-model"><a href="#Other-optimization-directions-in-the-MLP-model" class="headerlink" title="Other optimization directions in the MLP model"></a>Other optimization directions in the <code>MLP</code> model</h1><ol>
<li>It can be observed that in the word cloud of <code>item_desciption</code>, there are words such as <code>shipping</code> and <code>free</code>, which may stand for free shipping and other meanings, and there is some duplication with the <code>shipping</code> attribute, and using it as a feature word to train the model will cause interference.</li>
<li>The information contained in a single keyword may not be comprehensive, and there may be great correlation between keywords.</li>
<li>In the final model <code>MLP</code> uses a four-layer perceptron, and the number of layers of the perceptron and the input size of each layer can be further tuned.</li>
</ol>
<h1 id="Experience"><a href="#Experience" class="headerlink" title="Experience"></a>Experience</h1><p>This experiment was very difficult and I didn’t know where to start.</p>
<p>After carefully studying the sample code given in the course and the content of data visualization and analysis, I got a preliminary understanding of both the dataset and the method of prediction.  </p>
<p>Since I was very unfamiliar with models such as <code>MLP</code> and <code>Lightgbm</code>, I started from the input point of view and experimented with the combination of different attributes to get the final and better results.  </p>
<p>In the following study, we should learn and understand the model more deeply, and try to create the model independently, instead of modifying other models that have been written.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1].<a href="https://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html">https://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html</a></p>
<p>[2].  <a href="https://github.com/pjankiewicz/mercari-solution">https://github.com/pjankiewicz/mercari-solution</a></p>
<p>[3].<a href="https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling">https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling</a></p>
<p>[4].<a href="https://wklchris.github.io/Py3-pandas.html#统计信息dfdescribe-svalue_counts--unique">https://wklchris.github.io/Py3-pandas.html#%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AFdfdescribe-svalue_counts—unique</a></p>
<p>[5].<a href="https://zh.wikipedia.org/wiki/多层感知器">https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8</a></p>
<p>[6].<a href="https://blog.csdn.net/weixin_39807102/article/details/81912566">https://blog.csdn.net/weixin_39807102/article/details/81912566</a></p>
<p>[7].<a href="https://github.com/maiwen/NLP">https://github.com/maiwen/NLP</a></p>
<p>[8]. <a href="https://zh.wikipedia.org/wiki/正则表达式">https://zh.wikipedia.org/wiki/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F</a></p>
<p>[9].<a href="https://blog.csdn.net/u012609509/article/details/72911564">https://blog.csdn.net/u012609509/article/details/72911564</a></p>
<p>[10]. <a href="https://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44823">https://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44823</a></p>
<p>[11]. <a href="https://qiita.com/kazuhirokomoda/items/1e9b7ebcacf264b2d814">https://qiita.com/kazuhirokomoda/items/1e9b7ebcacf264b2d814</a></p>
<p>[12]. <a href="https://www.jianshu.com/p/c532424541ad">https://www.jianshu.com/p/c532424541ad</a></p>
<p>[13]. <a href="https://www.jiqizhixin.com/articles/2017-11-13-7">https://www.jiqizhixin.com/articles/2017-11-13-7</a></p>
]]></content>
      <categories>
        <category>NLP (Natural Language Processing)</category>
      </categories>
  </entry>
  <entry>
    <title>Linux开发环境及应用作业1</title>
    <url>/201911/Linux%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%BA%94%E7%94%A8%E4%BD%9C%E4%B8%9A%2020191031/</url>
    <content><![CDATA[<h2 id="作业要求"><a href="#作业要求" class="headerlink" title="作业要求"></a>作业要求</h2><p>从因特网上搜索相关Web网页，处理网页<code>html</code>数据，从中提取出当前时间点北京各监测站的 PM2.5浓度，输出格式如下。要求：写出各个处 理步骤，并给出解释。<br>2018-03-15 13:00:00,海淀区万柳,73<br>2018-03-15 13:00:00,昌平镇,67<br>2018-03-15 13:00:00,奥体中心,66<br>2018-03-15 14:00:00,海淀区万柳,73<br>2018-03-15 14:00:00,昌平镇,73<br>2018-03-15 14:00:00,奥体中心,75</p>
<span id="more"></span>
<h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><h3 id="数据搜集"><a href="#数据搜集" class="headerlink" title="数据搜集"></a>数据搜集</h3><p>北京各监测站的<code>PM2.5</code>指数的数据来源网站：<a href="http://www.86pm25.com/city/beijing.html">http://www.86pm25.com/city/beijing.html</a><br><img src="https://s2.ax1x.com/2019/10/31/K5rmkV.jpg" alt=""></p>
<h3 id="数据整理及汇总"><a href="#数据整理及汇总" class="headerlink" title="数据整理及汇总"></a>数据整理及汇总</h3><p>先展示实现该操作的指令和最后的结果：<br><img src="https://s2.ax1x.com/2019/10/31/K5rl6J.jpg" alt=""><br><img src="https://s2.ax1x.com/2019/10/31/K5rQl4.jpg" alt=""><br><img src="https://s2.ax1x.com/2019/10/31/K5rJTx.jpg" alt=""></p>
<p>下面详细解释指令：</p>
<ol>
<li>首先利用<tr>标签把数据分成单独的行，<code>sed -e &#39;s/&lt;tr/\n&lt;tr/g&#39;</code></li>
<li>其次删掉html文件中的所有标签<code>-e &#39;s/&lt;[^&lt;&gt;]*&gt;/ /g</code>，把所有标签都换成了空格。</li>
<li>我先在html文件中寻找日期和时间，发现时间的那一行有“更新”的字样，于是建立awk文件，此时发现“更新”后面中文的冒号紧跟着日期，没发把日期分离开，于是先在中文冒号后面添加空格。顺便把日期和时间的格式改成标准的输出的格式。<code>-e &#39;s/：/： /g&#39; -e &#39;s/[年月]/-/g&#39; -e &#39;s/日//g -e &#39;s/时/:00:00/g&#39;</code><br><img src="https://s2.ax1x.com/2019/10/31/K5rrnA.jpg" alt=""></li>
<li>此时可以把时间和日期抽离出来了。在建立的awk文件中输入<code>/更新/ &#123;data = $2; time = $3&#125;</code></li>
<li>得到日期和时间 之后，我们去找监测站和pm2.5指数，发现在这些数据最后都有$m^3$单位在，于是在awk文件中添加<code>/m3/&#123;printf(&quot;%s %s,%s,%s\n&quot;,date, time, $1, $3);&#125;</code><br><img src="https://s2.ax1x.com/2019/10/31/K5rs0I.jpg" alt=""></li>
<li>最后把单位删掉，并输出到csv文件中即可。<code>awk -f flow.awk | sed -e &#39;s/[ug/m3]//g&#39; &gt; flow.csv</code></li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络前向传播和反向传播算法推导</title>
    <url>/201911/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BD%9C%E4%B8%9A%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<h2 id="一、目标"><a href="#一、目标" class="headerlink" title="一、目标"></a>一、目标</h2><ol>
<li>推导具有单隐层的神经网络的前向传播和反向传播算法，并进行编程（可以使用<code>sklearn</code>中的神经网络）。<ul>
<li>探讨10，30，100，300，1000，不同隐藏节点数对网络性能的影响。</li>
<li>探讨不同学习率和迭代次数对网络性能的影响。</li>
<li>改变数据的标准化方法，探讨对训练的影响。</li>
</ul>
</li>
<li>查阅资料说明什么是<code>Hebb</code>学习规则</li>
</ol>
<span id="more"></span>
<h2 id="二、推导单隐层神经网络的前向传播和反向传播算法"><a href="#二、推导单隐层神经网络的前向传播和反向传播算法" class="headerlink" title="二、推导单隐层神经网络的前向传播和反向传播算法"></a>二、推导单隐层神经网络的前向传播和反向传播算法</h2><p>参考资料：<a href="https://blog.csdn.net/Lucky_Go/article/details/89738286">https://blog.csdn.net/Lucky_Go/article/details/89738286</a><br><img src="image4\reduction1.jpg" alt=""><br><img src="image4\reduction2.jpg" alt=""><br><img src="image4\reduction3.jpg" alt=""><br><img src="image4\reduction4.jpg" alt=""></p>
<h2 id="三、算法实现"><a href="#三、算法实现" class="headerlink" title="三、算法实现"></a>三、算法实现</h2><p>参考资料：<a href="https://blog.csdn.net/zsx17/article/details/89342506">https://blog.csdn.net/zsx17/article/details/89342506</a></p>
<p>因为网上神经网络的代码基本都是用<code>tensorflow</code>实现的，这里是直接调库。在完成了作业的基本要求之后我也尝试了自己实现单隐层神经网络的代码（在实验报告的后部分）。</p>
<h3 id="1-载入数据"><a href="#1-载入数据" class="headerlink" title="1. 载入数据"></a>1. 载入数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1、载入数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取mnist数据</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&#x27;MNIST_data/&#x27;</span>, one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-建立模型"><a href="#2-建立模型" class="headerlink" title="2. 建立模型"></a>2. 建立模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2.建立模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.1 构建输入层</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 构建隐藏层</span></span><br><span class="line"><span class="comment"># 隐藏层神经元数量(随意设置）</span></span><br><span class="line">H1_NN = <span class="number">256</span></span><br><span class="line"><span class="comment"># 权重</span></span><br><span class="line">W1 = tf.Variable(tf.random_normal([<span class="number">784</span>, H1_NN]))</span><br><span class="line"><span class="comment"># 偏置项</span></span><br><span class="line">b1 = tf.Variable(tf.zeros([H1_NN]))</span><br><span class="line"></span><br><span class="line">Y1 = tf.nn.relu(tf.matmul(x, W1) + b1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.3 构建输出层</span></span><br><span class="line">W2 = tf.Variable(tf.random_normal([H1_NN, <span class="number">10</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line">forward = tf.matmul(Y1, W2) + b2</span><br><span class="line">pred = tf.nn.softmax(forward)</span><br></pre></td></tr></table></figure>
<h3 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3. 训练模型"></a>3. 训练模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3.训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.1 定义损失函数</span></span><br><span class="line"><span class="comment"># tensorflow提供了下面的函数，用于避免log(0)值为Nan造成数据不稳定</span></span><br><span class="line">loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))</span><br><span class="line"><span class="comment"># # 交叉熵损失函数</span></span><br><span class="line"><span class="comment"># loss_function = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 设置训练参数</span></span><br><span class="line">train_epochs = <span class="number">40</span>  <span class="comment"># 训练轮数</span></span><br><span class="line">batch_size = <span class="number">50</span>  <span class="comment"># 单次训练样本数(批次大小)</span></span><br><span class="line"><span class="comment"># 一轮训练的批次数</span></span><br><span class="line">total_batch = <span class="built_in">int</span>(mnist.train.num_examples / batch_size)</span><br><span class="line">display_step = <span class="number">1</span>  <span class="comment"># 显示粒数</span></span><br><span class="line">learning_rate = <span class="number">0.01</span>  <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 选择优化器</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.3定义准确率</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(pred, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.4 模型的训练</span></span><br><span class="line"><span class="comment"># 记录训练开始的时间</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">startTime = time()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(train_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> <span class="built_in">range</span>(total_batch):</span><br><span class="line">        <span class="comment"># 读取批次训练数据</span></span><br><span class="line">        xs, ys = mnist.train.next_batch(batch_size)</span><br><span class="line">        <span class="comment"># 执行批次训练</span></span><br><span class="line">        sess.run(optimizer, feed_dict=&#123;x: xs, y: ys&#125;)</span><br><span class="line">    <span class="comment"># 在total_batch批次数据训练完成后，使用验证数据计算误差和准确率，验证集不分批</span></span><br><span class="line">    loss, acc = sess.run([loss_function, accuracy], feed_dict=&#123;x: mnist.validation.images, y: mnist.validation.labels&#125;)</span><br><span class="line">    <span class="comment"># 打印训练过程中的详细信息</span></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;训练轮次：&#x27;</span>, <span class="string">&#x27;%02d&#x27;</span> % (epoch + <span class="number">1</span>),</span><br><span class="line">              <span class="string">&#x27;损失：&#x27;</span>, <span class="string">&#x27;&#123;:.9f&#125;&#x27;</span>.<span class="built_in">format</span>(loss),</span><br><span class="line">              <span class="string">&#x27;准确率：&#x27;</span>, <span class="string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(acc))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练结束&#x27;</span>)</span><br><span class="line"><span class="comment"># 显示总运行时间</span></span><br><span class="line">duration = time() - startTime</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;总运行时间为：&quot;</span>, <span class="string">&quot;&#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(duration))</span><br></pre></td></tr></table></figure>
<h3 id="4-模型评估"><a href="#4-模型评估" class="headerlink" title="4. 模型评估"></a>4. 模型评估</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 4.评估模型</span></span><br><span class="line">accu_test = sess.run(accuracy,</span><br><span class="line">                     feed_dict=&#123;x: mnist.test.images, y: mnist.test.labels&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试集准确率：&#x27;</span>, accu_test)</span><br></pre></td></tr></table></figure>
<h3 id="5-应用模型"><a href="#5-应用模型" class="headerlink" title="5. 应用模型"></a>5. 应用模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 5.应用模型</span></span><br><span class="line">prediction_result = sess.run(tf.argmax(pred, <span class="number">1</span>), feed_dict=&#123;x: mnist.test.images&#125;)</span><br><span class="line"><span class="comment"># 查看预测结果的前10项</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前10项的结果：&quot;</span>, prediction_result[<span class="number">0</span>:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.1找出预测错误的样本</span></span><br><span class="line">compare_lists = prediction_result == np.argmax(mnist.test.labels, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(compare_lists)</span><br><span class="line">err_lists = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(compare_lists)) <span class="keyword">if</span> compare_lists[i] == <span class="literal">False</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测错误的图片：&#x27;</span>, err_lists)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;预测错误图片的总数：&#x27;</span>, <span class="built_in">len</span>(err_lists))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个输出错误分类的函数</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_predict_errs</span>(<span class="params">labels,  <span class="comment"># 标签列表</span></span></span><br><span class="line"><span class="params">                       prediction</span>):  <span class="comment"># 预测值列表</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    compare_lists = (prediction == np.argmax(labels, <span class="number">1</span>))</span><br><span class="line">    err_lists = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(compare_lists)) <span class="keyword">if</span> compare_lists[i] == <span class="literal">False</span>]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> err_lists:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;index=&#x27;</span> + <span class="built_in">str</span>(x) + <span class="string">&#x27;标签值=&#x27;</span>, np.argmax(labels[x]), <span class="string">&#x27;预测值=&#x27;</span>, prediction[x])</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;总计：&quot;</span> + <span class="built_in">str</span>(count))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print_predict_errs(labels=mnist.test.labels, prediction=prediction_result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_images_labels_prediction</span>(<span class="params">images,  <span class="comment"># 图像列表</span></span></span><br><span class="line"><span class="params">                                  labels,  <span class="comment"># 标签列表</span></span></span><br><span class="line"><span class="params">                                  predication,  <span class="comment"># 预测值列表</span></span></span><br><span class="line"><span class="params">                                  index,  <span class="comment"># 从第index个开始显示</span></span></span><br><span class="line"><span class="params">                                  num=<span class="number">10</span></span>):  <span class="comment"># 缺省一次显示10幅</span></span><br><span class="line">    fig = plt.gcf()  <span class="comment"># 获取当前图表，get current figure</span></span><br><span class="line">    fig.set_size_inches(<span class="number">10</span>, <span class="number">12</span>)  <span class="comment"># 设为英寸，1英寸=2.53厘米</span></span><br><span class="line">    <span class="keyword">if</span> num &gt; <span class="number">25</span>:</span><br><span class="line">        num = <span class="number">25</span>  <span class="comment"># 最多显示25个子图</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num):</span><br><span class="line">        ax = plt.subplot(<span class="number">5</span>, <span class="number">5</span>, i + <span class="number">1</span>)  <span class="comment"># 获取当前要处理的子图</span></span><br><span class="line">        <span class="comment"># 显示第index图像</span></span><br><span class="line">        ax.imshow(np.reshape(images[index], (<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建该图上显示的title</span></span><br><span class="line">        title = <span class="string">&#x27;label=&#x27;</span> + <span class="built_in">str</span>(np.argmax(labels[index]))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(predication) &gt; <span class="number">0</span>:</span><br><span class="line">            title += <span class="string">&quot;,predict=&quot;</span> + <span class="built_in">str</span>(predication[index])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示图上的title信息</span></span><br><span class="line">        ax.set_title(title, fontsize=<span class="number">10</span>)</span><br><span class="line">        ax.set_xticks([])  <span class="comment"># 不显示坐标轴</span></span><br><span class="line">        ax.set_yticks([])</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot_images_labels_prediction(mnist.test.images,</span><br><span class="line">                              mnist.test.labels,</span><br><span class="line">                              prediction_result, <span class="number">10</span>, <span class="number">25</span>)</span><br><span class="line">plot_images_labels_prediction(mnist.test.images,</span><br><span class="line">                              mnist.test.labels,</span><br><span class="line">                              prediction_result, <span class="number">610</span>, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<h3 id="6-结果展示"><a href="#6-结果展示" class="headerlink" title="6. 结果展示"></a>6. 结果展示</h3><p>上面的代码中隐层节点个数为256个，学习率为0.01，迭代次数为40次。训练结果如下：</p>
<p><img src="image4\256-0.01-40.jpg" alt=""></p>
<p>部分分类图像如下所示：</p>
<p><img src="image4\256-0.01-40-1.jpg" alt=""></p>
<p><img src="image4\256-0.01-40-2.jpg" alt=""></p>
<h2 id="四、算法调优"><a href="#四、算法调优" class="headerlink" title="四、算法调优"></a>四、算法调优</h2><p>在上面的模型中隐层结点数为256，学习率为0.01，迭代次数为40次。</p>
<p>下面分别从隐层节点数、学习率和迭代次数三个角度进行调优。</p>
<h3 id="1-隐层节点数"><a href="#1-隐层节点数" class="headerlink" title="1. 隐层节点数"></a>1. 隐层节点数</h3><p>将隐层节点数设为10，得到的结果如下图所示：</p>
<p><img src="image4\10-0.01-40.jpg" alt=""></p>
<p>将隐层节点设为30，100，300，1000的效果不再具体展示，效果如下所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">隐层节点个数</th>
<th style="text-align:center">总运行时间/s</th>
<th style="text-align:center">预测错误的图片数</th>
<th style="text-align:center">准确率</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center">46.29</td>
<td style="text-align:center">736</td>
<td style="text-align:center">0.9264</td>
</tr>
<tr>
<td style="text-align:center">30</td>
<td style="text-align:center">43.46</td>
<td style="text-align:center">528</td>
<td style="text-align:center">0.9472</td>
</tr>
<tr>
<td style="text-align:center">100</td>
<td style="text-align:center">59.06</td>
<td style="text-align:center">343</td>
<td style="text-align:center">0.9657</td>
</tr>
<tr>
<td style="text-align:center">256</td>
<td style="text-align:center">84.48</td>
<td style="text-align:center">249</td>
<td style="text-align:center">0.9751</td>
</tr>
<tr>
<td style="text-align:center">300</td>
<td style="text-align:center">76.64</td>
<td style="text-align:center">269</td>
<td style="text-align:center">0.9731</td>
</tr>
<tr>
<td style="text-align:center">1000</td>
<td style="text-align:center">302.27</td>
<td style="text-align:center">240</td>
<td style="text-align:center">0.976</td>
</tr>
</tbody>
</table>
</div>
<p>由表可知，准确率随着隐层节点个数的增加而增加，增加速率逐步减少。</p>
<h3 id="2-学习率"><a href="#2-学习率" class="headerlink" title="2. 学习率"></a>2. 学习率</h3><p>学习率分别为0.005，0.01， 0.02， 0.1，隐层节点数选择256，迭代次数选择40。分类结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">学习率</th>
<th style="text-align:center">总运行时间/s</th>
<th style="text-align:center">预测错误的图片数</th>
<th style="text-align:center">准确率</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0.005</td>
<td style="text-align:center">78.81</td>
<td style="text-align:center">231</td>
<td style="text-align:center">0.9769</td>
</tr>
<tr>
<td style="text-align:center">0.01</td>
<td style="text-align:center">84.48</td>
<td style="text-align:center">249</td>
<td style="text-align:center">0.9751</td>
</tr>
<tr>
<td style="text-align:center">0.02</td>
<td style="text-align:center">69.72</td>
<td style="text-align:center">446</td>
<td style="text-align:center">0.9554</td>
</tr>
<tr>
<td style="text-align:center">0.1</td>
<td style="text-align:center">73.87</td>
<td style="text-align:center">2561</td>
<td style="text-align:center">0.7439</td>
</tr>
</tbody>
</table>
</div>
<p>由表可知，准确率随着学习率的增加而降低。在学习率低于0.01时，图片分类的准确率提升的速率较小。</p>
<h3 id="3-迭代次数"><a href="#3-迭代次数" class="headerlink" title="3. 迭代次数"></a>3. 迭代次数</h3><p>迭代次数分别为20，40，100，隐层节点数选择256，学习率选择0.01。分类结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">迭代次数</th>
<th style="text-align:center">总运行时间/s</th>
<th style="text-align:center">预测错误的图片数</th>
<th style="text-align:center">准确率</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">20</td>
<td style="text-align:center">37.12</td>
<td style="text-align:center">307</td>
<td style="text-align:center">0.9693</td>
</tr>
<tr>
<td style="text-align:center">40</td>
<td style="text-align:center">84.48</td>
<td style="text-align:center">249</td>
<td style="text-align:center">0.9751</td>
</tr>
<tr>
<td style="text-align:center">100</td>
<td style="text-align:center">184.39</td>
<td style="text-align:center">239</td>
<td style="text-align:center">0.9761</td>
</tr>
</tbody>
</table>
</div>
<p>由表可知，迭代次数对总运行时间的影响率很大，准确率随着迭代次数的增加而增加，但对准确率起决定因素的还是隐层的节点个数以及学习率。</p>
<h3 id="4-改变数据标准化方法"><a href="#4-改变数据标准化方法" class="headerlink" title="4. 改变数据标准化方法"></a>4. 改变数据标准化方法</h3><h4 id="最大-最小规范化"><a href="#最大-最小规范化" class="headerlink" title="最大-最小规范化"></a>最大-最小规范化</h4><h4 id="Z-score规范化"><a href="#Z-score规范化" class="headerlink" title="Z-score规范化"></a><code>Z-score</code>规范化</h4><h2 id="五、Hebb学习规则"><a href="#五、Hebb学习规则" class="headerlink" title="五、Hebb学习规则"></a>五、<code>Hebb</code>学习规则</h2><p>参考资料：<a href="https://baike.baidu.com/item/Hebb学习规则/3061563?fr=aladdin">https://baike.baidu.com/item/Hebb%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%99/3061563?fr=aladdin</a></p>
<p><code>Hebb</code>学习规则是一个无监督学习规则，这种学习的结果是使网络能够提取训练集的统计特性，从而把输入信息按照它们的相似性程度划分为若干类。这一点与人类观察和认识世界的过程非常吻合，人类观察和认识世界在相当程度上就是在根据事物的统计特征进行分类。<code>Hebb</code>学习规则只根据神经元连接间的激活水平改变权值，因此这种方法又称为相关学习或并联学习。</p>
<p>无监督学习规则<br> 唐纳德·赫布（1904-1985）是加拿大著名生理心理学家。<code>Hebb</code>学习规则与“条件反射”机理一致，并且已经得到了神经细胞学说的证实。<br> 巴甫洛夫的条件反射实验：每次给狗喂食前都先响铃，时间一长，狗就会将铃声和食物联系起来。以后如果响铃但是不给食物，狗也会流口水。<br> 受该实验的启发，Hebb的理论认为在同一时间被激发的神经元间的联系会被强化。比如，铃声响时一个神经元被激发，在同一时间食物的出现会激发附近的另一个神经元，那么这两个神经元间的联系就会强化，从而记住这两个事物之间存在着联系。相反，如果两个神经元总是不能同步激发，那么它们间的联系将会越来越弱。<br> <code>Hebb</code>学习律可表示为：<br>$W<em>{ij}(t+1)=W</em>{ij}(t)+a⋅y<em>i⋅y_j$<br>$W</em>{ij}(t+1)=W_{ij}(t)+a⋅y_i⋅y_j$</p>
<p> 其中$W<em>{ij}$表示神经元$j$到神经元$i$的连接权，$y_i$与$y_j$表示两个神经元的输出，$a$是表示学习速率的常数，如果$y_i$与$y_j$同时被激活，即$y_i$与$y_j$同时为正，那么$W</em>{ij}$将增大。如果$y<em>i$被激活，而$y_j$处于抑制状态，即$y_i$为正$y_j$为负，那么$W</em>{ij}$将变小。</p>
<p><img src="https://images2015.cnblogs.com/blog/520787/201510/520787-20151021081107630-1544768706.png" alt=""></p>
<h2 id="六、-自己实现单隐层神经网络"><a href="#六、-自己实现单隐层神经网络" class="headerlink" title="六、 自己实现单隐层神经网络"></a>六、 自己实现单隐层神经网络</h2><p>参考资料：<a href="https://blog.csdn.net/hellozhxy/article/details/81055391">https://blog.csdn.net/hellozhxy/article/details/81055391</a></p>
<p>网络结构的函数定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">layer_sizes</span>(<span class="params">X, Y</span>):</span><br><span class="line">    n_x = X.shape[<span class="number">0</span>] <span class="comment"># size of input layer</span></span><br><span class="line">    n_h = <span class="number">4</span> <span class="comment"># size of hidden layer</span></span><br><span class="line">    n_y = Y.shape[<span class="number">0</span>] <span class="comment"># size of output layer</span></span><br><span class="line">    <span class="keyword">return</span> (n_x, n_h, n_y)</span><br></pre></td></tr></table></figure>
<p>参数初始化函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_parameters</span>(<span class="params">n_x, n_h, n_y</span>):</span><br><span class="line">    W1 = np.random.randn(n_h, n_x)*<span class="number">0.01</span></span><br><span class="line">    b1 = np.zeros((n_h, <span class="number">1</span>))</span><br><span class="line">    W2 = np.random.randn(n_y, n_h)*<span class="number">0.01</span></span><br><span class="line">    b2 = np.zeros((n_y, <span class="number">1</span>)) </span><br><span class="line">   </span><br><span class="line">    <span class="keyword">assert</span> (W1.shape == (n_h, n_x))    </span><br><span class="line">    <span class="keyword">assert</span> (b1.shape == (n_h, <span class="number">1</span>))    </span><br><span class="line">    <span class="keyword">assert</span> (W2.shape == (n_y, n_h))    </span><br><span class="line">    <span class="keyword">assert</span> (b2.shape == (n_y, <span class="number">1</span>))</span><br><span class="line">    parameters = &#123;<span class="string">&quot;W1&quot;</span>: W1, </span><br><span class="line">                  <span class="string">&quot;b1&quot;</span>: b1,                 </span><br><span class="line">                  <span class="string">&quot;W2&quot;</span>: W2,                  </span><br><span class="line">                  <span class="string">&quot;b2&quot;</span>: b2&#125;   </span><br><span class="line">                   </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<p>前向传播计算函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_propagation</span>(<span class="params">X, parameters</span>):</span><br><span class="line">    <span class="comment"># Retrieve each parameter from the dictionary &quot;parameters&quot;</span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]    </span><br><span class="line">    <span class="comment"># Implement Forward Propagation to calculate A2 (probabilities)</span></span><br><span class="line">    Z1 = np.dot(W1, X) + b1</span><br><span class="line">    A1 = np.tanh(Z1)</span><br><span class="line">    Z2 = np.dot(W2, Z1) + b2</span><br><span class="line">    A2 = sigmoid(Z2)    </span><br><span class="line">    <span class="keyword">assert</span>(A2.shape == (<span class="number">1</span>, X.shape[<span class="number">1</span>]))</span><br><span class="line">    cache = &#123;<span class="string">&quot;Z1&quot;</span>: Z1,                   </span><br><span class="line">             <span class="string">&quot;A1&quot;</span>: A1,                   </span><br><span class="line">             <span class="string">&quot;Z2&quot;</span>: Z2,                  </span><br><span class="line">             <span class="string">&quot;A2&quot;</span>: A2&#125;    </span><br><span class="line">    <span class="keyword">return</span> A2, cache</span><br></pre></td></tr></table></figure>
<p>计算损失函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_cost</span>(<span class="params">A2, Y, parameters</span>):</span><br><span class="line">    m = Y.shape[<span class="number">1</span>] <span class="comment"># number of example</span></span><br><span class="line">    <span class="comment"># Compute the cross-entropy cost</span></span><br><span class="line">    logprobs = np.multiply(np.log(A2),Y) + np.multiply(np.log(<span class="number">1</span>-A2), <span class="number">1</span>-Y)</span><br><span class="line">    cost = -<span class="number">1</span>/m * np.<span class="built_in">sum</span>(logprobs)</span><br><span class="line">    cost = np.squeeze(cost)     <span class="comment"># makes sure cost is the dimension we expect.</span></span><br><span class="line">    <span class="keyword">assert</span>(<span class="built_in">isinstance</span>(cost, <span class="built_in">float</span>))    </span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<p>反向传播函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">backward_propagation</span>(<span class="params">parameters, cache, X, Y</span>):</span><br><span class="line">    m = X.shape[<span class="number">1</span>]    </span><br><span class="line">    <span class="comment"># First, retrieve W1 and W2 from the dictionary &quot;parameters&quot;.</span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]    </span><br><span class="line">    <span class="comment"># Retrieve also A1 and A2 from dictionary &quot;cache&quot;.</span></span><br><span class="line">    A1 = cache[<span class="string">&#x27;A1&#x27;</span>]</span><br><span class="line">    A2 = cache[<span class="string">&#x27;A2&#x27;</span>]    </span><br><span class="line">    <span class="comment"># Backward propagation: calculate dW1, db1, dW2, db2. </span></span><br><span class="line">    dZ2 = A2-Y</span><br><span class="line">    dW2 = <span class="number">1</span>/m * np.dot(dZ2, A1.T)</span><br><span class="line">    db2 = <span class="number">1</span>/m * np.<span class="built_in">sum</span>(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    dZ1 = np.dot(W2.T, dZ2)*(<span class="number">1</span>-np.power(A1, <span class="number">2</span>))</span><br><span class="line">    dW1 = <span class="number">1</span>/m * np.dot(dZ1, X.T)</span><br><span class="line">    db1 = <span class="number">1</span>/m * np.<span class="built_in">sum</span>(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    grads = &#123;<span class="string">&quot;dW1&quot;</span>: dW1,</span><br><span class="line">             <span class="string">&quot;db1&quot;</span>: db1,                      </span><br><span class="line">             <span class="string">&quot;dW2&quot;</span>: dW2,             </span><br><span class="line">             <span class="string">&quot;db2&quot;</span>: db2&#125;   </span><br><span class="line">    <span class="keyword">return</span> grads</span><br></pre></td></tr></table></figure>
<p>权值更新函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update_parameters</span>(<span class="params">parameters, grads, learning_rate = <span class="number">1.2</span></span>):</span><br><span class="line">    <span class="comment"># Retrieve each parameter from the dictionary &quot;parameters&quot;</span></span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]    </span><br><span class="line">    <span class="comment"># Retrieve each gradient from the dictionary &quot;grads&quot;</span></span><br><span class="line">    dW1 = grads[<span class="string">&#x27;dW1&#x27;</span>]</span><br><span class="line">    db1 = grads[<span class="string">&#x27;db1&#x27;</span>]</span><br><span class="line">    dW2 = grads[<span class="string">&#x27;dW2&#x27;</span>]</span><br><span class="line">    db2 = grads[<span class="string">&#x27;db2&#x27;</span>]    </span><br><span class="line">    <span class="comment"># Update rule for each parameter</span></span><br><span class="line">    W1 -= dW1 * learning_rate</span><br><span class="line">    b1 -= db1 * learning_rate</span><br><span class="line">    W2 -= dW2 * learning_rate</span><br><span class="line">    b2 -= db2 * learning_rate</span><br><span class="line">    parameters = &#123;<span class="string">&quot;W1&quot;</span>: W1, </span><br><span class="line">                  <span class="string">&quot;b1&quot;</span>: b1,            </span><br><span class="line">                  <span class="string">&quot;W2&quot;</span>: W2,   </span><br><span class="line">                  <span class="string">&quot;b2&quot;</span>: b2&#125;    </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
<p>最终的神经网络模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nn_model</span>(<span class="params">X, Y, n_h, num_iterations = <span class="number">10000</span>, print_cost=<span class="literal">False</span></span>):</span><br><span class="line">    np.random.seed(<span class="number">3</span>)</span><br><span class="line">    n_x = layer_sizes(X, Y)[<span class="number">0</span>]</span><br><span class="line">    n_y = layer_sizes(X, Y)[<span class="number">2</span>]    </span><br><span class="line">    <span class="comment"># Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: &quot;n_x, n_h, n_y&quot;. Outputs = &quot;W1, b1, W2, b2, parameters&quot;.</span></span><br><span class="line">    parameters = initialize_parameters(n_x, n_h, n_y)</span><br><span class="line">    W1 = parameters[<span class="string">&#x27;W1&#x27;</span>]</span><br><span class="line">    b1 = parameters[<span class="string">&#x27;b1&#x27;</span>]</span><br><span class="line">    W2 = parameters[<span class="string">&#x27;W2&#x27;</span>]</span><br><span class="line">    b2 = parameters[<span class="string">&#x27;b2&#x27;</span>]    </span><br><span class="line">    <span class="comment"># Loop (gradient descent)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_iterations):        </span><br><span class="line">    <span class="comment"># Forward propagation. Inputs: &quot;X, parameters&quot;. Outputs: &quot;A2, cache&quot;.</span></span><br><span class="line">        A2, cache = forward_propagation(X, parameters)        </span><br><span class="line">        <span class="comment"># Cost function. Inputs: &quot;A2, Y, parameters&quot;. Outputs: &quot;cost&quot;.</span></span><br><span class="line">        cost = compute_cost(A2, Y, parameters)        </span><br><span class="line">        <span class="comment"># Backpropagation. Inputs: &quot;parameters, cache, X, Y&quot;. Outputs: &quot;grads&quot;.</span></span><br><span class="line">        grads = backward_propagation(parameters, cache, X, Y)        </span><br><span class="line">        <span class="comment"># Gradient descent parameter update. Inputs: &quot;parameters, grads&quot;. Outputs: &quot;parameters&quot;.</span></span><br><span class="line">        parameters = update_parameters(parameters, grads, learning_rate=<span class="number">1.2</span>)        </span><br><span class="line">        <span class="comment"># Print the cost every 1000 iterations</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">1000</span> == <span class="number">0</span>:            </span><br><span class="line">            <span class="built_in">print</span> (<span class="string">&quot;Cost after iteration %i: %f&quot;</span> %(i, cost))    </span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> parameters</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Finds算法和ID3算法</title>
    <url>/201910/FINDS%E7%AE%97%E6%B3%95%E5%92%8CID3%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="作业要求"><a href="#作业要求" class="headerlink" title="作业要求"></a>作业要求</h2><ol>
<li>实现<code>FINDS</code>算法</li>
<li>实现<code>ID3</code>算法</li>
</ol>
<ul>
<li>不要调库自己写。如果有能力可以继续用课件里的数据集测试两个算法（用天气的4条记录测试<code>FINDS</code>，用贷款的15条记录测试<code>ID3</code>）给出训练误差测试误差等；  </li>
<li>再有能力可以使用更大的数据集测试算法。</li>
</ul>
<span id="more"></span>
<h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><h3 id="FINDS算法"><a href="#FINDS算法" class="headerlink" title="FINDS算法"></a><code>FINDS</code>算法</h3><ol>
<li>目标：寻找极大特殊假设。</li>
<li>从假设集合H中最特殊的假设开始。在该假设不能正确地划分一个正例的时候将其进行一般化。算法如下：<br><img src="https://s2.ax1x.com/2019/10/22/K3ymOH.jpg" alt="算法流程"></li>
<li><code>FINDS</code>算法是一种利用<code>more-general-than</code>的偏序结构来搜索假设空间的方法，这一搜索沿着偏序链，从较特殊的假设逐渐演变为较一般的假设。</li>
<li>算法<code>Python</code>实现：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string"> Created on 2019/10/21 21:02</span></span><br><span class="line"><span class="string"> FINDS</span></span><br><span class="line"><span class="string"> @Author  : Zhouy</span></span><br><span class="line"><span class="string"> @Blog    : www.crocodilezs.top</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create dataset</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">CreateDataset</span>():</span><br><span class="line">    dataset = [[<span class="string">&#x27;Sunny&#x27;</span>, <span class="string">&#x27;Warm&#x27;</span>, <span class="string">&#x27;Normal&#x27;</span>, <span class="string">&#x27;Strong&#x27;</span>, <span class="string">&#x27;Warm&#x27;</span>, <span class="string">&#x27;Same&#x27;</span>, <span class="string">&#x27;Yes&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;Sunny&#x27;</span>, <span class="string">&#x27;Warm&#x27;</span>, <span class="string">&#x27;High&#x27;</span>, <span class="string">&#x27;Strong&#x27;</span>, <span class="string">&#x27;Warm&#x27;</span>, <span class="string">&#x27;Same&#x27;</span>, <span class="string">&#x27;Yes&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;Rainy&#x27;</span>, <span class="string">&#x27;Cold&#x27;</span>, <span class="string">&#x27;High&#x27;</span>, <span class="string">&#x27;Strong&#x27;</span>, <span class="string">&#x27;Warm&#x27;</span>, <span class="string">&#x27;Change&#x27;</span>, <span class="string">&#x27;No&#x27;</span>],</span><br><span class="line">               [<span class="string">&#x27;Sunny&#x27;</span>, <span class="string">&#x27;Warm&#x27;</span>, <span class="string">&#x27;High&#x27;</span>, <span class="string">&#x27;Strong&#x27;</span>, <span class="string">&#x27;Cold&#x27;</span>, <span class="string">&#x27;Change&#x27;</span>, <span class="string">&#x27;Yes&#x27;</span>]]</span><br><span class="line">    labels = [<span class="string">&#x27;Sky&#x27;</span>, <span class="string">&#x27;Temp&#x27;</span>, <span class="string">&#x27;Humidity&#x27;</span>, <span class="string">&#x27;Wind&#x27;</span>, <span class="string">&#x27;Water&#x27;</span>, <span class="string">&#x27;Forest&#x27;</span>, <span class="string">&#x27;OutdoorSport&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> dataset, labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find one version space by using FINDS</span></span><br><span class="line"><span class="comment"># &#x27;/&#x27; means null, and &#x27;*&#x27; means generalization</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">FINDS</span>(<span class="params">dataset</span>):</span><br><span class="line">    constraint = [<span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;/&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">        <span class="keyword">if</span> item[-<span class="number">1</span>] == <span class="string">&#x27;Yes&#x27;</span>:</span><br><span class="line">            <span class="comment"># only go through positive instances</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(item)-<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span>(item[i] != constraint[i] <span class="keyword">and</span> constraint[i] != <span class="string">&#x27;*&#x27;</span>):</span><br><span class="line">                    <span class="keyword">if</span>(constraint[i] == <span class="string">&#x27;/&#x27;</span>):</span><br><span class="line">                        constraint[i] = item[i]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        constraint[i] = <span class="string">&#x27;*&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> constraint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    dataset, labels = CreateDataset()</span><br><span class="line">    constraint = FINDS(dataset)</span><br><span class="line">    <span class="built_in">print</span>(constraint)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a><code>ID3</code>算法</h3><ol>
<li>决策树：决策树是一种常用的分类与回归方法。决策树的模型为树形结构，在针对分类问题时，实际上就是针对输入数据的各个特征对实例进行分类的过程，即通过树形结构的模型，在每一层级上对特征值进行判断，进而到达决策树叶子节点，即完成分类过程。<br><strong>决策树的本质是概念学习。</strong></li>
<li><p>信息熵（香浓熵）、条件熵和信息增益的概念</p>
<ul>
<li>信息量：一件事发生的概率越小，我们说它所蕴含的信息量越大。<br><img src="https://s2.ax1x.com/2019/10/22/K36VNq.jpg" alt="信息量"></li>
<li>信息熵：信息熵就是所有可能发生的事件的信息量的期望<br><img src="https://s2.ax1x.com/2019/10/22/K36EEn.jpg" alt="信息熵"></li>
<li>条件熵：表示在X给定条件下，Y的条件概率分布的熵对X的数学期望。<br>![条件熵(<a href="https://s2.ax1x.com/2019/10/22/K36FBj.jpg">https://s2.ax1x.com/2019/10/22/K36FBj.jpg</a>)</li>
<li>信息增益：当我们用另一个变量X对原变量Y分类后，原变量Y的不确定性就会减小了(即熵值减小)。而熵就是不确定性，不确定程度减少了多少其实就是信息增益。这就是信息增益的由来，所以信息增益定义如下：<br><img src="https://s2.ax1x.com/2019/10/22/K36kHs.jpg" alt="信息增益"></li>
</ul>
</li>
<li><p>算法’python’实现:<br>(用课件上的贷款数据集一直没法成功分类，于是参考了csdn博客的另一个数据集合代码)</p>
</li>
</ol>
<p><code>myTrees.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string"> Created on 2019/10/22 11:59</span></span><br><span class="line"><span class="string"> myTrees</span></span><br><span class="line"><span class="string"> @Author  : Zhouy</span></span><br><span class="line"><span class="string"> @Blog    : www.crocodilezs.top</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createDataSet</span>():</span><br><span class="line">    dataSet = [[<span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>]]</span><br><span class="line">    labels = [<span class="string">&#x27;no surfacing&#x27;</span>,<span class="string">&#x27;flippers&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多数表决器</span></span><br><span class="line"><span class="comment"># 列中相同值数量最多为结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">majorityCnt</span>(<span class="params">classList</span>):</span><br><span class="line">    classCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> (value <span class="keyword">not</span> <span class="keyword">in</span> classCounts.keys()):</span><br><span class="line">            classCounts[value] = <span class="number">0</span></span><br><span class="line">        classCounts[value] += <span class="number">1</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCounts.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line"><span class="comment"># dataSet:原始数据集</span></span><br><span class="line"><span class="comment"># axis:进行分割的指定列索引</span></span><br><span class="line"><span class="comment"># value:指定列中的值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitDataSet</span>(<span class="params">dataSet, axis, value</span>):</span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featDataVal <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featDataVal[axis] == value:</span><br><span class="line">            <span class="comment"># 下面两行去除某一项指定列的值，很巧妙有没有</span></span><br><span class="line">            reducedFeatVal = featDataVal[:axis]</span><br><span class="line">            reducedFeatVal.extend(featDataVal[axis + <span class="number">1</span>:])</span><br><span class="line">            retDataSet.append(reducedFeatVal)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算香农熵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcShannonEnt</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 数据集总项数</span></span><br><span class="line">    numEntries = <span class="built_in">len</span>(dataSet)</span><br><span class="line">    <span class="comment"># 标签计数对象初始化</span></span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featDataVal <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="comment"># 获取数据集每一项的最后一列的标签值</span></span><br><span class="line">        currentLabel = featDataVal[-<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 如果当前标签不在标签存储对象里，则初始化，然后计数</span></span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span></span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 熵初始化</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 遍历标签对象，求概率，计算熵</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">        prop = labelCounts[key] / <span class="built_in">float</span>(numEntries)</span><br><span class="line">        shannonEnt -= prop * log(prop, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选出最优特征列索引</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chooseBestFeatureToSplit</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 计算特征个数，dataSet最后一列是标签属性，不是特征量</span></span><br><span class="line">    numFeatures = <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计算初始数据香农熵</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)</span><br><span class="line">    <span class="comment"># 初始化信息增益，最优划分特征列索引</span></span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeatureIndex = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeatures):</span><br><span class="line">        <span class="comment"># 获取每一列数据</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        <span class="comment"># 将每一列数据去重</span></span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)</span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)</span><br><span class="line">            <span class="comment"># 计算条件概率</span></span><br><span class="line">            prob = <span class="built_in">len</span>(subDataSet) / <span class="built_in">float</span>(<span class="built_in">len</span>(dataSet))</span><br><span class="line">            <span class="comment"># 计算条件熵</span></span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line">        infoGain = baseEntropy - newEntropy</span><br><span class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeatureIndex = i</span><br><span class="line">    <span class="keyword">return</span> bestFeatureIndex</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 决策树创建</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet, labels</span>):</span><br><span class="line">    <span class="comment"># 获取标签属性，dataSet最后一列，区别于labels标签名称</span></span><br><span class="line">    classList = [example[-<span class="number">1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="comment"># 树极端终止条件判断</span></span><br><span class="line">    <span class="comment"># 标签属性值全部相同，返回标签属性第一项值</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == <span class="built_in">len</span>(classList):</span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 只有一个特征（1列）</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    <span class="comment"># 获取最优特征列索引</span></span><br><span class="line">    bestFeatureIndex = chooseBestFeatureToSplit(dataSet)</span><br><span class="line">    <span class="comment"># 获取最优索引对应的标签名称</span></span><br><span class="line">    bestFeatureLabel = labels[bestFeatureIndex]</span><br><span class="line">    <span class="comment"># 创建根节点</span></span><br><span class="line">    myTree = &#123;bestFeatureLabel: &#123;&#125;&#125;</span><br><span class="line">    <span class="comment"># 去除最优索引对应的标签名，使labels标签能正确遍历</span></span><br><span class="line">    <span class="keyword">del</span> (labels[bestFeatureIndex])</span><br><span class="line">    <span class="comment"># 获取最优列</span></span><br><span class="line">    bestFeature = [example[bestFeatureIndex] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniquesVals = <span class="built_in">set</span>(bestFeature)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniquesVals:</span><br><span class="line">        <span class="comment"># 子标签名称集合</span></span><br><span class="line">        subLabels = labels[:]</span><br><span class="line">        <span class="comment"># 递归</span></span><br><span class="line">        myTree[bestFeatureLabel][value] = createTree(splitDataSet(dataSet, bestFeatureIndex, value), subLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取分类结果</span></span><br><span class="line"><span class="comment"># inputTree:决策树字典</span></span><br><span class="line"><span class="comment"># featLabels:标签列表</span></span><br><span class="line"><span class="comment"># testVec:测试向量  例如：简单实例下某一路径 [1,1]  =&gt; yes（树干值组合，从根结点到叶子节点）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classify</span>(<span class="params">inputTree, featLabels, testVec</span>):</span><br><span class="line">    <span class="comment"># 获取根结点名称，将dict转化为list</span></span><br><span class="line">    firstSide = <span class="built_in">list</span>(inputTree.keys())</span><br><span class="line">    <span class="comment"># 根结点名称String类型</span></span><br><span class="line">    firstStr = firstSide[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 获取根结点对应的子节点</span></span><br><span class="line">    secondDict = inputTree[firstStr]</span><br><span class="line">    <span class="comment"># 获取根结点名称在标签列表中对应的索引</span></span><br><span class="line">    featIndex = featLabels.index(firstStr)</span><br><span class="line">    <span class="comment"># 由索引获取向量表中的对应值</span></span><br><span class="line">    key = testVec[featIndex]</span><br><span class="line">    <span class="comment"># 获取树干向量后的对象</span></span><br><span class="line">    valueOfFeat = secondDict[key]</span><br><span class="line">    <span class="comment"># 判断是子结点还是叶子节点：子结点就回调分类函数，叶子结点就是分类结果</span></span><br><span class="line">    <span class="comment"># if type(valueOfFeat).__name__==&#x27;dict&#x27;: 等价 if isinstance(valueOfFeat, dict):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(valueOfFeat, <span class="built_in">dict</span>):</span><br><span class="line">        classLabel = classify(valueOfFeat, featLabels, testVec)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        classLabel = valueOfFeat</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将决策树分类器存储在磁盘中，filename一般保存为txt格式</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">storeTree</span>(<span class="params">inputTree, filename</span>):</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    fw = <span class="built_in">open</span>(filename, <span class="string">&#x27;wb+&#x27;</span>)</span><br><span class="line">    pickle.dump(inputTree, fw)</span><br><span class="line">    fw.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将瓷盘中的对象加载出来，这里的filename就是上面函数中的txt文件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">grabTree</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    fr = <span class="built_in">open</span>(filename, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> pickle.load(fr)</span><br></pre></td></tr></table></figure>
<p><code>treePlotter.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string"> Created on 2019/10/22 12:00</span></span><br><span class="line"><span class="string"> treePlotter</span></span><br><span class="line"><span class="string"> @Author  : Zhouy</span></span><br><span class="line"><span class="string"> @Blog    : www.crocodilezs.top</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">decisionNode = <span class="built_in">dict</span>(boxstyle=<span class="string">&quot;sawtooth&quot;</span>, fc=<span class="string">&quot;0.8&quot;</span>)</span><br><span class="line">leafNode = <span class="built_in">dict</span>(boxstyle=<span class="string">&quot;round4&quot;</span>, fc=<span class="string">&quot;0.8&quot;</span>)</span><br><span class="line">arrow_args = <span class="built_in">dict</span>(arrowstyle=<span class="string">&quot;&lt;-&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取树的叶子节点</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getNumLeafs</span>(<span class="params">myTree</span>):</span><br><span class="line">    numLeafs = <span class="number">0</span></span><br><span class="line">    <span class="comment"># dict转化为list</span></span><br><span class="line">    firstSides = <span class="built_in">list</span>(myTree.keys())</span><br><span class="line">    firstStr = firstSides[<span class="number">0</span>]</span><br><span class="line">    secondDict = myTree[firstStr]</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="comment"># 判断是否是叶子节点（通过类型判断，子类不存在，则类型为str；子类存在，则为dict）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(secondDict[</span><br><span class="line">                    key]).__name__ == <span class="string">&#x27;dict&#x27;</span>:  <span class="comment"># test to see if the nodes are dictonaires, if not they are leaf nodes</span></span><br><span class="line">            numLeafs += getNumLeafs(secondDict[key])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            numLeafs += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> numLeafs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取树的层数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTreeDepth</span>(<span class="params">myTree</span>):</span><br><span class="line">    maxDepth = <span class="number">0</span></span><br><span class="line">    <span class="comment"># dict转化为list</span></span><br><span class="line">    firstSides = <span class="built_in">list</span>(myTree.keys())</span><br><span class="line">    firstStr = firstSides[<span class="number">0</span>]</span><br><span class="line">    secondDict = myTree[firstStr]</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(secondDict[</span><br><span class="line">                    key]).__name__ == <span class="string">&#x27;dict&#x27;</span>:  <span class="comment"># test to see if the nodes are dictonaires, if not they are leaf nodes</span></span><br><span class="line">            thisDepth = <span class="number">1</span> + getTreeDepth(secondDict[key])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            thisDepth = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> thisDepth &gt; maxDepth: maxDepth = thisDepth</span><br><span class="line">    <span class="keyword">return</span> maxDepth</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plotNode</span>(<span class="params">nodeTxt, centerPt, parentPt, nodeType</span>):</span><br><span class="line">    createPlot.ax1.annotate(nodeTxt, xy=parentPt, xycoords=<span class="string">&#x27;axes fraction&#x27;</span>,</span><br><span class="line">                            xytext=centerPt, textcoords=<span class="string">&#x27;axes fraction&#x27;</span>,</span><br><span class="line">                            va=<span class="string">&quot;center&quot;</span>, ha=<span class="string">&quot;center&quot;</span>, bbox=nodeType, arrowprops=arrow_args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plotMidText</span>(<span class="params">cntrPt, parentPt, txtString</span>):</span><br><span class="line">    xMid = (parentPt[<span class="number">0</span>] - cntrPt[<span class="number">0</span>]) / <span class="number">2.0</span> + cntrPt[<span class="number">0</span>]</span><br><span class="line">    yMid = (parentPt[<span class="number">1</span>] - cntrPt[<span class="number">1</span>]) / <span class="number">2.0</span> + cntrPt[<span class="number">1</span>]</span><br><span class="line">    createPlot.ax1.text(xMid, yMid, txtString, va=<span class="string">&quot;center&quot;</span>, ha=<span class="string">&quot;center&quot;</span>, rotation=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plotTree</span>(<span class="params">myTree, parentPt, nodeTxt</span>):  <span class="comment"># if the first key tells you what feat was split on</span></span><br><span class="line">    numLeafs = getNumLeafs(myTree)  <span class="comment"># this determines the x width of this tree</span></span><br><span class="line">    depth = getTreeDepth(myTree)</span><br><span class="line">    firstSides = <span class="built_in">list</span>(myTree.keys())</span><br><span class="line">    firstStr = firstSides[<span class="number">0</span>]  <span class="comment"># the text label for this node should be this</span></span><br><span class="line">    cntrPt = (plotTree.xOff + (<span class="number">1.0</span> + <span class="built_in">float</span>(numLeafs)) / <span class="number">2.0</span> / plotTree.totalW, plotTree.yOff)</span><br><span class="line">    plotMidText(cntrPt, parentPt, nodeTxt)</span><br><span class="line">    plotNode(firstStr, cntrPt, parentPt, decisionNode)</span><br><span class="line">    secondDict = myTree[firstStr]</span><br><span class="line">    plotTree.yOff = plotTree.yOff - <span class="number">1.0</span> / plotTree.totalD</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(secondDict[</span><br><span class="line">                    key]).__name__ == <span class="string">&#x27;dict&#x27;</span>:  <span class="comment"># test to see if the nodes are dictonaires, if not they are leaf nodes</span></span><br><span class="line">            plotTree(secondDict[key], cntrPt, <span class="built_in">str</span>(key))  <span class="comment"># recursion</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># it&#x27;s a leaf node print the leaf node</span></span><br><span class="line">            plotTree.xOff = plotTree.xOff + <span class="number">1.0</span> / plotTree.totalW</span><br><span class="line">            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)</span><br><span class="line">            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, <span class="built_in">str</span>(key))</span><br><span class="line">    plotTree.yOff = plotTree.yOff + <span class="number">1.0</span> / plotTree.totalD</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># if you do get a dictonary you know it&#x27;s a tree, and the first element will be another dict</span></span><br><span class="line"><span class="comment"># 绘制决策树</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createPlot</span>(<span class="params">inTree</span>):</span><br><span class="line">    fig = plt.figure(<span class="number">1</span>, facecolor=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">    fig.clf()</span><br><span class="line">    axprops = <span class="built_in">dict</span>(xticks=[], yticks=[])</span><br><span class="line">    createPlot.ax1 = plt.subplot(<span class="number">111</span>, frameon=<span class="literal">False</span>, **axprops)  <span class="comment"># no ticks</span></span><br><span class="line">    <span class="comment"># createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses</span></span><br><span class="line">    plotTree.totalW = <span class="built_in">float</span>(getNumLeafs(inTree))</span><br><span class="line">    plotTree.totalD = <span class="built_in">float</span>(getTreeDepth(inTree))</span><br><span class="line">    plotTree.xOff = -<span class="number">0.5</span> / plotTree.totalW</span><br><span class="line">    plotTree.yOff = <span class="number">1.0</span></span><br><span class="line">    plotTree(inTree, (<span class="number">0.5</span>, <span class="number">1.0</span>), <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制树的根节点和叶子节点（根节点形状：长方形，叶子节点：椭圆形）</span></span><br><span class="line"><span class="comment"># def createPlot():</span></span><br><span class="line"><span class="comment">#    fig = plt.figure(1, facecolor=&#x27;white&#x27;)</span></span><br><span class="line"><span class="comment">#    fig.clf()</span></span><br><span class="line"><span class="comment">#    createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses</span></span><br><span class="line"><span class="comment">#    plotNode(&#x27;a decision node&#x27;, (0.5, 0.1), (0.1, 0.5), decisionNode)</span></span><br><span class="line"><span class="comment">#    plotNode(&#x27;a leaf node&#x27;, (0.8, 0.1), (0.3, 0.8), leafNode)</span></span><br><span class="line"><span class="comment">#    plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">retrieveTree</span>(<span class="params">i</span>):</span><br><span class="line">    listOfTrees = [&#123;<span class="string">&#x27;no surfacing&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;no&#x27;</span>, <span class="number">1</span>: &#123;<span class="string">&#x27;flippers&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;no&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;yes&#x27;</span>&#125;&#125;&#125;&#125;,</span><br><span class="line">                   &#123;<span class="string">&#x27;no surfacing&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;no&#x27;</span>, <span class="number">1</span>: &#123;<span class="string">&#x27;flippers&#x27;</span>: &#123;<span class="number">0</span>: &#123;<span class="string">&#x27;head&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;no&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;yes&#x27;</span>&#125;&#125;, <span class="number">1</span>: <span class="string">&#x27;no&#x27;</span>&#125;&#125;&#125;&#125;</span><br><span class="line">                   ]</span><br><span class="line">    <span class="keyword">return</span> listOfTrees[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># thisTree = retrieveTree(0)</span></span><br><span class="line"><span class="comment"># createPlot(thisTree)</span></span><br><span class="line"><span class="comment"># createPlot()</span></span><br><span class="line"><span class="comment"># myTree = retrieveTree(0)</span></span><br><span class="line"><span class="comment"># numLeafs =getNumLeafs(myTree)</span></span><br><span class="line"><span class="comment"># treeDepth =getTreeDepth(myTree)</span></span><br><span class="line"><span class="comment"># print(u&quot;叶子节点数目：%d&quot;% numLeafs)</span></span><br><span class="line"><span class="comment"># print(u&quot;树深度：%d&quot;%treeDepth)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>testTrees_3.py</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string"> Created on 2019/10/22 12:00</span></span><br><span class="line"><span class="string"> testTrees_3</span></span><br><span class="line"><span class="string"> @Author  : Zhouy</span></span><br><span class="line"><span class="string"> @Blog    : www.crocodilezs.top</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> myTrees <span class="keyword">as</span> mt</span><br><span class="line"><span class="keyword">import</span> treePlotter <span class="keyword">as</span> tp</span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">dataSet, labels = mt.createDataSet()</span><br><span class="line"><span class="comment">#copy函数：新开辟一块内存，然后将list的所有值复制到新开辟的内存中</span></span><br><span class="line">labels1 = labels.copy()</span><br><span class="line"><span class="comment">#createTree函数中将labels1的值改变了，所以在分类测试时不能用labels1</span></span><br><span class="line">myTree = mt.createTree(dataSet,labels1)</span><br><span class="line"><span class="comment">#保存树到本地</span></span><br><span class="line">mt.storeTree(myTree,<span class="string">&#x27;myTree.txt&#x27;</span>)</span><br><span class="line"><span class="comment">#在本地磁盘获取树</span></span><br><span class="line">myTree = mt.grabTree(<span class="string">&#x27;myTree.txt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">u&quot;决策树结构：%s&quot;</span>%myTree)</span><br><span class="line"><span class="comment">#绘制决策树</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&quot;绘制决策树：&quot;</span>)</span><br><span class="line">tp.createPlot(myTree)</span><br><span class="line">numLeafs =tp.getNumLeafs(myTree)</span><br><span class="line">treeDepth =tp.getTreeDepth(myTree)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&quot;叶子节点数目：%d&quot;</span>% numLeafs)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&quot;树深度：%d&quot;</span>%treeDepth)</span><br><span class="line"><span class="comment">#测试分类 简单样本数据3列</span></span><br><span class="line">labelResult =mt.classify(myTree,labels,[<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&quot;[1,1] 测试结果为：%s&quot;</span>%labelResult)</span><br><span class="line">labelResult =mt.classify(myTree,labels,[<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&quot;[1,0] 测试结果为：%s&quot;</span>%labelResult)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>FindS</tag>
        <tag>ID3</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础实验一、Linux环境和GCC工具链</title>
    <url>/201910/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E4%B8%80/</url>
    <content><![CDATA[<h1 id="Linux操作系统概述和实验环境介绍"><a href="#Linux操作系统概述和实验环境介绍" class="headerlink" title="Linux操作系统概述和实验环境介绍"></a><code>Linux</code>操作系统概述和实验环境介绍</h1><h2 id="操作系统概念"><a href="#操作系统概念" class="headerlink" title="操作系统概念"></a>操作系统概念</h2><p><code>OS</code>是管理和控制计算机硬件与软件资源的计算机程序，是直接在“裸机”上的最基本的系统软件。</p>
<h2 id="Linux的应用"><a href="#Linux的应用" class="headerlink" title="Linux的应用"></a><code>Linux</code>的应用</h2><ol>
<li>服务器端：Linux非常稳定，特别适合大型企业生产环境。</li>
<li>作为网络平台的后端服务器被使用。</li>
<li>作为应用服务器、数据库服务器被使用：解决海量数据、高并发的问题；</li>
<li>作为嵌入式操作系统被使用：智能控制、自动化、物联网等领域。</li>
</ol>
<span id="more"></span>
<h2 id="Linux历史"><a href="#Linux历史" class="headerlink" title="Linux历史"></a><code>Linux</code>历史</h2><p>追溯到<code>UNIX</code><br>简单地说，<code>Linux</code>是对<code>UNIX</code>的重新实现。世界各地的<code>Linux</code>开发人员借鉴了<code>UNIX</code>的技术和用户界面，并且融入了很多独创的技术。<code>Linux</code>不属于<code>BSD</code>和<code>AT&amp;T</code>风格的<code>UNIX</code>中的任何一种。因此，严格来说，<code>Linux</code>是有别于<code>UNIX</code>的另一种操作系统。</p>
<h2 id="Linux简介"><a href="#Linux简介" class="headerlink" title="Linux简介"></a><code>Linux</code>简介</h2><p><code>Linux</code>发现行版本举例：<code>Ubuntu</code>、<code>redhat</code></p>
<h2 id="操作系统的三个部分"><a href="#操作系统的三个部分" class="headerlink" title="操作系统的三个部分"></a>操作系统的三个部分</h2><h3 id="内核"><a href="#内核" class="headerlink" title="内核"></a>内核</h3><p>操作系统五大管理功能一般都由操作系统内核负责。</p>
<h3 id="外壳"><a href="#外壳" class="headerlink" title="外壳"></a>外壳</h3><ul>
<li>外壳程序负责接收用户操作，提供与 用户的交互界面。</li>
<li>一般操作系统提供给用户的界面主要有两种：文本界面、<code>GUI</code>图形界面。<h3 id="管理工具和附属软件"><a href="#管理工具和附属软件" class="headerlink" title="管理工具和附属软件"></a>管理工具和附属软件</h3></li>
</ul>
<h2 id="操作系统的功能"><a href="#操作系统的功能" class="headerlink" title="操作系统的功能"></a>操作系统的功能</h2><ol>
<li><code>CPU</code>的控制与管理：处理器管理</li>
<li>内存的分配与管理：存储器管理</li>
<li>外部设备的控制与管理：设备管理</li>
<li>文件管理</li>
<li>作业管理和控制：用户接口</li>
</ol>
<h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a><code>Shell</code></h2><ol>
<li>外壳程序对用户的输入命令进行解释，为用户提供一种通过操作系统使用计算机的操作环境。</li>
<li><code>Windows</code>的图形界面，由一个成为<code>Explorer</code>的模块解释用户的输入。</li>
<li>如<code>DOS</code>的命令行界面，<code>Command.com</code>是对命令输入进行解释的外壳程序(<code>Linux</code>的<code>Shell</code>)</li>
<li>Shell命令：从命令行输入语句，每输入一次就能得到一次响应，这些语句就是<code>shell</code>命令。</li>
<li><code>Shell</code>程序：又称<code>Shell</code>脚本。（把一系列的<code>shell</code>命令，按照一定的语法规则和控制结构，组织在一个文件中，然后由内核来一条接一条地解释和执行这些命令，这个文件就是shell程序，类似<code>DOS</code>/<code>Winsows</code>中的。bat批处理文件。）</li>
<li>[username@computername ~]$<br>user name为当前用户名，computername 为当前计算机名 ，$表示当前用户是一般用户。 <h2 id="ssh-secure-shell"><a href="#ssh-secure-shell" class="headerlink" title="ssh secure shell"></a><code>ssh</code> secure shell</h2>把<code>Linux</code>终端搬到<code>Windows</code>下，连接到BUPT1.<h2 id="Shell常用命令"><a href="#Shell常用命令" class="headerlink" title="Shell常用命令"></a><code>Shell</code>常用命令</h2><h3 id="目录操作命令"><a href="#目录操作命令" class="headerlink" title="目录操作命令"></a>目录操作命令</h3>目录操作命令能够对当前的目录进行查看、创建、删除，以及显示当前工作目录和改变当前目录等操作。</li>
</ol>
<div note="class info">
    1. /etc - 系统所需的重要配置和管理文件<br />
    2. /dev - 存放device file（装置文件）<br />
    3. /boot - 存放系统激活的相关文件，不可任意删除。<br />
    4. /home - 登陆用户的主目录<br />
    5. /lib - 存放系统激活时需要的系统函数库<br />
    6. /usr/lib - 存放一些应用程序的共享函数库<br />
    7. /mnt - 系统默认的挂载点(mount point)
    8. /proc - 虚拟文件系统，不占用硬盘空间，目录下的文件均放置于内存中<br />
    9. /root - 系统管理用户root的主目录<br />
    10. /bin - 存放一些系统启动时所需的普通程序和系统程序<br />
    11. /tmp - 存放临时文件
    12. /var - 存放被系统修改过的数据。
</div>

<p>常用的目录操作命令包括：</p>
<ol>
<li>pwd 打印当前工作目录</li>
<li>cd 改变当前所在目录</li>
<li>ls 查看当前目录下的内容</li>
<li>dir 类似ls命令</li>
<li>mkdir 创建目录</li>
<li>rmdir 删除空目录</li>
</ol>
<h3 id="文件操作命令"><a href="#文件操作命令" class="headerlink" title="文件操作命令"></a>文件操作命令</h3><ul>
<li>在命令行环境下对文件进行操作将比在图形环境下操作文件更加快捷和高效</li>
<li>文件操作主要包括：搜索文件、复制和移动文件、删除文件以及合并文件内容</li>
</ul>
<p>常用文件操作命令：  </p>
<ul>
<li><code>cat</code>  </li>
<li><code>more</code>  </li>
<li><code>less</code>  </li>
<li><code>head</code></li>
<li><code>tail</code></li>
<li><code>cp</code></li>
<li><code>mv</code></li>
<li><code>rm</code></li>
<li><code>find</code></li>
<li><code>touch</code></li>
<li><code>ln</code></li>
</ul>
<h3 id="使用帮助命令"><a href="#使用帮助命令" class="headerlink" title="使用帮助命令"></a>使用帮助命令</h3><ol>
<li><code>man 命令名</code> </li>
<li><code>whatis 命令名</code>  </li>
<li><code>help 命令名</code>：适用于部分命令</li>
</ol>
<h2 id="Vi编辑器"><a href="#Vi编辑器" class="headerlink" title="Vi编辑器"></a>Vi编辑器</h2><h3 id="Vi简介"><a href="#Vi简介" class="headerlink" title="Vi简介"></a><code>Vi</code>简介</h3><ul>
<li><code>Vi</code>编辑器是<code>Visual interface</code>的简称，它可以执行输出、删除、查找、替换、块操作等众多文本操作</li>
<li><code>Vi</code>不是一个排版程序，只是一个文本编辑程序。</li>
<li>是全屏幕文本编辑器，没有菜单，只有命令。</li>
</ul>
<h3 id="Vi的基本概念"><a href="#Vi的基本概念" class="headerlink" title="Vi的基本概念"></a><code>Vi</code>的基本概念</h3><ol>
<li>命令行模式（command mode）<br>控制屏幕光标的移动、字符、字或行的删除、移动复制某区段及进入<code>Insert mode</code>下，或者到<code>last line mode</code>。</li>
<li>插入模式（Insert mode）<br>只有在<code>Insert mode</code>下，才可以做文字输入，按ESC键可回到命令行模式。</li>
<li>底行模式(last line mode)<br>将文件保存或退出vi，也可以设置编辑环境，如寻找字符串、列出行号。</li>
</ol>
<div class="note info">
    $ vi test.txt<br />
    即可进入vi（打开或新建文件）
</div>

<p>操作：</p>
<ol>
<li>命令行模式 —-&gt;(i)  插入模式</li>
<li>插入模式  —-&gt;（ESC）  命令行模式</li>
<li>如果处于「插入模式」，就只能一直输入文字，如果发现输错了字想用光标往回移动将该字删除，就得先回到「命令行模式」</li>
<li>在「命令行模式」下，按下：进入底行模式<br><code>: w filename</code><br><code>: wq</code><br><code>: q!</code></li>
</ol>
<h2 id="GCC工具链"><a href="#GCC工具链" class="headerlink" title="GCC工具链"></a><code>GCC</code>工具链</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ol>
<li><code>GCC</code>编译器能将<code>C</code>和<code>C++</code>语言源程序、汇编程序编译、链接成可执行文件。</li>
<li>使用<code>GCC</code>编译器时，编译过程可以被细分为四个阶段：<ul>
<li>预处理(Pre-Processing)</li>
<li>编译(Compiling)</li>
<li>汇编(Assembling)</li>
<li>链接(Linking)</li>
</ul>
</li>
</ol>
<h3 id="GDB的概述"><a href="#GDB的概述" class="headerlink" title="GDB的概述"></a><code>GDB</code>的概述</h3><p><code>GDB</code>是一款GNU开发组织并发布的UNIX/Linux下的程序调试工具。它使你能够在程序运行时观察程序的内部结构和内存的使用情况。以下是<code>GDB</code>提供的一些功能：</p>
<ol>
<li>监视程序中变量的值</li>
<li>设置断点以使程序在指定的代码行上停止运行</li>
<li>能逐行执行代码</li>
</ol>
<h2 id="Objdump简介"><a href="#Objdump简介" class="headerlink" title="Objdump简介"></a><code>Objdump</code>简介</h2><p><code>Objdump</code>是以一种可阅读的格式让你更多地了解二进制文件可能带有地附加信息。<br>对于想进一步了解系统地程序员，这个命令没有没有更多意义，对于想进一步了解系统的程序员，应该掌握这种工具，至少你可以自己写写<code>shellcode</code>了，或者看看人家给的<code>exploit</code>中的<code>shellcode</code>是什么东西。<br><strong>把C语言源代码编译链接生成的可执行程序反汇编后得到对应的汇编代码，可以帮助我们理解C语言和汇编语言之间的对应关系。非常有助于深入理解C语言</strong></p>
<div class="note warning">
    至此，已经完成了计算机系统基础第一次实验的理论部分，其中有太多的东西还需要自己去实践、接下来开始实验！
</div>]]></content>
      <categories>
        <category>计算机系统基础</category>
      </categories>
  </entry>
  <entry>
    <title>KNN与Naive_Bayes代码实现</title>
    <url>/201911/KNN%E4%B8%8ENaive_Bayes%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="任务要求"><a href="#任务要求" class="headerlink" title="任务要求"></a>任务要求</h2><p>采用Python实现分类算法：</p>
<ul>
<li>不得借助现成的工具包调库，例如SKlearn</li>
<li>至少实现k-近邻，朴素贝叶斯，逻辑回归，决策树与支持向量机中的其中一个算法。k-临近，朴素贝叶斯相对较简单，逻辑回归，决策树与支持向量机相对较难。</li>
<li>对breast cancer数据集调用编写的函数进行分类演示。</li>
<li>能力强的可以多实现几种算法</li>
</ul>
<span id="more"></span>
<h2 id="算法实现——kNN"><a href="#算法实现——kNN" class="headerlink" title="算法实现——kNN"></a>算法实现——kNN</h2><p>利用breast_cancer中的数据，实现kNN算法。  </p>
<ol>
<li>导入数据集，并分为训练集和测试集</li>
<li>实现kNN算法<ul>
<li>对每一个测试集中的实例，计算它距离训练集中的点的距离</li>
<li>根据选定的k值，选择距离最近的k个点数量更多的“标签”</li>
</ul>
</li>
<li>算法效果测试，测试算法的精确度，和SKlearn提供的kNN算法进行比较。</li>
</ol>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"></span><br><span class="line">datasets = datasets.load_breast_cancer()</span><br><span class="line">X = datasets.data;</span><br><span class="line">y = datasets.target;</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>)</span><br><span class="line">k = <span class="number">5</span></span><br><span class="line"><span class="comment"># print(datasets.DESCR)</span></span><br><span class="line"><span class="comment"># malignant - 0, benign - 1</span></span><br><span class="line">y_predict = []</span><br></pre></td></tr></table></figure>
<h3 id="kNN算法实现"><a href="#kNN算法实现" class="headerlink" title="kNN算法实现"></a>kNN算法实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">knn</span>(<span class="params">X_train, y_train, X_test, y_predict</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    对测试集的数据进行预测，得到的结果与y_test比较。用欧式距离进行计算。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> test_data <span class="keyword">in</span> X_test:</span><br><span class="line">        first_k_instance = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">            distance = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> attributes_no <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">                distance += (test_data[attributes_no] - X_train[i][attributes_no]) ** <span class="number">2</span></span><br><span class="line">            Euclid_distance = distance ** <span class="number">0.5</span></span><br><span class="line">            <span class="comment">#print(Euclid_distance)</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; k:</span><br><span class="line">                first_k_instance.append((i, Euclid_distance))</span><br><span class="line">            <span class="keyword">elif</span> Euclid_distance &lt; first_k_instance[k-<span class="number">1</span>][<span class="number">1</span>]:</span><br><span class="line">                first_k_instance[k-<span class="number">1</span>] = (i, Euclid_distance)</span><br><span class="line">            first_k_instance = <span class="built_in">sorted</span>(first_k_instance, key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>]) </span><br><span class="line">            <span class="comment">#print(first_k_instance)</span></span><br><span class="line">        <span class="comment"># 现在得到了距离测试点最近的k个点，用多数表决器来判断测试点是良性还是恶性</span></span><br><span class="line">        benign = <span class="number">0</span></span><br><span class="line">        malignant = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> instance <span class="keyword">in</span> first_k_instance:</span><br><span class="line">            <span class="keyword">if</span> y_train[instance[<span class="number">0</span>]] == <span class="number">0</span>:</span><br><span class="line">                malignant += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                benign += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> malignant &gt;= benign:</span><br><span class="line">            y_predict.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y_predict.append(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="精确度计算函数"><a href="#精确度计算函数" class="headerlink" title="精确度计算函数"></a>精确度计算函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_predict, y_test</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_predict)):</span><br><span class="line">        <span class="keyword">if</span> y_predict[i] == y_test[i]:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">    accuracy_rate = correct / <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> correct, accuracy_rate</span><br></pre></td></tr></table></figure>
<h3 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    knn(X_train, y_train, X_test, y_predict)</span><br><span class="line">    correct, accuracy_rate = accuracy(y_predict, y_test)</span><br><span class="line">    <span class="built_in">print</span>(y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;kNN模型测试集预测的准确率为：%.3f&quot;</span> % accuracy_rate);</span><br><span class="line">    KNN = neighbors.KNeighborsClassifier(n_neighbors = <span class="number">5</span>)</span><br><span class="line">    KNN.fit(X_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;sklearn库中kNN模型预测的准确率为：%.3f&quot;</span> % KNN.score(X_test, y_test));</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<pre><code>[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1]
kNN模型测试集预测的准确率为：0.947
sklearn库中kNN模型预测的准确率为：0.947
</code></pre><p>通过实验结果可以发现，我们实现的kNN与SKlearn中提供的kNN效果一致。<br>我们可以通过设置k的值和转换寻找相似样本的策略（将欧式距离替换为匹配系数或Jaccard等），进一步优化精确度。</p>
<h2 id="算法实现——Naive-Bayes"><a href="#算法实现——Naive-Bayes" class="headerlink" title="算法实现——Naive_Bayes"></a>算法实现——Naive_Bayes</h2><p>利用breast_cancer中的数据，实现Naive_Bayes算法。  </p>
<ol>
<li>导入数据集，并分为训练集和测试集</li>
<li>实现Naive Bayes算法<ul>
<li>把连续的属性划分区间，计算正例和反例落在每个属性的每个区间的个数</li>
<li>计算概率值，预测测试集的标签</li>
</ul>
</li>
<li>算法效果测试，测试算法的精确度，和SKlearn提供的Naive Bayes算法进行比较。</li>
</ol>
<h2 id="源码-1"><a href="#源码-1" class="headerlink" title="源码"></a>源码</h2><h3 id="导入数据-1"><a href="#导入数据-1" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load datasets</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> naive_bayes</span><br><span class="line"></span><br><span class="line">datasets = datasets.load_breast_cancer()</span><br><span class="line">X = datasets.data;</span><br><span class="line">y = datasets.target;</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>)</span><br><span class="line"><span class="comment">#print(datasets.DESCR)</span></span><br><span class="line"><span class="comment">#malignant - 0, benign - 1</span></span><br><span class="line">y_predict = []</span><br></pre></td></tr></table></figure>
<p>由于30个属性全部都是连续值，我们使用朴素贝叶斯的时候需要将属性的值的范围分为几个区间，计算实例落在该区间的概率。这里每个属性我都以平均值作为间隔来划分区间。<br><img src="2-1.jpg" alt=""></p>
<h3 id="对每个连续的属性划分区间并统计个数"><a href="#对每个连续的属性划分区间并统计个数" class="headerlink" title="对每个连续的属性划分区间并统计个数"></a>对每个连续的属性划分区间并统计个数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">distribution</span>(<span class="params">X_train, y_train</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    先把区间分好，然后再计算概率。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#===============区间划分====================#</span></span><br><span class="line">    attributes_max_min_mean = []</span><br><span class="line">    <span class="comment"># 记录所有属性的最大值、最小值和平均值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">        <span class="comment">#属性循环</span></span><br><span class="line">        <span class="comment">#section = [max, min, mean]</span></span><br><span class="line">        section = [X_train[<span class="number">0</span>][i], X_train[<span class="number">0</span>][i], <span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> instance <span class="keyword">in</span> X_train:</span><br><span class="line">            <span class="comment">#训练样例循环</span></span><br><span class="line">            <span class="keyword">if</span> instance[i] &gt; section[<span class="number">0</span>]:</span><br><span class="line">                section[<span class="number">0</span>] = instance[i]</span><br><span class="line">            <span class="keyword">if</span> instance[i] &lt; section[<span class="number">1</span>]:</span><br><span class="line">                section[<span class="number">1</span>] = instance[i]</span><br><span class="line">            section[<span class="number">2</span>] += instance[i]</span><br><span class="line">        section[<span class="number">2</span>] /= <span class="built_in">len</span>(X_train)</span><br><span class="line">        attributes_max_min_mean.append(section)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#=========计算每个属性落在每个区间的样例个数=========#</span></span><br><span class="line">    instance_distribution = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">        <span class="comment">#属性循环</span></span><br><span class="line">        smaller_benign = <span class="number">0</span></span><br><span class="line">        larger_benign = <span class="number">0</span></span><br><span class="line">        smaller_malignant = <span class="number">0</span></span><br><span class="line">        larger_malignant = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">            <span class="comment">#训练样例循环</span></span><br><span class="line">            <span class="keyword">if</span> X_train[j][i] &gt; attributes_max_min_mean[i][<span class="number">2</span>]:</span><br><span class="line">                <span class="keyword">if</span> y_train[j] == <span class="number">1</span>:</span><br><span class="line">                    larger_benign += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    larger_malignant +=<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> y_train[j] == <span class="number">1</span>:</span><br><span class="line">                smaller_benign += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                smaller_malignant += <span class="number">1</span>   </span><br><span class="line">        instance_distribution.append([smaller_benign, larger_benign, smaller_malignant, larger_malignant])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> instance_distribution, attributes_max_min_mean</span><br></pre></td></tr></table></figure>
<h3 id="实现朴素贝叶斯"><a href="#实现朴素贝叶斯" class="headerlink" title="实现朴素贝叶斯"></a>实现朴素贝叶斯</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Naive_Bayes</span>(<span class="params">X_test, y_predict, instance_distribution,attributes_max_min_mean</span>):</span><br><span class="line">    <span class="keyword">for</span> test_data <span class="keyword">in</span> X_test:</span><br><span class="line">        <span class="comment">#测试样例循环</span></span><br><span class="line">        <span class="comment">#训练集中良性和恶性肿瘤的数量</span></span><br><span class="line">        malignant = instance_distribution[<span class="number">0</span>][<span class="number">2</span>] + instance_distribution[<span class="number">0</span>][<span class="number">3</span>]</span><br><span class="line">        benign = instance_distribution[<span class="number">0</span>][<span class="number">0</span>] + instance_distribution[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#概率初始化，下面计算每个属性的概率</span></span><br><span class="line">        p_xc0 = <span class="number">1</span></span><br><span class="line">        p_xc1 = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">            <span class="comment"># 属性循环</span></span><br><span class="line">            <span class="keyword">if</span> test_data[i] &gt; attributes_max_min_mean[i][<span class="number">2</span>]:</span><br><span class="line">                p_xc0 *= instance_distribution[i][<span class="number">3</span>] / malignant</span><br><span class="line">                p_xc1 *= instance_distribution[i][<span class="number">1</span>] / benign</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p_xc0 *= instance_distribution[i][<span class="number">2</span>] / malignant</span><br><span class="line">                p_xc1 *= instance_distribution[i][<span class="number">0</span>] / benign</span><br><span class="line">        p0 = p_xc0 * malignant / (malignant + benign)</span><br><span class="line">        p1 = p_xc1 * benign / (malignant + benign)</span><br><span class="line">        <span class="keyword">if</span> p0 &gt; p1:</span><br><span class="line">            y_predict.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y_predict.append(<span class="number">1</span>)      </span><br></pre></td></tr></table></figure>
<h3 id="计算精确度"><a href="#计算精确度" class="headerlink" title="计算精确度"></a>计算精确度</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_predict, y_test</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_predict)):</span><br><span class="line">        <span class="keyword">if</span> y_predict[i] == y_test[i]:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">    accuracy_rate = correct / <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> correct, accuracy_rate</span><br></pre></td></tr></table></figure>
<h3 id="主函数-1"><a href="#主函数-1" class="headerlink" title="主函数"></a>主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    instance_distribution, attributes_max_min_mean = distribution(X_train, y_train)</span><br><span class="line">    Naive_Bayes(X_test, y_predict, instance_distribution, attributes_max_min_mean)</span><br><span class="line">    correct, accuracy_rate = accuracy(y_predict, y_test)</span><br><span class="line">    <span class="built_in">print</span>(y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Naive Bayes模型测试集预测的准确率为：%.3f&quot;</span> % accuracy_rate);</span><br><span class="line">    bayes = naive_bayes.GaussianNB()</span><br><span class="line">    bayes.fit(X_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;sklearn库中Naive Bayes模型预测的准确率为：%.3f&quot;</span> % bayes.score(X_test, y_test));</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<pre><code>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1]
Naive Bayes模型测试集预测的准确率为：0.930
sklearn库中Naive Bayes模型预测的准确率为：0.924
</code></pre><p>通过实验结果可以发现，我们实现的朴素贝叶斯比SKlearn提供的朴素贝叶斯效果更好。<br>我们可以通过尝试各属性不同的区间划分，进一步优化精确度。而SKlearn提供的朴素贝叶斯效果不好的原因可能就是将连续值转换为离散值的区间划分没有做好。</p>
]]></content>
      <categories>
        <category>数据科学导论</category>
      </categories>
  </entry>
  <entry>
    <title>Fisher算法&amp;SVM&amp;K-Means及其优化</title>
    <url>/201911/Fisher%E7%AE%97%E6%B3%95&amp;SVM&amp;K-Means%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="fisher算法及其实现"><a href="#fisher算法及其实现" class="headerlink" title="fisher算法及其实现"></a><code>fisher</code>算法及其实现</h2><ol>
<li>请实现<code>fisher</code>算法，并采用自己随机生成2类数据（每类100个）的方式，验证自己的算法。<br><a href="https://blog.csdn.net/pengjian444/article/details/71138003">参考资料:https://blog.csdn.net/pengjian444/article/details/71138003</a></li>
</ol>
<span id="more"></span>
<h3 id="数据生成"><a href="#数据生成" class="headerlink" title="数据生成"></a>数据生成</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_multilabel_classification</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x, y = make_multilabel_classification(n_samples=<span class="number">200</span>, n_features=<span class="number">2</span>,</span><br><span class="line">                                      n_labels=<span class="number">1</span>, n_classes=<span class="number">1</span>,</span><br><span class="line">                                      random_state=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据类别分类</span></span><br><span class="line">index1 = np.array([index <span class="keyword">for</span> (index, value) <span class="keyword">in</span> <span class="built_in">enumerate</span>(y) <span class="keyword">if</span> value == <span class="number">0</span>])  <span class="comment"># 获取类别1的indexs</span></span><br><span class="line">index2 = np.array([index <span class="keyword">for</span> (index, value) <span class="keyword">in</span> <span class="built_in">enumerate</span>(y) <span class="keyword">if</span> value == <span class="number">1</span>])  <span class="comment"># 获取类别2的indexs</span></span><br><span class="line"></span><br><span class="line">c_1 = x[index1]   <span class="comment"># 类别1的所有数据(x1, x2) in X_1</span></span><br><span class="line">c_2 = x[index2]  <span class="comment"># 类别2的所有数据(x1, x2) in X_2</span></span><br></pre></td></tr></table></figure>
<p><a href="http://lijiancheng0614.github.io/scikit-learn/modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification">make_multilabel_classification方法参数说明</a><br><code>n_samples</code>:样本的数量。<br><code>n_features</code>：样本的特征，这里是在二维平面中的点，所以为2.<br><code>n_labels</code>：每个实例的平均标签数。<br><code>n_classes</code>：分类问题的分类数。<br><code>random_state</code>：设置随机数种子，保证每次产生相同的数据。</p>
<p><a href="https://www.runoob.com/python/python-func-enumerate.html">enumerate()函数说明</a><br><code>enumerate()</code>函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p>
<h3 id="fisher算法实现"><a href="#fisher算法实现" class="headerlink" title="fisher算法实现"></a>fisher算法实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cal_cov_and_avg</span>(<span class="params">samples</span>):</span><br><span class="line">    u1 = np.mean(samples, axis=<span class="number">0</span>)</span><br><span class="line">    cov_m = np.zeros((samples.shape[<span class="number">1</span>], samples.shape[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> samples:</span><br><span class="line">        t = s - u1</span><br><span class="line">        cov_m += t * t.reshape(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> cov_m, u1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fisher</span>(<span class="params">c_1, c_2</span>):</span><br><span class="line">    cov_1, u1 = cal_cov_and_avg(c_1)</span><br><span class="line">    cov_2, u2 = cal_cov_and_avg(c_2)</span><br><span class="line">    s_w = cov_1 + cov_2</span><br><span class="line">    u, s, v = np.linalg.svd(s_w)  <span class="comment"># 奇异值分解</span></span><br><span class="line">    s_w_inv = np.dot(np.dot(v.T, np.linalg.inv(np.diag(s))), u.T)</span><br><span class="line">    <span class="keyword">return</span> np.dot(s_w_inv, u1 - u2)</span><br></pre></td></tr></table></figure>
<p><code>np.mean</code>：计算制定轴上的平均值。<br><code>np.zeros</code>：给定形状和类型确定的数组，并用0填充。</p>
<h3 id="判定类别"><a href="#判定类别" class="headerlink" title="判定类别"></a>判定类别</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">judge</span>(<span class="params">sample, w, c_1, c_2</span>):</span><br><span class="line">    u1 = np.mean(c_1, axis=<span class="number">0</span>)</span><br><span class="line">    u2 = np.mean(c_2, axis=<span class="number">0</span>)</span><br><span class="line">    center_1 = np.dot(w.T, u1)</span><br><span class="line">    center_2 = np.dot(w.T, u2)</span><br><span class="line">    pos = np.dot(w.T, sample)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>(pos - center_1) &lt; <span class="built_in">abs</span>(pos - center_2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">w = fisher(c_1, c_2)  <span class="comment"># 调用函数，得到参数w</span></span><br><span class="line">out = judge(c_1[<span class="number">1</span>], w, c_1, c_2)   <span class="comment"># 判断所属的类别</span></span><br><span class="line"><span class="comment"># print(out)</span></span><br></pre></td></tr></table></figure>
<h3 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.scatter(c_1[:, <span class="number">0</span>], c_1[:, <span class="number">1</span>], c=<span class="string">&#x27;#99CC99&#x27;</span>)</span><br><span class="line">plt.scatter(c_2[:, <span class="number">0</span>], c_2[:, <span class="number">1</span>], c=<span class="string">&#x27;#FFCC00&#x27;</span>)</span><br><span class="line">line_x = np.arange(<span class="built_in">min</span>(np.<span class="built_in">min</span>(c_1[:, <span class="number">0</span>]), np.<span class="built_in">min</span>(c_2[:, <span class="number">0</span>])),</span><br><span class="line">                   <span class="built_in">max</span>(np.<span class="built_in">max</span>(c_1[:, <span class="number">0</span>]), np.<span class="built_in">max</span>(c_2[:, <span class="number">0</span>])),</span><br><span class="line">                   step=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">line_y = - (w[<span class="number">0</span>] * line_x) / w[<span class="number">1</span>]</span><br><span class="line">plt.plot(line_x, line_y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 640x480 with 1 Axes&gt;
</code></pre><h2 id="SVM优化对偶问题的详细推导过程"><a href="#SVM优化对偶问题的详细推导过程" class="headerlink" title="SVM优化对偶问题的详细推导过程"></a><code>SVM</code>优化对偶问题的详细推导过程</h2><ol>
<li>请给出<code>SVM</code>优化对偶问题的详细推导过程；并给出只有2维特征情况下的，对偶问题的优化求解过程（可以采用<code>lagrange</code>方法，也可以采用其他方法。）<br><a href="https://zhuanlan.zhihu.com/p/49331510">参考资料：https://zhuanlan.zhihu.com/p/49331510</a>  </li>
</ol>
<p><img src="https://s2.ax1x.com/2019/10/08/uWyoX4.png" alt=""><br><img src="https://s2.ax1x.com/2019/10/08/uWy4pT.png" alt=""><br><img src="https://s2.ax1x.com/2019/10/08/uWyIcF.png" alt=""><br><img src="https://s2.ax1x.com/2019/10/08/uWy51U.png" alt=""><br><img src="https://s2.ax1x.com/2019/10/08/uWyfhV.png" alt=""></p>
<h2 id="SVM算法的实现"><a href="#SVM算法的实现" class="headerlink" title="SVM算法的实现"></a><code>SVM</code>算法的实现</h2><ol>
<li>请实现<code>SVM</code>算法；并采用自己随机生成2类线性可分数据（每类100个）的方式验证自己的算法。<br><a href="https://www.jb51.net/article/131580.htm">参考资料：https://www.jb51.net/article/131580.htm</a></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line">  </span><br><span class="line">np.random.seed(<span class="number">0</span>) </span><br><span class="line">x = np.r_[np.random.randn(<span class="number">100</span>,<span class="number">2</span>)-[<span class="number">2</span>,<span class="number">2</span>],np.random.randn(<span class="number">100</span>,<span class="number">2</span>)+[<span class="number">2</span>,<span class="number">2</span>]] <span class="comment">#正态分布来产生数字,20行2列*2 </span></span><br><span class="line">y = [<span class="number">0</span>]*<span class="number">100</span>+[<span class="number">1</span>]*<span class="number">100</span> <span class="comment">#100个class0，100个class1 </span></span><br><span class="line">  </span><br><span class="line">clf = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>) </span><br><span class="line">clf.fit(x,y) </span><br><span class="line">  </span><br><span class="line">w = clf.coef_[<span class="number">0</span>] <span class="comment">#获取w </span></span><br><span class="line">a = -w[<span class="number">0</span>]/w[<span class="number">1</span>] <span class="comment">#斜率 </span></span><br><span class="line"><span class="comment">#画图划线 </span></span><br><span class="line">xx = np.linspace(-<span class="number">5</span>,<span class="number">5</span>) <span class="comment">#(-5,5)之间x的值 </span></span><br><span class="line">yy = a*xx-(clf.intercept_[<span class="number">0</span>])/w[<span class="number">1</span>] <span class="comment">#xx带入y，截距 </span></span><br><span class="line">  </span><br><span class="line"><span class="comment">#画出与点相切的线 </span></span><br><span class="line">b = clf.support_vectors_[<span class="number">0</span>] </span><br><span class="line">yy_down = a*xx+(b[<span class="number">1</span>]-a*b[<span class="number">0</span>]) </span><br><span class="line">b = clf.support_vectors_[-<span class="number">1</span>] </span><br><span class="line">yy_up = a*xx+(b[<span class="number">1</span>]-a*b[<span class="number">0</span>]) </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;W:&quot;</span>,w) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;a:&quot;</span>,a) </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;support_vectors_:&quot;</span>,clf.support_vectors_) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;clf.coef_:&quot;</span>,clf.coef_) </span><br><span class="line">  </span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">4</span>)) </span><br><span class="line">plt.plot(xx,yy) </span><br><span class="line">plt.plot(xx,yy_down) </span><br><span class="line">plt.plot(xx,yy_up) </span><br><span class="line">plt.scatter(clf.support_vectors_[:,<span class="number">0</span>],clf.support_vectors_[:,<span class="number">1</span>],s=<span class="number">80</span>) </span><br><span class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>],c=y,cmap=plt.cm.Paired) <span class="comment">#[:，0]列切片，第0列 </span></span><br><span class="line">  </span><br><span class="line">plt.axis(<span class="string">&#x27;tight&#x27;</span>) </span><br><span class="line">  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>W: [0.95070185 1.15607502]
a: -0.8223530762163854
support_vectors_: [[-0.51174781 -0.10411082]
 [ 0.16323595 -0.66347205]
 [ 2.39904635 -0.77259276]
 [ 0.66574153  0.65328249]
 [-0.25556423  0.97749316]]
clf.coef_: [[0.95070185 1.15607502]]
</code></pre><p><img src="output_12_1.png" alt="png"></p>
<h2 id="k-means算法的实现"><a href="#k-means算法的实现" class="headerlink" title="k-means算法的实现"></a><code>k-means</code>算法的实现</h2><ol>
<li>请实现<code>k-means</code>的算法；并采用自己随机生成3类数据（每类100个）的方式，验证自己的算法。<br><a href="https://cloud.tencent.com/developer/article/1465020">参考资料1:https://cloud.tencent.com/developer/article/1465020</a><br><a href="https://blog.csdn.net/weixin_42029738/article/details/81978038">参考资料2:https://blog.csdn.net/weixin_42029738/article/details/81978038</a>  </li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    K-Means clustering algorithms</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MiniBatchKMeans, KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances_argmin</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Generate sample data</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">45</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]] <span class="comment"># 初始化3个中心</span></span><br><span class="line">n_clusters = <span class="built_in">len</span>(centers) <span class="comment"># 聚类的数目为3</span></span><br><span class="line"><span class="comment"># 产生10000组二维数据，以上面三个点为中心，以(-10,10)为边界，数据集的标准差是0.7</span></span><br><span class="line">X, labels_true = make_blobs(n_samples=<span class="number">10000</span>, centers=centers, cluster_std=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Compute clustering with Means</span></span><br><span class="line"></span><br><span class="line">k_means = KMeans(init=<span class="string">&#x27;k-means++&#x27;</span>, n_clusters=<span class="number">3</span>, n_init=<span class="number">10</span>)</span><br><span class="line">t0 = time.time()</span><br><span class="line">k_means.fit(X)</span><br><span class="line"><span class="comment"># 使用k-means对300组数据集训练算法的时间消耗</span></span><br><span class="line">t_batch = time.time() - t0</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Plot result</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">fig.subplots_adjust(left=<span class="number">0.02</span>, right=<span class="number">0.98</span>, bottom=<span class="number">0.05</span>, top=<span class="number">0.9</span>)</span><br><span class="line">colors = [<span class="string">&#x27;#4EACC5&#x27;</span>, <span class="string">&#x27;#FF9C34&#x27;</span>, <span class="string">&#x27;#4E9A06&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># We want to have the same colors for the same cluster from the</span></span><br><span class="line"><span class="comment"># MiniBatchKMeans and the KMeans algorithm. Let&#x27;s pair the cluster centers per</span></span><br><span class="line"><span class="comment"># closest one.</span></span><br><span class="line">k_means_cluster_centers = np.sort(k_means.cluster_centers_, axis=<span class="number">0</span>)</span><br><span class="line">k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># KMeans</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters), colors):</span><br><span class="line">    my_members = k_means_labels == k</span><br><span class="line">    cluster_center = k_means_cluster_centers[k]</span><br><span class="line">    ax.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">            markerfacecolor=col, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    ax.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">            markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;KMeans&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line">plt.text(-<span class="number">3.5</span>, <span class="number">1.8</span>,  <span class="string">&#x27;train time: %.2fs\ninertia: %f&#x27;</span> % (</span><br><span class="line">    t_batch, k_means.inertia_))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>    K-Means clustering algorithms
</code></pre><p><img src="output_14_1.png" alt="png"></p>
<h2 id="k-means算法的改进"><a href="#k-means算法的改进" class="headerlink" title="k-means算法的改进"></a><code>k-means</code>算法的改进</h2><ol>
<li>请给出三种<code>k-means</code>算法在大数据量时的改进方法，并分析改进的结果。<br>改进方法包括：<ol>
<li><code>k-means++</code>（改变中心点的选取方法）</li>
<li><code>elkan K-Means</code>（减少不必要的距离计算）</li>
<li><code>ISODATA</code>算法（在运行过程中根据实际情况调整聚类中心数k）</li>
<li><code>Mini Batch k-means</code>算法（采用部分样本，舍弃一些精确度大大加快收敛速度）</li>
</ol>
</li>
</ol>
<p>其中1和4改进方法给出了源码和对比。</p>
<h3 id="k-means-（改变中心点的选择方法）"><a href="#k-means-（改变中心点的选择方法）" class="headerlink" title="k-means++（改变中心点的选择方法）"></a><code>k-means++</code>（改变中心点的选择方法）</h3><p><a href="https://blog.csdn.net/github_39261590/article/details/76910689">参考资料1:https://blog.csdn.net/github_39261590/article/details/76910689</a><br><a href="https://www.cnblogs.com/yszd/p/9672885.html">参考资料2:https://www.cnblogs.com/yszd/p/9672885.html</a><br><code>k-means++</code>算法选择初始seeds的基本思想就是：<strong>初始的聚类中心之间的相互距离要尽可能的远。</strong>  </p>
<p>算法步骤：</p>
<ol>
<li>从输入的数据点集合中随机选择一个点作为第一个聚类中心</li>
<li>对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)</li>
<li>选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大</li>
<li>重复2和3直到k个聚类中心被选出来</li>
<li>利用这k个初始的聚类中心来运行标准的k-means算法</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets <span class="keyword">as</span> ds</span><br><span class="line"><span class="keyword">import</span> matplotlib.colors</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MiniBatchKMeans</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">expand</span>(<span class="params">a, b</span>):</span><br><span class="line">    d = (b - a) * <span class="number">0.1</span></span><br><span class="line">    <span class="keyword">return</span> a-b, b+d</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    N = <span class="number">400</span></span><br><span class="line">    centers = <span class="number">4</span></span><br><span class="line">    data, y = ds.make_blobs(N, n_features=<span class="number">2</span>, centers=centers, random_state=<span class="number">2</span>)</span><br><span class="line">    data2, y2 = ds.make_blobs(N, n_features=<span class="number">2</span>, centers=centers, cluster_std=(<span class="number">1</span>, <span class="number">2.5</span>, <span class="number">0.5</span>, <span class="number">2</span>), random_state=<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 按行拼接numpy数组</span></span><br><span class="line">    data3 = np.vstack((data[y == <span class="number">0</span>][:], data[y == <span class="number">1</span>][:<span class="number">50</span>], data[y == <span class="number">2</span>][:<span class="number">20</span>], data[y == <span class="number">3</span>][:<span class="number">5</span>]))</span><br><span class="line">    y3 = np.array([<span class="number">0</span>] * <span class="number">100</span> + [<span class="number">1</span>] * <span class="number">50</span> + [<span class="number">2</span>] * <span class="number">20</span> + [<span class="number">3</span>] * <span class="number">5</span>)</span><br><span class="line">    cls = KMeans(n_clusters=<span class="number">4</span>, init=<span class="string">&#x27;k-means++&#x27;</span>)</span><br><span class="line">    y_hat = cls.fit_predict(data)</span><br><span class="line">    y2_hat = cls.fit_predict(data2)</span><br><span class="line">    y3_hat = cls.fit_predict(data3)</span><br><span class="line">    </span><br><span class="line">    m = np.array(((<span class="number">1</span>, <span class="number">1</span>),(<span class="number">1</span>, <span class="number">3</span>)))</span><br><span class="line">    data_r = data.dot(m)</span><br><span class="line">    y_r_hat = cls.fit_predict(data_r)</span><br><span class="line">    </span><br><span class="line">    matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">u&#x27;SimHei&#x27;</span>]</span><br><span class="line">    matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">    cm = matplotlib.colors.ListedColormap(<span class="built_in">list</span>(<span class="string">&#x27;rgbm&#x27;</span>))</span><br><span class="line">    plt.figure(figsize=(<span class="number">9</span>, <span class="number">10</span>), facecolor=<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">421</span>)</span><br><span class="line">    plt.title(<span class="string">u&#x27;原始数据&#x27;</span>)</span><br><span class="line">    plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], c=y, s=<span class="number">30</span>, cmap=cm, edgecolors=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    x1_min, x2_min = np.<span class="built_in">min</span>(data, axis=<span class="number">0</span>)</span><br><span class="line">    x1_max, x2_max = np.<span class="built_in">max</span>(data, axis=<span class="number">0</span>)</span><br><span class="line">    x1_min, x1_max = expand(x1_min, x1_max)</span><br><span class="line">    x2_min, x2_max = expand(x2_min, x2_max)</span><br><span class="line">    plt.xlim((x1_min, x1_max))</span><br><span class="line">    plt.ylim((x2_min, x2_max))</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">422</span>)</span><br><span class="line">    plt.title(<span class="string">u&#x27;KMeans++聚类&#x27;</span>)</span><br><span class="line">    plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], c=y_hat, s=<span class="number">30</span>, cmap=cm, edgecolors=<span class="string">&#x27;none&#x27;</span>)    </span><br><span class="line">    plt.xlim((x1_min, x1_max))</span><br><span class="line">    plt.ylim((x2_min, x2_max))</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="output_16_0.png" alt="png"></p>
<h3 id="elkan-k-means算法"><a href="#elkan-k-means算法" class="headerlink" title="elkan k-means算法"></a><code>elkan k-means</code>算法</h3><p><a href="https://blog.csdn.net/u014465639/article/details/71342072">参考资料:https://blog.csdn.net/u014465639/article/details/71342072</a><br><code>elkan K-Means</code>利用了两边之和大于等于第三边,以及两边之差小于第三边的三角形性质，来减少距离的计算。<br>第一种规律是对于一个样本点和两个质心。如果我们预先计算出了这两个质心之间的距离，则如果计算发现,我们立即就可以知道。此时我们不需要再计算,也就是说省了一步距离计算。<br>第二种规律是对于一个样本点和两个质心。我们可以得到。这个从三角形的性质也很容易得到。<br>利用上边的两个规律，elkan K-Means比起传统的K-Means迭代速度有很大的提高。但是如果我们的样本的特征是稀疏的，有缺失值的话，这个方法就不使用了，此时某些距离无法计算，则不能使用该算法。  </p>
<h3 id="ISODATA算法"><a href="#ISODATA算法" class="headerlink" title="ISODATA算法"></a><code>ISODATA</code>算法</h3><p><a href="https://blog.csdn.net/houston11235/article/details/8511379">参考资料1:https://blog.csdn.net/houston11235/article/details/8511379</a><br><a href="https://www.cnblogs.com/huadongw/p/4101422.html">参考资料2:https://www.cnblogs.com/huadongw/p/4101422.html</a><br>k-means 的一个缺点就是必须指定聚类的个数，这个有些时候并不太行得通。于是就要求最好这个类别的个数也可以改变，这就形成了 isodata 方法，通过设定一些类别分裂和合并的条件，在聚类的过程中自动增减类别的数目。当然这也带来了一个问题，就是这个条件有时候并不那么好给出。当然 isodata 在很多情况下还是可以得到比较靠谱的结果。  </p>
<h3 id="Mini-Batch-k-means（用一部分样本做传统的k-means，舍弃一部分精确度大大提高收敛速度）"><a href="#Mini-Batch-k-means（用一部分样本做传统的k-means，舍弃一部分精确度大大提高收敛速度）" class="headerlink" title="Mini Batch k-means（用一部分样本做传统的k-means，舍弃一部分精确度大大提高收敛速度）"></a><code>Mini Batch k-means</code>（用一部分样本做传统的k-means，舍弃一部分精确度大大提高收敛速度）</h3><p><a href="https://cloud.tencent.com/developer/article/1465020">参考资料1:https://cloud.tencent.com/developer/article/1465020</a><br>Mini Batch KMeans算法是一种能<strong>尽量保持聚类准确性下但能大幅度降低计算时间的聚类模型</strong>，采用小批量的数据子集减少计算时间，同时仍试图优化目标函数，这里所谓的Mini Batch是指每次训练算法时随机抽取的数据子集，采用这些随机选取的数据进行训练，大大的减少了计算的时间，减少的KMeans算法的收敛时间，但要比标准算法略差一点，建议当样本量大于一万做聚类时，就需要考虑选用Mini Batch KMeans算法。  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Comparison of the K-Means and MiniBatchKMeans clustering algorithms</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MiniBatchKMeans, KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> pairwise_distances_argmin</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Generate sample data</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">45</span></span><br><span class="line">centers = [[<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>]] <span class="comment"># 初始化3个中心</span></span><br><span class="line">n_clusters = <span class="built_in">len</span>(centers) <span class="comment"># 聚类的数目为3</span></span><br><span class="line"><span class="comment"># 产生10000组二维数据，以上面三个点为中心，以(-10,10)为边界，数据集的标准差是0.7</span></span><br><span class="line">X, labels_true = make_blobs(n_samples=<span class="number">10000</span>, centers=centers, cluster_std=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Compute clustering with Means</span></span><br><span class="line"></span><br><span class="line">k_means = KMeans(init=<span class="string">&#x27;k-means++&#x27;</span>, n_clusters=<span class="number">3</span>, n_init=<span class="number">10</span>)</span><br><span class="line">t0 = time.time()</span><br><span class="line">k_means.fit(X)</span><br><span class="line"><span class="comment"># 使用k-means对300组数据集训练算法的时间消耗</span></span><br><span class="line">t_batch = time.time() - t0</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Compute clustering with MiniBatchKMeans</span></span><br><span class="line"></span><br><span class="line">mbk = MiniBatchKMeans(init=<span class="string">&#x27;k-means++&#x27;</span>, n_clusters=<span class="number">3</span>, batch_size=batch_size,</span><br><span class="line">                      n_init=<span class="number">10</span>, max_no_improvement=<span class="number">10</span>, verbose=<span class="number">0</span>)</span><br><span class="line">t0 = time.time()</span><br><span class="line">mbk.fit(X)</span><br><span class="line"><span class="comment"># 使用MiniBatchKMeans对300组数据集训练算法的时间消耗</span></span><br><span class="line">t_mini_batch = time.time() - t0</span><br><span class="line"></span><br><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Plot result</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">fig.subplots_adjust(left=<span class="number">0.02</span>, right=<span class="number">0.98</span>, bottom=<span class="number">0.05</span>, top=<span class="number">0.9</span>)</span><br><span class="line">colors = [<span class="string">&#x27;#4EACC5&#x27;</span>, <span class="string">&#x27;#FF9C34&#x27;</span>, <span class="string">&#x27;#4E9A06&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># We want to have the same colors for the same cluster from the</span></span><br><span class="line"><span class="comment"># MiniBatchKMeans and the KMeans algorithm. Let&#x27;s pair the cluster centers per</span></span><br><span class="line"><span class="comment"># closest one.</span></span><br><span class="line">k_means_cluster_centers = np.sort(k_means.cluster_centers_, axis=<span class="number">0</span>)</span><br><span class="line">mbk_means_cluster_centers = np.sort(mbk.cluster_centers_, axis=<span class="number">0</span>)</span><br><span class="line">k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)</span><br><span class="line">mbk_means_labels = pairwise_distances_argmin(X, mbk_means_cluster_centers)</span><br><span class="line">order = pairwise_distances_argmin(k_means_cluster_centers,</span><br><span class="line">                                  mbk_means_cluster_centers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># KMeans</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters), colors):</span><br><span class="line">    my_members = k_means_labels == k</span><br><span class="line">    cluster_center = k_means_cluster_centers[k]</span><br><span class="line">    ax.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">            markerfacecolor=col, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    ax.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">            markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;KMeans&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line">plt.text(-<span class="number">3.5</span>, <span class="number">1.8</span>,  <span class="string">&#x27;train time: %.2fs\ninertia: %f&#x27;</span> % (</span><br><span class="line">    t_batch, k_means.inertia_))</span><br><span class="line"></span><br><span class="line"><span class="comment"># MiniBatchKMeans</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(n_clusters), colors):</span><br><span class="line">    my_members = mbk_means_labels == order[k]</span><br><span class="line">    cluster_center = mbk_means_cluster_centers[order[k]]</span><br><span class="line">    ax.plot(X[my_members, <span class="number">0</span>], X[my_members, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">            markerfacecolor=col, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    ax.plot(cluster_center[<span class="number">0</span>], cluster_center[<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>, markerfacecolor=col,</span><br><span class="line">            markeredgecolor=<span class="string">&#x27;k&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;MiniBatchKMeans&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line">plt.text(-<span class="number">3.5</span>, <span class="number">1.8</span>, <span class="string">&#x27;train time: %.2fs\ninertia: %f&#x27;</span> %</span><br><span class="line">         (t_mini_batch, mbk.inertia_))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialise the different array to all False</span></span><br><span class="line">different = (mbk_means_labels == <span class="number">4</span>)</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">    different += ((k_means_labels == k) != (mbk_means_labels == order[k]))</span><br><span class="line"></span><br><span class="line">identic = np.logical_not(different)</span><br><span class="line">ax.plot(X[identic, <span class="number">0</span>], X[identic, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">        markerfacecolor=<span class="string">&#x27;#bbbbbb&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">ax.plot(X[different, <span class="number">0</span>], X[different, <span class="number">1</span>], <span class="string">&#x27;w&#x27;</span>,</span><br><span class="line">        markerfacecolor=<span class="string">&#x27;m&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Difference&#x27;</span>)</span><br><span class="line">ax.set_xticks(())</span><br><span class="line">ax.set_yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>    Comparison of the K-Means and MiniBatchKMeans clustering algorithms
</code></pre><p><img src="output_20_1.png" alt="png"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Fisher</tag>
        <tag>SVM</tag>
        <tag>K-Means</tag>
      </tags>
  </entry>
  <entry>
    <title>写于10月15日——博客正式对外开放之际</title>
    <url>/201909/%E5%86%99%E4%BA%8E%E5%8D%9A%E5%AE%A2%E6%AD%A3%E5%BC%8F%E5%AF%B9%E5%A4%96%E5%BC%80%E6%94%BE%E4%B9%8B%E9%99%85/</url>
    <content><![CDATA[<p><img src="https://s2.ax1x.com/2019/10/15/KPwEYd.jpg" alt=""></p>
<p class="tag-plugin quot" type="text">If you can quite, then quite.<br /> If you can't quite, you're a writer. <div style=text-align:right>——R.A.Salvatore</div></p>
<span id="more"></span>
<p>经过四个月的磨叽，新的博客基本已经完善。<a href="www.crocodilezs.top">鳄鱼先生的水族馆</a><br>本来想着把原先<code>wordpress</code>博客的文章慢慢搬过来再向大家开放博客，但是仔细看看自己原来的那些文章，要么是没什么深度的书评和影评，要么是平淡的流水账。  </p>
<p>但是讲真话，看到自己以前的文字觉得很有成就感，因为那些文章的信息量虽然没那么高、有很多无意义的情绪宣泄，但是里面都有很有意思的闪光点，自己大一大二还真是一个有些自负的天马行空少年。如果这个学期还有时间，就把自己曾经的一些想法整理一下发到博客上来。  </p>
<p>下面就记录一下自己接触博客这个圈子以来的一些感触。</p>
<h1 id="我为什么要写博客？"><a href="#我为什么要写博客？" class="headerlink" title="我为什么要写博客？"></a>我为什么要写博客？</h1><p>表达自己的方式有太多了，微信朋友圈、微信公众平台、QQ空间、微博、知乎、百度贴吧…<br>但是我逐渐发现两个非常严重的问题，其一、这些社交平台上的原创信息都太多了，把自己的想法和感触发布出去真的就是石沉大海，少有人能注意到自己的想法，即使看到了，能让大家留下印象真的非常困难（微信公众平台最明显，随着微信公众平台的门槛降低，“写的比看的多”真的成为了现实）这是消息爆炸的必然结果，随着时间的累积，互联网上文字的平均价值一定会逐渐减少。<br>其二、即使在自己很有存在感的朋友圈和空间，发布的内容也只是自己即时的感慨和供大家取乐的段子，这些东西能够极大地满足我的虚荣心，也记录下了自己很多美好的瞬间。但是在这些平台发布一些长篇大论，就少有人阅读也很难引发深刻的共鸣。  </p>
<p><b>自己的文字越来越浮躁、信息量越来越低，最终在2017年12月，我开始接触博客。</b>  </p>
<p>博客对于我来说就像是信息海洋里属于自己的象牙舟——任缘分流，最后还回港口。</p>
<p>老狼就是一个不会被时间改变的人，你应该庆幸身边有这样的人。<br /><br>我是那种随时跟着时代改变的，但是如果你身边都是这样的人，大家都是弄潮儿，最后就不知道随波逐流到哪儿去了。<br /><br>那你身边有这么一个人呢，你在哪儿弄潮也好，还是劈波斩浪也好，你老能看见他。<br />你会知道，“哦，这个地方是我们出发的地方，这个地方是我们还要回去的地方。”</p>
<div style="text-align:right">——高晓松</div>


<h1 id="搭建博客的历史"><a href="#搭建博客的历史" class="headerlink" title="搭建博客的历史"></a>搭建博客的历史</h1><p>大一的时候根本不懂任何技术，经知乎大佬们安利最终决定自己买服务器用<code>wordpress</code>进行傻瓜操作。<br>买域名主机一气呵成，按照教程搭建好了自己的博客。<br><code>wordpress</code>也确实对小白很友好了，但是它有一个很严重的问题——慢，还有一个致命的问题——莫名其妙地自己的博客就会打不开。<br><code>wordpress</code>有很棒的地方比如说操作简单、文章可以带密码（有些文章只开放给特定人群），当然缺点就是可定制性太低了，博文内部的插件很少很少，不想现在的’hexo’<code>NeXT</code>主题非常灵活。<br>最终，在我又一次打不开自己博客的时候，我选择了放弃<code>wordpress</code>，放弃自己买的主机，准备转战其他的地方。</p>
<p><b>博客中国、博客大巴</b>这些老牌BSP（Blog Service Provider）已经半死不活了。博客园、CSDN的博客技术性又太强了。当时的我始终逃避自己码代码，虽然对<code>hexo</code>早有耳闻，但是总感觉技术性太强一直不愿尝试。<br>最后找到了一个发布轻博文的地方——网易lofter，然而lofter现在的用户流量也大不如前。无奈，我最终还是选择了<code>hexo</code>+<code>github</code>。现在真的可以说是真香了。  </p>
<p>搭建的过程真的非常非常艰辛，从六月份一直到现在，花了不知道多少时间和多少精力，从<code>git</code>的使用到前端的学习，从<code>markdown</code>进阶到<code>next</code>博文内嵌的插件，每一项都学的我要疯掉。最困难的就是<code>next</code>主题更新的速度太快，根本找不到什么新版本的指导教程，只能自己一点一点摸索，借鉴别人的博客。最终才把自己的主题写好。期间受到过很多大佬的博客的启发：  </p>
<ul>
<li><p>内容方面<br><a href="https://www.cnfeat.com/">陈素封的博客</a>：陈素封老师是我搭建博客期间最佩服的博主，他的文章信息量极大，让我获益匪浅。</p>
</li>
<li><p>技术方面<br><a href="https://bestzuo.cn/">Sanarous的博客</a>：最好看的主题没有之一，我的博客的博文字体和配色基本都是借鉴这位大佬的。他的博客搭建系列对我的技术和审美的提升都非常大。他的博客也是我见过的最优秀的博客。  </p>
</li>
</ul>
<p>下面的博客各有可取之处，在搭建的过程中也给了我莫大的帮助：</p>
<p><a href="https://lruihao.cn/">李瑞豪的博客</a><br><a href="https://asdfv1929.github.io/">asdfv1929’s blog</a><br><a href="https://xian6ge.cn/">贤柳阁</a><br><a href="https://yfzhou.coding.me/">Felix</a>：这个主题真的让人眼前一亮<br><a href="https://www.zhyong.cn/">YouForever</a><br><a href="https://linchao1002.github.io">Linchao’s Blog</a></p>
<h1 id="我的生活"><a href="#我的生活" class="headerlink" title="我的生活"></a>我的生活</h1><p>博客搭建的具体过程已经忘得差不多了，也不想再费尽心思地回想和记录。<br>目前自己博客的定位当然不会是一个单纯的技术博客，平时也会post自己的学习笔记、健身记录、书影观后感、游记、摄影和随笔。<br>可以说这是自己的一个个人品牌吧，在接下来的日子里要不断地完善。<br>陈素封老师在自己地一篇文章中提到过写博客的意义：</p>
<ol>
<li>提供持续学习的动力</li>
<li>积累更多的知识</li>
<li>提高将事情讲清楚的能力</li>
<li>分享带来的连锁反应</li>
<li>帮你找到志同道合的人</li>
<li>记录成长</li>
<li>培养持续做一件事的能力</li>
<li>讨论反思</li>
<li>搜寻你意想不到的东西</li>
<li>一个人在做一件属于自己的事</li>
<li>互联网的身份识别</li>
</ol>
<p>以上意义对我来说，最重要的应该是1、5、10、11，还有就是让自己沉淀下来，能够去把信息碎片整合、归纳、扩展，形成自己独树一帜的观点。这些是博客对于我的意义。</p>
<div style='display: none'>
我现在的日程轨迹自己也非常地满意：
晚上十一点开始清理滴答清单的每日Checklist，然后为第二天安排任务。滴答清单的具体使用方法参考了课程《跟邹小强学用滴答清单》，课程在网易云课堂上应该有。滴答清单我用了快半年了，这是我目前接触的最完美的时间管理类app，我需要的功能它全部都有，而且有产品自己的对时间管理的一些想法。“收集箱”的存在对我有很大的帮助。  
下面是我每晚的checklist：

<div class="note info">
    1. 信息门户<br />
    2. 北邮人论坛十大<br />
    3. 清理阅读清单<br />
    4. qq官方通知群<br />
    5. 清理滴答清单<br />
    6. 整理知识碎片<br />
    7. 计算机院公众号
</div>

<p>每日的打卡清单包括：</p>
<div class="note success">
    1. 查看今天花了多少钱<br />
    2. 健身（z1.2.3.5.6）<br />
    3. 坚持记录<br />
    4. 阅读<br />
    5. 不发脾气<br />
    6. 背单词<br />
    7. 吃早餐<br />
    8. 喝水
</div>

<p>每日的咨询获得包括：36氪、澎湃新闻、部分微信公众号、网易云课堂、北邮人论坛<br>收集的app：<b>pocket</b>（很优秀的app！）<br>晚上记录的app：<b>卡片日记</b>（记录app里界面我最喜欢的了，每天记录的时候心情最重要，所以日记软件的颜值要求应该是最高的~）<br>然后有时间的时候再根据卡片日记里的想法形成长篇大论发到博客。<br>&lt;/div&gt;</p>
<p>然而、然而、最近课程真的太忙了啊！专业分流就跟转专业了一样，前两年学的东西和现在的专业都脱轨了啊！<br>这几天累的不行，也好久都没写博客了。</p>
<p>今天写的这一篇的内容一定还有太多不完善的地方，日后再慢慢细化吧。</p>
]]></content>
      <categories>
        <category>参省乎己</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>关于细节</title>
    <url>/201909/2019-09-24-%E5%85%B3%E4%BA%8E%E7%BB%86%E8%8A%82/</url>
    <content><![CDATA[<p>最近的生活中“细节”这个词出现了很多次。我们从小就被大人们叮嘱要“注意细节”，随着年龄的增长这个词很少再被人提起。这两天发生的一系列事情都让我回过头来重新关注这个词。  </p>
<p>近期让我重新注意到这个词的时候是在发给合伙人中秋茶话会的问卷时，标题后面“【复制】”两个字没有删掉，凤民学姐一句“要细心呐”让我突然楞了一下。上次听到这种提醒应该是在小学了。那个时候做错了自己本应该做对的题，会收到老师这样的提醒。  </p>
<p>我突然意识到自己在浮躁地做很多事情，这种做事的状态应该调整过来。自己想要做的事情太多，但是行动力没有预期的那么高，所以很多事情都没有做到百分百的完美。对于一个思想活跃的大学生来说，产生新鲜的想法是一件最廉价的事情，真正重要的是做事的行动力。现在的自己应该是有“做减法”的需求，一些事情要么就不做，要么就做到自己的百分之百。尤其是无法逃避的课程作业和课程设计，这些事情理应做到自己的最完美。  </p>
<p>在和李京老师的面谈中也提到了关于细节的一些问题。李京老师讲到的关于面试比赛的策划，项目组给出了106页的策划书——不管策划到底怎样，仅仅从策划书的量来看，就知道做这件事的人已经做到尽善尽美了。当我们在职场中或者在平时的学习生活中，我们不可能一上来就拥有很优越的机会，也不可能一下子就做出惊为天人的事情。那么我们的能力和出众点就体现在细节上，在细节上做到无可挑剔同样能给人留下很深的印象。“做好细节”能够让我们“被人注意到”。  </p>
<p>认真雕刻细节能够让我们给人留下很好的第一印象。今天欧老师在上课的时候提到免试研究生的复试，单单从一个学生的简历就能发现很多事情——那些认认真真琢磨简历的人至少说明他们把这件事情“放在心上”，这说明他们愿意把之后的时间投入到实验室，愿意和身边的同学交流等等。一份认真的简历能够表达很多东西。老师提醒我们，一定要注意细节，特别是在第一印象中的细节十分重要。  </p>
<p>今天在线上和一位快手的学长交流，他着重强调了“亮点”这个词，它可以是学历、专业、论文或者实践等等，重要的是我们要留意开始打造“个人品牌”。  </p>
<p>大厂不缺好学校的学生，比如快手一度清北比例高达40%，组里一半以上的清北中科院，但是永远缺乏岗位极度匹配的人。原因并非是大学的专业和研究方向不对口，也并非是高校的教育和职场脱节，而是我们一直是从大学的培养方案出发，去适应不同公司的需求；而非从岗位需求出发，面向岗位技能在大学中学习。这种培养方法是一把双刃剑，它虽然保证了对岗位的高度适应，但是也削弱了人的全面的能力，在社会飞速发展中，可能会随着职业的没落，这种培训方式的偏颇也就显现出来。  </p>
<p>我们也应该去尝试构建一种结果导向的培养方案，按照未来的需求在大学阶段集成能力，尤其是在大学专业划分模糊且行业发展迅速的时代。</p>
<p>今天：肝数据科学导论作业到3点，玩手机到4点。九点二十起床，马马虎虎听了课 （大数据技术基础），中午完了一会游戏，美美地吃了一顿，宿舍睡了一会儿，就去上课，没怎么认真听（数据科学导论）在研究博客地SEO。晚上看了好久的乐队的夏天。然后忙于各种琐事，一边学习一边聊天。</p>
<p>效率好低啊，明天还要写作业呢。</p>
]]></content>
      <categories>
        <category>参省乎己</category>
      </categories>
  </entry>
  <entry>
    <title>「学生宿舍管理系统」实验报告</title>
    <url>/201909/%E3%80%8C%E5%AD%A6%E7%94%9F%E5%AE%BF%E8%88%8D%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E3%80%8D%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>使用<code>Python</code>语言，设计一个小型的学生宿舍管理系统，系统用户为宿舍管理员。</p>
<span id="more"></span>
<h2 id="功能要求"><a href="#功能要求" class="headerlink" title="功能要求"></a>功能要求</h2><ol>
<li>学生信息：学号、姓名、性别（男/女）、宿舍房间号、联系电话。</li>
<li>系统功能<ol>
<li>可按学号查找某一位学生的具体信息</li>
<li>可以录入新的学生信息</li>
<li>可以显示现有的所有学生信息</li>
</ol>
</li>
</ol>
<h2 id="程序要求"><a href="#程序要求" class="headerlink" title="程序要求"></a>程序要求</h2><ol>
<li>使用函数、列表、字典、字符串、条件循环等解决问题；</li>
<li>程序规模在80~200行左右。</li>
</ol>
<hr>
<h2 id="任务分析"><a href="#任务分析" class="headerlink" title="任务分析"></a>任务分析</h2><p>实现宿舍管理程序的三个功能。<br>添加的功能包括：可以利用学生的姓名进行查找。<br>错误处理：在功能选择、输入学号、姓名、性别、宿舍房间号、联系电话时都有可能出现数据格式不正确的情况，需要请求用户重新输入。在查找失败时，需要向用户提供查找失败信息。</p>
<h2 id="模块划分"><a href="#模块划分" class="headerlink" title="模块划分"></a>模块划分</h2><p>共有一个主函数和三个模块函数：</p>
<ol>
<li><code>search_stu</code>可按照学号查找某一位学生的具体信息。（这里做了一个功能拓展，可以通过学生姓名来进行查找，如果有重名的同学都会查找出来）</li>
<li><code>add_stu</code>模块录入新的学生信息</li>
<li><code>show_all_students</code>显示现有的所有学生信息</li>
<li><code>main</code>函数进行功能选择</li>
</ol>
<h2 id="数据结构和关键算法"><a href="#数据结构和关键算法" class="headerlink" title="数据结构和关键算法"></a>数据结构和关键算法</h2><ol>
<li>导入<code>prettytable</code>模块，使输出结果更为美观。</li>
<li><code>stu_info</code>是一个$n * 5$ 的数组，其中$n$为学生数量</li>
</ol>
<hr>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><h3 id="search-stu函数"><a href="#search-stu函数" class="headerlink" title="search_stu函数"></a><code>search_stu</code>函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">search_stu</span>():</span><br><span class="line">    <span class="string">&quot;按照学号或姓名查找某一位学生的具体信息&quot;</span></span><br><span class="line">    find = -<span class="number">1</span></span><br><span class="line">    t = PrettyTable([<span class="string">&quot;学号&quot;</span>,<span class="string">&quot;姓名&quot;</span>,<span class="string">&quot;性别&quot;</span>,<span class="string">&quot;宿舍房间号&quot;</span>,<span class="string">&quot;联系电话&quot;</span>])</span><br><span class="line">    sea = <span class="built_in">input</span>(<span class="string">&quot;请输入要搜索的学号或姓名： &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> sea.isdigit() == <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(stu_info)):</span><br><span class="line">            <span class="keyword">if</span> stu_info[i][<span class="number">0</span>] == sea:</span><br><span class="line">                find = i</span><br><span class="line">                t.add_row(stu_info[i])</span><br><span class="line">    <span class="keyword">if</span> sea.isalpha() == <span class="literal">True</span>:</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(stu_info)):</span><br><span class="line">            <span class="keyword">if</span> stu_info[i][<span class="number">1</span>] == sea:</span><br><span class="line">                find = i</span><br><span class="line">                t.add_row(stu_info[i])</span><br><span class="line">    <span class="keyword">if</span> find == -<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;抱歉，未查找到该学生。&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(t)</span><br></pre></td></tr></table></figure>
<h3 id="add-stu函数"><a href="#add-stu函数" class="headerlink" title="add_stu函数"></a><code>add_stu</code>函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_stu</span>():</span><br><span class="line">    <span class="string">&quot;录入新的学生信息&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">50</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;新增学生&quot;</span>)</span><br><span class="line">    num = <span class="built_in">input</span>(<span class="string">&quot;请输入学号： &quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> num.isdigit() != <span class="literal">True</span>:</span><br><span class="line">        num = <span class="built_in">input</span>(<span class="string">&quot;输入错误，请重新输入： &quot;</span>)</span><br><span class="line">    name = <span class="built_in">input</span>(<span class="string">&quot;请输入姓名： &quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> name.isalpha() != <span class="literal">True</span>:</span><br><span class="line">        name = <span class="built_in">input</span>(<span class="string">&quot;输入错误，请重新输入： &quot;</span>)</span><br><span class="line">    sex = <span class="built_in">input</span>(<span class="string">&quot;请输入性别：（男/女） &quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> sex != <span class="string">&quot;男&quot;</span> <span class="keyword">and</span> sex != <span class="string">&quot;女&quot;</span>:</span><br><span class="line">        sex = <span class="built_in">input</span>(<span class="string">&quot;输入错误，请重新输入： &quot;</span>)</span><br><span class="line">    room_no = <span class="built_in">input</span>(<span class="string">&quot;请输入房间号： &quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> room_no.isdigit() != <span class="literal">True</span>:</span><br><span class="line">        room_no = <span class="built_in">input</span>(<span class="string">&quot;输入错误，请重新输入： &quot;</span>)</span><br><span class="line">    tel = <span class="built_in">input</span>(<span class="string">&quot;请输入电话：&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> tel.isdigit() != <span class="literal">True</span>:</span><br><span class="line">        tel = <span class="built_in">input</span>(<span class="string">&quot;输入错误，请重新输入： &quot;</span>)</span><br><span class="line">    stu = [num, name, sex, room_no, tel]</span><br><span class="line">    stu_info.append(stu)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;添加&quot;</span>+num+<span class="string">&quot;成功&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="show-all-students函数"><a href="#show-all-students函数" class="headerlink" title="show_all_students函数"></a><code>show_all_students</code>函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_all_students</span>():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(stu_info)):</span><br><span class="line">        table.add_row(stu_info[i])</span><br><span class="line">    <span class="built_in">print</span>(table)</span><br></pre></td></tr></table></figure>
<h3 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;欢迎使用【宿舍管理系统】&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;1.查找学生&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;2.新增学生&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;3.显示全部&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;0.退出系统&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;*&quot;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        instruct = <span class="built_in">input</span>(<span class="string">&quot;请选择希望执行的操作：&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> instruct == <span class="string">&quot;1&quot;</span>:</span><br><span class="line">            search_stu()</span><br><span class="line">        <span class="keyword">elif</span> instruct == <span class="string">&quot;2&quot;</span>:</span><br><span class="line">            add_stu()</span><br><span class="line">        <span class="keyword">elif</span> instruct == <span class="string">&quot;3&quot;</span>:</span><br><span class="line">            show_all_students()</span><br><span class="line">        <span class="keyword">elif</span> instruct == <span class="string">&quot;0&quot;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;欢迎再次使用【宿舍管理系统】&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;输入错误，请重新输入指令！&quot;</span>)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h2><h3 id="功能2-录入学生信息"><a href="#功能2-录入学生信息" class="headerlink" title="功能2. 录入学生信息"></a>功能2. 录入学生信息</h3><p><img src="https://s2.ax1x.com/2019/09/23/uCWEmF.jpg" alt=""></p>
<h3 id="功能3-显示所有学生信息"><a href="#功能3-显示所有学生信息" class="headerlink" title="功能3.显示所有学生信息"></a>功能3.显示所有学生信息</h3><p><img src="https://s2.ax1x.com/2019/09/23/uCWZTJ.jpg" alt=""></p>
<h3 id="功能1-根据学号或姓名进行查找"><a href="#功能1-根据学号或姓名进行查找" class="headerlink" title="功能1. 根据学号或姓名进行查找"></a>功能1. 根据学号或姓名进行查找</h3><ol>
<li><p>根据学号查找<br><img src="https://s2.ax1x.com/2019/09/23/uCWVw4.jpg" alt=""></p>
</li>
<li><p>根据姓名查找<br><img src="https://s2.ax1x.com/2019/09/23/uCWkOU.jpg" alt=""></p>
</li>
</ol>
<div class="note success">
可见，重名的学生被查找出来
</div>

<h3 id="功能0-退出系统"><a href="#功能0-退出系统" class="headerlink" title="功能0. 退出系统"></a>功能0. 退出系统</h3><p><img src="https://s2.ax1x.com/2019/09/23/uCW1OO.jpg" alt=""></p>
<h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p><img src="https://s2.ax1x.com/2019/09/23/uCWmk9.jpg" alt="指令选择错误"></p>
<p><img src="https://s2.ax1x.com/2019/09/23/uCWuf1.jpg" alt="信息录入错误"></p>
<p><img src="https://s2.ax1x.com/2019/09/23/uCWMSx.md.jpg" alt="查找错误"></p>
]]></content>
      <categories>
        <category>数据科学导论</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>实验室苦逼搬砖暑假生活纪实</title>
    <url>/201909/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E8%8B%A6%E9%80%BC%E6%90%AC%E7%A0%96%E6%9A%91%E5%81%87%E7%94%9F%E6%B4%BB%E7%BA%AA%E5%AE%9E/</url>
    <content><![CDATA[<div class="note primary">
    记录一下自己暑假在实验室做的一些事情和收获吧。<br />
    虽然进步很小很缓慢，但总归是有的。
</div>

<h2 id="7月13日"><a href="#7月13日" class="headerlink" title="7月13日"></a>7月13日</h2><ol>
<li><p>关于论文的主要内容，学长进行了讲解：<br /><br> <strong>任务目标：</strong>通过迁移学习实现用户对齐问题，并将对齐结果与其他的用户对其方法进行比较：其中的方法包括“监督类型的”和“非监督类型的”，最终论文里要将我们的方法与其他至少三四种方法进行比较。</p>
 <span id="more"></span>
</li>
<li><p>下面的时间应该做到：<br> 0）熟悉各数据集，每个数据集经过哪个函数变成什么样子？<br> <code>myspace</code>文件夹中，<code>.node</code>文件前一个数字表示结点标号，后面的表示用户名。<br> <code>.edges</code>文件每一行的两个数字表示边连接的两个节点。<br> <code>aminer.tar.gz</code>,<code>flicker.tar.gz</code>,<code>lastfm.tar.gz</code>,<code>linkedin.tar,gz</code>,<code>livejournal.tar.gz</code>这五个压缩包都是上面形式的点和边<br> <code>aminer-linkedin.map.raw</code>文件，将<code>aminer.tar.gz</code>文件中的结点映射到<code>linkedin</code>上  </p>
<p> 1）<code>DRNE</code>（将图表示矩阵转化成向量）<br> 转化成的向量是什么格式？它是怎样表示矩阵的？它的输入和输出是怎样的？</p>
<p> 2）<code>wGAN</code>的一个变种函数（生成相应的对齐结果）<br> 它的输入和输出是怎样的？</p>
</li>
</ol>
<h2 id="7月14日"><a href="#7月14日" class="headerlink" title="7月14日"></a>7月14日</h2><p>非常艰难的一天，<code>DRNE</code>作者的<code>readme</code>文档写错了，指令是错误的，我第一次接触这个看不懂debug信息，学长也没发现。最后发邮件问原作者才知道<code>readme</code>中把<code>\</code>打成了<code>/</code>🤬<br>这一件事情花了我三天的时间，一开始以为自己的环境没搭建好，安装了各种库，利用<code>anaconda</code>创造了许多环境测试，我哭了。</p>
<ol>
<li><p>关于安装<code>tensorflow</code>的方法：<br> <a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-2-install/">莫凡Python</a><br> <a href="https://www.cnblogs.com/lvsling/p/8672404.html">ling’s bolg</a></p>
<p> <a href="https://www.jianshu.com/p/28e2ae6fbd75">安装时遇到的问题</a></p>
</li>
<li><p>上面这些乱七八糟的都不如直接<code>pip install</code>，觉得慢的话换成清华镜像资源<a href="https://mirrors.tuna.tsinghua.edu.cn/">清华大学开源软件镜像站</a></p>
</li>
</ol>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/pypi/">pypi镜像使用帮助</a></p>
<h2 id="7月15日"><a href="#7月15日" class="headerlink" title="7月15日"></a>7月15日</h2><div class="note primary">
    学长又分配了两个任务，第一个是判断图是否为连通图。 <br /> 
    其实要是只有几个点倒简单，但是仅仅接触了一点`Python`就要写个几千点判断连通图的程序，我想到的第一点是效率会非常低。。。最后这个代码学长亲自写了。
</div>

<p>这里顺带复习了一下数据结构的东西</p>
<ol>
<li>邻接矩阵与邻接表<br> <a href="https://www.cnblogs.com/icode-girl/p/5273209.html">邻接矩阵</a></li>
<li>边表<br> 边集表，图的储存结构之一。边表由表头结点和表结点两部分组成，图中每个顶点均对应一个存储在数组中的表头结点。<br> 边表存储了以点为起点的边的信息，邻接表存储了以点为出发点的点的信息。 </li>
<li>edgelist边表中每行有两个数，表示这两个结点之间有边</li>
<li>python nx.has_path(G, source, target)用来判断是否为连通图</li>
<li>networkx库查阅资料：<br><a href="https://www.cnblogs.com/kaituorensheng/p/5423131.html">network资料</a><br>NetworkX是一个用Python语言开发的图论与复杂网络建模工具，内置了常用的图与复杂网络分析算法，可以方便的进行复杂网络数据分析、仿真建模等工作。networkx支持创建简单无向图、有向图和多重图（multigraph）；内置许多标准的图论算法，节点可为任意数据；支持任意的边值维度，功能丰富，简单易用。<br><a href="https://networkx.github.io/documentation/stable/tutorial.html">network官方文档</a>  </li>
</ol>
<p>发现文档里举的例子都是自己输入的个别的点，我可以先研究一下DRNE的代码，从里面得到一些有用的内容。</p>
<p>代码看不懂的地方，首先就是embedding：<br><a href="https://blog.csdn.net/songyunli1111/article/details/85100616">关于embedding</a></p>
<h2 id="7月16日"><a href="#7月16日" class="headerlink" title="7月16日"></a>7月16日</h2><ol>
<li>CONSNET数据集：<br> deepwalk-master先不用，做对比算法的<br> DRNE-master 用来做embedding的<br> GAN用来生成模型  </li>
<li>关于anaconda的使用：<br> Anaconda是一个方便的python包管理和环境管理软件，一般用来配置不同的项目环境。<br> 我们常常会遇到这样的情况，正在做的项目A和项目B分别基于python2和python3，而第电脑只能安装一个环境，这个时候Anaconda就派上了用场，它可以创建多个互不干扰的环境，分别运行不同版本的软件包，以达到兼容的目的。<br> Anaconda通过管理工具包、开发环境、Python版本，大大简化了你的工作流程。不仅可以方便地安装、更新、卸载工具包，而且安装时能自动安装相应的依赖包，同时还能使用不同的虚拟环境隔离不同要求的项目。<br> <a href="https://www.jianshu.com/p/742dc4d8f4c5">Anaconda入门</a></li>
</ol>
<h2 id="7月17日"><a href="#7月17日" class="headerlink" title="7月17日"></a>7月17日</h2><div class="note success">
    conda有一点好处是，如果你需要安装一个包，系统将自动检查这个包需要的前置包并且安装，比如你要安装TensorFlow，而TensorFlow会用到很多像前置包像pandas、matiplot等，如果你在单纯的python下没有安装pandas等包就直接安装TensorFlow，那么和有可能无法使用，而使用conda安装TensorFlow将会询问你并自动帮你把缺少的前置包安装好
</div>

<ol>
<li><p>使用anaconda先创建一个用于drne的环境<br> <img src="https://s2.ax1x.com/2019/09/28/u1d88U.png" alt=""><br> 安装以上环境<br> 其中添加的资源库都没有tensorflow == 1.2.0<br> 按照提示 </p>
 <blockquote><p>To search for alternate channels that may provide the conda package you’re looking for, navigate to <a href="https://anaconda.org">https://anaconda.org</a> and use the search bar at the top of the page.</p>
</blockquote>
<p> 去官网搜索资源即可下载</p>
<p> 环境安装完成</p>
</li>
<li><p>anaconda跑不出来，先学习anaconda的使用方法：<br> <a href="https://www.jianshu.com/p/eaee1fadc1e9">anaconda1</a></p>
<p> <a href="https://i.xdc.at/2017/08/13/add-anaconda-prompt-to-context-menu-of-explorer/">anaconda2</a></p>
<p> <a href="https://blog.csdn.net/c20081052/article/details/88839479">anaconda3</a></p>
</li>
</ol>
<h2 id="7月19日"><a href="#7月19日" class="headerlink" title="7月19日"></a>7月19日</h2><p>继续研究network库</p>
<h2 id="7月21日"><a href="#7月21日" class="headerlink" title="7月21日"></a>7月21日</h2><p>研读networkx的文档，在后面处理相关问题的时候会简单很多。<br>在学习图的过程中，遇到的问题：<br><img src="https://s2.ax1x.com/2019/09/28/u1wzTI.png" alt=""><br><img src="https://s2.ax1x.com/2019/09/28/u1wx0A.png" alt=""></p>
<p>最后一行输出，我记得莫凡python里有讲这个，关于迭代器的东西，然后搜索了一下，继续进行学习：<br><a href="https://blog.csdn.net/u014028063/article/details/80572234">Python迭代器</a></p>
<p><strong>任务：</strong><br>写一个可以将ground truth抽样的函数，给定一个列表，例如[0.3， 0.5， 0.7]，<br>0.3表示在groundtruth里面随机抽样30%，并生成名为new-gt-0.3.txt的文件，列表长度为多少，就生成多少个这样的文件。</p>
<h2 id="7月22日"><a href="#7月22日" class="headerlink" title="7月22日"></a>7月22日</h2><p>readme文档中AcrossNetworkEmbeddingData文件夹里的文件和实际文件夹里的不一样，是否有问题？</p>
<p>anchor users 定位用户</p>
<h2 id="7月23日"><a href="#7月23日" class="headerlink" title="7月23日"></a>7月23日</h2><p>读学长写的：</p>
<ol>
<li><p>连通图代码<br>numpy.zeros<br><a href="https://blog.csdn.net/qq_28618765/article/details/78085457">https://blog.csdn.net/qq_28618765/article/details/78085457</a></p>
</li>
<li><p>抽样代码<br>自己完成：数据转换代码<br>python open函数的参数<br><a href="https://www.runoob.com/python/python-func-open.html">https://www.runoob.com/python/python-func-open.html</a></p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/qq_33254870/article/details/81668297">https://blog.csdn.net/qq_33254870/article/details/81668297</a></p>
<p><a href="https://cloud.tencent.com/developer/ask/172682">https://cloud.tencent.com/developer/ask/172682</a></p>
<font color="FF0000">一定要系统地学一下python！要不然什么都不会，写起来效率太低了！！</font>

<p>怎样用csvreader读入用tab分隔的文件——直接用\t</p>
<p><a href="https://www.runoob.com/python/att-list-len.html">https://www.runoob.com/python/att-list-len.html</a></p>
<p>for while if后面都要有冒号</p>
<p>python的‘和’符号是 and</p>
<p>关于newline参数</p>
<h2 id="7月24日"><a href="#7月24日" class="headerlink" title="7月24日"></a>7月24日</h2><div class="note danger">
    把trans_result打成了tranns_result，出现问题，，，，，
    python也没有报错，还好自己发现了
</div>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">0</span></span><br><span class="line">	<span class="keyword">while</span>(i &lt; <span class="built_in">len</span>(trans_result)):</span><br><span class="line">		<span class="comment"># print(&quot;Delete process...&quot;)</span></span><br><span class="line">		<span class="keyword">if</span>(trans_result[i][<span class="number">0</span>] == <span class="number">0</span> <span class="keyword">or</span> trans_result[i][<span class="number">1</span>] == <span class="number">0</span>):</span><br><span class="line">			trans_result = np.delete(trans_result, i, axis = <span class="number">0</span>)</span><br><span class="line">		<span class="keyword">else</span>:<span class="comment">#！！！！注意这里的else！！！否则会出错</span></span><br><span class="line">			i = i + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<center>❤️ 🧡 💛 💚 💙 💜 </center>
<center>中间几天帮张老师查项目资料来着——关于“认知计算”和“意图推理”</center>

<h2 id="7月31日"><a href="#7月31日" class="headerlink" title="7月31日"></a>7月31日</h2><p>如何调出eclipse左边文件栏<br><a href="https://jingyan.baidu.com/article/a24b33cd3af41119ff002b7a.html"></a></p>
<p>anaconda prompt 切换到e盘：<br><a href="https://blog.csdn.net/c20081052/article/details/88839479"></a></p>
<p>drne配适自己的代码：<br>activate for_drne<br>e:</p>
<h2 id="8月4日"><a href="#8月4日" class="headerlink" title="8月4日"></a>8月4日</h2><p>coursera视频无法播放<br><a href="https://blog.csdn.net/qq_39521554/article/details/79039548">https://blog.csdn.net/qq_39521554/article/details/79039548</a></p>
<p>欧式距离</p>
<p><a href="https://www.cnblogs.com/kimkat/p/9938475.html">https://www.cnblogs.com/kimkat/p/9938475.html</a></p>
<p>测试程序（把程序拆成几小部分）</p>
<ol>
<li>np.linalg.norm(vec1 - vec2)</li>
<li>读入部分，怎样读出来两个向量</li>
</ol>
<p>python cookbook 真的能学到很多东西！！<br>挺有用！</p>
<p><a href="https://zhidao.baidu.com/question/115008008.html">https://zhidao.baidu.com/question/115008008.html</a></p>
<p><a href="https://www.cnblogs.com/bakari/p/4807847.html">https://www.cnblogs.com/bakari/p/4807847.html</a></p>
<h2 id="8月5日"><a href="#8月5日" class="headerlink" title="8月5日"></a>8月5日</h2><ol>
<li><p>查数据类型：<br><a href="https://www.cnblogs.com/carlber/p/9362584.html">https://www.cnblogs.com/carlber/p/9362584.html</a></p>
</li>
<li><p>列表最后有一个逗号，就会多出来一个空元素<br><a href="https://www.cnblogs.com/lostme/articles/8857083.html">https://www.cnblogs.com/lostme/articles/8857083.html</a></p>
</li>
<li><p>operands could not be broadcast together with shapes (2,) (250,)<br><a href="https://blog.csdn.net/Odyssues_lee/article/details/85244735">https://blog.csdn.net/Odyssues_lee/article/details/85244735</a></p>
</li>
<li><p>运行map（）后，报：map object at 0x02629E50解决方法与原因分析​​​​​​​<br><a href="https://blog.csdn.net/weixin_40807247/article/details/82797378">https://blog.csdn.net/weixin_40807247/article/details/82797378</a></p>
</li>
</ol>
<p><a href="https://www.cnblogs.com/hwd9654/p/5707920.html">https://www.cnblogs.com/hwd9654/p/5707920.html</a></p>
<ol>
<li><p>从字符串中提取数字：<br><a href="https://www.cnblogs.com/dancesir/p/11021829.html">https://www.cnblogs.com/dancesir/p/11021829.html</a></p>
</li>
<li><p>python中，“<filter object at 0x028A2050>”是什么意思？怎么解决？<br><a href="https://zhidao.baidu.com/question/329317296.html">https://zhidao.baidu.com/question/329317296.html</a></p>
</li>
<li><p>数据格式要求很严格：<br>3   2<br>5  4<br>7  6<br>9  7<br>tab和x个空格不一样</p>
</li>
<li><p>输出百分比：<br><a href="https://blog.csdn.net/u013553529/article/details/78567696">https://blog.csdn.net/u013553529/article/details/78567696</a></p>
</li>
</ol>
<h2 id="8月7日"><a href="#8月7日" class="headerlink" title="8月7日"></a>8月7日</h2><p>博客搭建<br><a href="https://blog.csdn.net/fangquan1980/article/details/80648171">https://blog.csdn.net/fangquan1980/article/details/80648171</a></p>
<p><a href="https://blog.csdn.net/zyupupup/article/details/85098366">https://blog.csdn.net/zyupupup/article/details/85098366</a></p>
<p><a href="https://blog.csdn.net/weixin_42419856/article/details/81141546">https://blog.csdn.net/weixin_42419856/article/details/81141546</a></p>
<p><a href="https://blog.csdn.net/lvsehaiyang1993/article/details/80881433">https://blog.csdn.net/lvsehaiyang1993/article/details/80881433</a></p>
<p><a href="http://zhangchunlei.com/blog/2014/12/01/modify-a-record-of-my-website-dns/">http://zhangchunlei.com/blog/2014/12/01/modify-a-record-of-my-website-dns/</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">On a Windows machine, you&#x27;ll want to run nslookup your-domain.com and ensure that the output does not include any of the deprecated IP addresses (207.97.227.XXX, 204.232.175.XX, or 199.27.73.XXX).</span><br><span class="line">If you&#x27;re on a Mac or Linux machine, simply paste this command into a terminal window, replacing your-domain.com with, your site&#x27;s domain. dig your-domain.com | grep -E &#x27;(207.97.227.245|204.232.175.78|199.27.73.133)&#x27; || echo &quot;OK&quot;. If you see the word &quot;OK&quot;, you&#x27;re all set.</span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/a1023182899/article/details/77461567">https://blog.csdn.net/a1023182899/article/details/77461567</a></p>
<h2 id="8月8日"><a href="#8月8日" class="headerlink" title="8月8日"></a>8月8日</h2><p><a href="https://www.v2ex.com/amp/t/465570">https://www.v2ex.com/amp/t/465570</a></p>
<p>LINE（PALE中）<br>GAN<br>画圈</p>
<h2 id="8月11日"><a href="#8月11日" class="headerlink" title="8月11日"></a>8月11日</h2><p>xlrd模块：<br><a href="https://www.cnblogs.com/insane-Mr-Li/p/9092619.html">https://www.cnblogs.com/insane-Mr-Li/p/9092619.html</a></p>
<h2 id="8月13日"><a href="#8月13日" class="headerlink" title="8月13日"></a>8月13日</h2><ol>
<li><p>random.choices<br><a href="https://blog.csdn.net/lcqin111/article/details/83504029">https://blog.csdn.net/lcqin111/article/details/83504029</a></p>
</li>
<li><p>Cannot feed value of shape (256, 255) for Tensor ‘Placeholder:0’, which has shape ‘(?, 256)’<br><a href="http://www.mamicode.com/info-detail-2346029.html">http://www.mamicode.com/info-detail-2346029.html</a></p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4000</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--------------training---------DDDDDD----------EPOCH：&quot;</span> + <span class="built_in">str</span>(i) + <span class="string">&quot;-----------------------&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        mm = np.reshape(random.choices(f_d, f_g, k=<span class="number">256</span>))</span><br><span class="line">        nn = np.reshape(random.choices(t_d, t_g, k=<span class="number">256</span>))</span><br><span class="line">        rms_train1, loss1 = sess.run([model.rms_train_op1, model.loss_d], feed_dict=&#123;model.s: np.array(random.choices(f_d, f_g, k=<span class="number">256</span>)), model.t: np.array(random.choices(t_d, t_g, k=<span class="number">256</span>))&#125;)</span><br><span class="line">        <span class="keyword">for</span> every <span class="keyword">in</span> model.clip:</span><br><span class="line">            sess.run(every)</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>7.13<br>了解任务详情<br /></p>
<p>7.14<br>装相应的环境，跑DRNE，发现了文档的错误<br>DRNE在命令行窗口运行。<br>输入：edgelist<br>输出：.npy（需要再写程序转换为embedding）<br /></p>
<p>7.15<br>想要完成任务：判断是否为连通图<br>结果就是不行，，<br /></p>
<p>7.16<br>还在为DRNE的无脑错误 debug<br /></p>
<p>7.17<br>学习了anaconda的使用，还在跑DRNE，，<br /></p>
<p>7.18<br>DRNE，，<br /></p>
<p>7.19<br>完成一个可以将ground truth抽样的函数，例如[0.3, 0.5, 0.7]<br /></p>
<p>7.21<br>学习关于图的内容，不敢下手自己写代码<br /></p>
<p>7.22<br>开始跑IONE（java）<br /></p>
<p>7.23<br>数据转换代码，将cosnet数据集中的用户名转换成结点号<br /></p>
<p>7.24<br>删去edges里面没有在groundtruth中出现的记录，以此来缩小数据集<br /></p>
<p>7.25<br>用学长改过的代码跑ione<br /></p>
<p>7.31<br>用anaconda环境跑DRNE<br /></p>
<p>8.4<br>写计算距离，画圈的代码<br /></p>
<p>8.5<br>计算距离的代码，注意数据格式<br /></p>
<p>8.7<br>博客搭建<br /></p>
<p>8.8<br>跑PALE中的LINE，尝试WGAN<br /></p>
<p>8.11<br>跑学长改过的WGAN<br /></p>
<p>8.11<br>跑学长改过的WGAN完成，DRNE结果的npy转成txt<br /></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
        <tag>Anaconda</tag>
        <tag>DRNE</tag>
        <tag>IONE</tag>
        <tag>WGAN</tag>
        <tag>PALE</tag>
      </tags>
  </entry>
  <entry>
    <title>30天自制操作系统（27）</title>
    <url>/201905/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8827%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY27-LDT与库"><a href="#DAY27-LDT与库" class="headerlink" title="DAY27_LDT与库"></a>DAY27_LDT与库</h1><h2 id="1-先来修复bug"><a href="#1-先来修复bug" class="headerlink" title="1. 先来修复bug"></a>1. 先来修复bug</h2><p>bug：用nsct命令运行的应用程序，无论是按Shift+F1还是点击窗口的”x”按钮狗没有反应。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">task_run(task, -1, 0);</span><br></pre></td></tr></table></figure></p>
<span id="more"></span>
<h2 id="2-应用程序运行时关闭命令行窗口"><a href="#2-应用程序运行时关闭命令行窗口" class="headerlink" title="2. 应用程序运行时关闭命令行窗口"></a>2. 应用程序运行时关闭命令行窗口</h2><ul>
<li>目标：在应用程序运行的时候无法关闭所对应的命令行窗口。</li>
<li>修改：1.让系统在按下”x”按钮的时候暂且将命令行窗口从画面上隐藏起来。（因为关闭命令行窗口会有延迟）<ol>
<li>当FIFO接收到从console.c发送的“关闭窗口”请求数据时所进行的处理，主要是释放指定的图层。</li>
</ol>
</li>
</ul>
<h2 id="3-保护应用程序-1"><a href="#3-保护应用程序-1" class="headerlink" title="3. 保护应用程序(1)"></a>3. 保护应用程序(1)</h2><p>破坏程序：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[FORMAT &quot;WCOFF&quot;] </span><br><span class="line">[INSTRSET &quot;i486p&quot;] </span><br><span class="line">[BITS 32] </span><br><span class="line">[FILE &quot;crack7.nas&quot;] </span><br><span class="line">    GLOBAL _HariMain </span><br><span class="line">[SECTION .text] </span><br><span class="line">_HariMain: </span><br><span class="line">     MOV AX,1005*8 </span><br><span class="line">     MOV DS,AX </span><br><span class="line">     CMP DWORD [DS:0x0004],&#x27;Hari&#x27; </span><br><span class="line">     JNE fin ; 不是应用程序，因此不执行任何操作</span><br><span class="line">     MOV ECX,[DS:0x0000] ; 读取该应用程序数据段的大小</span><br><span class="line">     MOV AX,2005*8 </span><br><span class="line">     MOV DS,AX </span><br><span class="line">crackloop: ; 整个用123填充</span><br><span class="line">     ADD ECX,-1 </span><br><span class="line">     MOV BYTE [DS:ECX],123 </span><br><span class="line">     CMP ECX,0 </span><br><span class="line">     JNE crackloop </span><br><span class="line">fin: ; 结束</span><br><span class="line">     MOV EDX,4 </span><br><span class="line">     INT 0x40</span><br></pre></td></tr></table></figure></p>
<h2 id="4-保护应用程序-2"><a href="#4-保护应用程序-2" class="headerlink" title="4. 保护应用程序(2)"></a>4. 保护应用程序(2)</h2><p>CPU为我们提供了解决方案，那就是LDT。<br>GDT: global descriptor table<br>LDT: local descriptor table<br>其中GDT中的段设置是供所有任务通用的，而LDT中的段设置只对某个应用程序有效。</p>
<h2 id="5-优化应用程序的大小"><a href="#5-优化应用程序的大小" class="headerlink" title="5. 优化应用程序的大小"></a>5. 优化应用程序的大小</h2><p>那么我们该怎么办呢？我们可以将这些函数做成不同的.obj文件，将_api_putchar等需要用到的函数和_api_openwin等不需要用到的函数分离开。</p>
<h2 id="6-库"><a href="#6-库" class="headerlink" title="6. 库"></a>6. 库</h2><p>如果像上一节那样，把函数拆分开来，并用连接器来进行连接的话，我们需要创建很多很多个.obj文件。当然，如果不拆分函数，而是做成一个大的.obj文件也可以（如同a_nask.obj），但这样的话应用程序没有引用的函数也会被包含进去，生成的应用程序文件就会像之前那样无端增大很多。<br>库：将很多个.obj文件打包成一个文件。<br>要创建一个库，我们首先需要.obj文件作为原材料，除此之外，我们还需要一个叫做库管理器的程序。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GOLIB = $(TOOLPATH)golib00.exe </span><br><span class="line"></span><br><span class="line">apilib.lib : Makefile $(OBJS_API) </span><br><span class="line"> $(GOLIB) $(OBJS_API) out:apilib.lib</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a.bim : a.obj apilib.lib Makefile </span><br><span class="line">  $(OBJ2BIM) @$(RULEFILE) out:a.bim map:a.map a.obj apilib.lib</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void api_putchar(int c); </span><br><span class="line">void api_putstr0(char *s); </span><br><span class="line">void api_putstr1(char *s, int l); </span><br><span class="line">void api_end(void); </span><br><span class="line">int api_openwin(char *buf, int xsiz, int ysiz, int col_inv, char *title); </span><br><span class="line">void api_putstrwin(int win, int x, int y, int col, int len, char *str); </span><br><span class="line">void api_boxfilwin(int win, int x0, int y0, int x1, int y1, int col); </span><br><span class="line">void api_initmalloc(void); </span><br><span class="line">char *api_malloc(int size); </span><br><span class="line">void api_free(char *addr, int size); </span><br><span class="line">void api_point(int win, int x, int y, int col); </span><br><span class="line">void api_refreshwin(int win, int x0, int y0, int x1, int y1);</span><br><span class="line">void api_linewin(int win, int x0, int y0, int x1, int y1, int col); </span><br><span class="line">void api_closewin(int win); </span><br><span class="line">int api_getkey(int mode); </span><br><span class="line">int api_alloctimer(void); </span><br><span class="line">void api_inittimer(int timer, int data); </span><br><span class="line">void api_settimer(int timer, int time); </span><br><span class="line">void api_freetimer(int timer); </span><br><span class="line">void api_beep(int tone);</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &quot;apilib.h&quot;</span><br></pre></td></tr></table></figure>
<h2 id="7-整理make环境"><a href="#7-整理make环境" class="headerlink" title="7. 整理make环境"></a>7. 整理make环境</h2><p>整理操作系统、库、应用程序的文件和代码。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（26）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8826%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY26-为窗口移动提速"><a href="#DAY26-为窗口移动提速" class="headerlink" title="DAY26_为窗口移动提速"></a>DAY26_为窗口移动提速</h1><h2 id="1-提高窗口的移动速度-1"><a href="#1-提高窗口的移动速度-1" class="headerlink" title="1. 提高窗口的移动速度(1)"></a>1. 提高窗口的移动速度(1)</h2><p>导致窗口移动速度慢的原因有很多，其中之一就是sheet_refreshmap的速度太慢。这个函数在<br>sheet_slide中被调用了两次，如果能提高它的速度效果应该会很明显。</p>
<h2 id="2-提高窗口的移动速度-2"><a href="#2-提高窗口的移动速度-2" class="headerlink" title="2. 提高窗口的移动速度(2)"></a>2. 提高窗口的移动速度(2)</h2><span id="more"></span>
<p>sheet_refreshmap中有这样一句<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">map[vy * ctl-&gt;xsize + vx] = sid;</span><br></pre></td></tr></table></figure></p>
<p>在汇编语言中，如果我们用16位寄存器代替8位寄存器来执行MOV指令的话，相邻的地址中也会同时写入数据，而如果用32位寄存器，仅1条指令就可以同时向相邻的4个地址写入值了。<br>更重要的是，即便是同时写入4个字节的值，只要指定地址是4的整数倍，指令的执行速度就<br>和1个字节的MOV是相同的。也就是说，速度说不定能提高到原来的4倍！</p>
<h2 id="3-提高窗口移动速度-3"><a href="#3-提高窗口移动速度-3" class="headerlink" title="3.提高窗口移动速度(3)"></a>3.提高窗口移动速度(3)</h2><p>于是我们首先想到了sheet_refreshsub，窗口移动的时候也调用了这个函数，因此通过修改它可以提高窗口移动的速度，此外其他一些地方也会调用这个函数。</p>
<h2 id="4-提高窗口移动速度-4"><a href="#4-提高窗口移动速度-4" class="headerlink" title="4.提高窗口移动速度(4)"></a>4.提高窗口移动速度(4)</h2><p>为什么明明已经放开了鼠标键，窗口却还在挪动呢？这是因为伴随图层移动所进行的绘图操<br>作非常消耗时间，导致系统来不及处理FIFO中的鼠标移动数据。那么我们可以在接收到鼠标移动数据后不立即进行绘图操作，但如果一直不绘图的话鼠标和窗口就静止不动了，那不就没意义了吗？我们可以等FIFO为空时再进行绘图操作嘛。</p>
<h2 id="5-启动时只打开一个命令行窗口"><a href="#5-启动时只打开一个命令行窗口" class="headerlink" title="5.启动时只打开一个命令行窗口"></a>5.启动时只打开一个命令行窗口</h2><p>一般都是先打开一个命令行窗口，然后根据需要增加。下面我们就将启动时显示的命令行窗口数量改为一个，并且实现可以随意启动新命令行窗口的功能吧。</p>
<hr>
<p>在Windows中，即便不在命令行中输入命令，只通过鼠标的操作也可以打开新的命令行窗口。不过鼠标点击开始菜单这种方式实现起来太难，我们还是做快捷键吧。</p>
<h2 id="6-增加更多的命令行窗口"><a href="#6-增加更多的命令行窗口" class="headerlink" title="6.增加更多的命令行窗口"></a>6.增加更多的命令行窗口</h2><h2 id="7-关闭命令行窗口-1"><a href="#7-关闭命令行窗口-1" class="headerlink" title="7. 关闭命令行窗口(1)"></a>7. 关闭命令行窗口(1)</h2><p>在Windows的命令行窗口中，输入“exit”命令就可以关闭当前窗口.<br>在关闭一个命令行窗口时系统需要做些什么事呢？首先需要将创建该窗口时所占用的内存<br>空间全部释放出来，然后还需要释放窗口的图层和任务结构。咦，问题来了，在创建任务时我们为命令行窗口准备了专用的栈，却没有将这个栈的地址保存起来，这样的话就无法执行释放操作了。怎么办呢？我们可以在TASK结构中添加一个cons_stack成员，用来保存栈的地址。</p>
<h2 id="8-关闭命令行窗口-2"><a href="#8-关闭命令行窗口-2" class="headerlink" title="8. 关闭命令行窗口(2)"></a>8. 关闭命令行窗口(2)</h2><p>实现用鼠标关闭命令行窗口的功能。当鼠标点击窗口上的“×”按钮时，向命令行窗口任务发送4这个数据，命令行窗口接收到这个数据后则开始执行exit命令的程序。</p>
<h2 id="9-start命令"><a href="#9-start命令" class="headerlink" title="9.start命令"></a>9.start命令</h2><p>Windows的命令行窗口里有一个start命令，它的功能是可以打开一个新的命令行窗口并运行指定的应用程序。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void cmd_start(struct CONSOLE *cons, char *cmdline, int memtotal) </span><br><span class="line">&#123; </span><br><span class="line"> struct SHTCTL *shtctl = (struct SHTCTL *) *((int *) 0x0fe4); </span><br><span class="line"> struct SHEET *sht = open_console(shtctl, memtotal); </span><br><span class="line"> struct FIFO32 *fifo = &amp;sht-&gt;task-&gt;fifo; </span><br><span class="line"> int i; </span><br><span class="line"> sheet_slide(sht, 32, 4); </span><br><span class="line"> sheet_updown(sht, shtctl-&gt;top); </span><br><span class="line"> /*将命令行输入的字符串逐字复制到新的命令行窗口中*/ </span><br><span class="line"> for (i = 6; cmdline[i] != 0; i++) &#123; </span><br><span class="line"> fifo32_put(fifo, cmdline[i] + 256); </span><br><span class="line"> &#125; </span><br><span class="line"> fifo32_put(fifo, 10 + 256); /*回车键*/ </span><br><span class="line"> cons_newline(cons); </span><br><span class="line"> return; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="10-ncst命令"><a href="#10-ncst命令" class="headerlink" title="10. ncst命令"></a>10. ncst命令</h2><p>用start命令启动应用程序看起来很不错，但如果运行color这样的程序的话，我们并不希望真的新开一个命令行窗口出来，反倒是没有这个多余的窗口比较好。那么下面我们就来做一个不打开新命令行窗口的start命令吧，给它起个名字，叫做“no console start”，简称ncst命令。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（25）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8825%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY25-增加命令行窗口"><a href="#DAY25-增加命令行窗口" class="headerlink" title="DAY25_增加命令行窗口"></a>DAY25_增加命令行窗口</h1><h2 id="1-蜂鸣器发声"><a href="#1-蜂鸣器发声" class="headerlink" title="1.蜂鸣器发声"></a>1.蜂鸣器发声</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">蜂鸣器发声</span><br><span class="line">EDX=20 </span><br><span class="line">EAX=声音频率（单位是mHz，即毫赫兹）</span><br><span class="line">例如当EAX=4400000时，则发出440Hz的声音</span><br><span class="line">频率设为0则表示停止发声</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int *hrb_api(int edi, int esi, int ebp, int esp, int ebx, int edx, int ecx, int eax) </span><br><span class="line">&#123; </span><br><span class="line"> （中略）</span><br><span class="line"> &#125; else if (edx == 20) &#123; </span><br><span class="line"> if (eax == 0) &#123; </span><br><span class="line"> i = io_in8(0x61); </span><br><span class="line"> io_out8(0x61, i &amp; 0x0d); </span><br><span class="line"> &#125; else &#123; </span><br><span class="line"> i = 1193180000 / eax; </span><br><span class="line"> io_out8(0x43, 0xb6); </span><br><span class="line"> io_out8(0x42, i &amp; 0xff);</span><br><span class="line"> io_out8(0x42, i &gt;&gt; 8); </span><br><span class="line"> i = io_in8(0x61); </span><br><span class="line"> io_out8(0x61, (i | 0x03) &amp; 0x0f); </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> return 0; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-增加更多的颜色-1"><a href="#2-增加更多的颜色-1" class="headerlink" title="2.增加更多的颜色(1)"></a>2.增加更多的颜色(1)</h2><p>修改graphic.c<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void init_palette(void) </span><br><span class="line">&#123; </span><br><span class="line"> static unsigned char table_rgb[16 * 3] = &#123; </span><br><span class="line"> （中略）</span><br><span class="line"> &#125;; </span><br><span class="line"> unsigned char table2[216 * 3]; </span><br><span class="line"> int r, g, b; </span><br><span class="line"> set_palette(0, 15, table_rgb); </span><br><span class="line"> for (b = 0; b &lt; 6; b++) &#123; </span><br><span class="line"> for (g = 0; g &lt; 6; g++) &#123; </span><br><span class="line"> for (r = 0; r &lt; 6; r++) &#123; </span><br><span class="line"> table2[(r + g * 6 + b * 36) * 3 + 0] = r * 51; </span><br><span class="line"> table2[(r + g * 6 + b * 36) * 3 + 1] = g * 51; </span><br><span class="line"> table2[(r + g * 6 + b * 36) * 3 + 2] = b * 51; </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> set_palette(16, 231, table2); </span><br><span class="line"> return; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="3-增加更多的颜色-2"><a href="#3-增加更多的颜色-2" class="headerlink" title="3.增加更多的颜色(2)"></a>3.增加更多的颜色(2)</h2><p>我们可以用两种颜色交替排列，看上去就像这两种颜色混合在一起一样，这就是要点。颜色的混合方式我们考虑了下面3种（算上完全不混合的情况，一共有5种）。<br><img src="https://s2.ax1x.com/2019/04/28/El968s.jpg" alt="25.1"></p>
<h2 id="4-窗口初始位置"><a href="#4-窗口初始位置" class="headerlink" title="4. 窗口初始位置"></a>4. 窗口初始位置</h2><p>因此我们希望让窗口总是显示在画面的中央，而且显示窗口时的图层高度也不能总是固定为3，而是要判断当前画面中窗口的数量并自动显示在最上面。</p>
<h2 id="5-增加命令行窗口-1"><a href="#5-增加命令行窗口-1" class="headerlink" title="5. 增加命令行窗口(1)"></a>5. 增加命令行窗口(1)</h2><p>于是，我们这次只修改bootpack.c，将命令行窗口的相关变量（buf_cons、sht_cons、task_cons和cons）各准备2个，分别分给命令行1和命令行2。</p>
<h2 id="6-增加命令行窗口-2"><a href="#6-增加命令行窗口-2" class="headerlink" title="6.增加命令行窗口(2)"></a>6.增加命令行窗口(2)</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct CONSOLE *cons = (struct CONSOLE *) *((int *) 0x0fec);</span><br></pre></td></tr></table></figure>
<p>这里的cons变量是用来判断“要向哪个命令行窗口输出字符”的关键。该变量的值是从内存地址0x0fec读取出来的，而无论从哪个任务读取这个内存地址中的值，得到的肯定都是同一个值，因此不管在哪个窗口中运行a.hrb，都只能在固定的其中一个窗口中显示字符。</p>
<h2 id="7-增加命令行窗口-3"><a href="#7-增加命令行窗口-3" class="headerlink" title="7. 增加命令行窗口(3)"></a>7. 增加命令行窗口(3)</h2><p>问题出在cmd_app身上<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set_segmdesc(gdt + 1003, finfo-&gt;size - 1, (int) p, AR_CODE32_ER + 0x60); </span><br><span class="line"> set_segmdesc(gdt + 1004, segsiz - 1, (int) q, AR_DATA32_RW + 0x60); </span><br><span class="line"> （中略）</span><br><span class="line"> start_app(0x1b, 1003 * 8, esp, 1004 * 8, &amp;(task-&gt;tss.esp0));</span><br><span class="line"> </span><br></pre></td></tr></table></figure></p>
<p>首先，color.hrb在某个窗口中被运行，启动程序一切顺利，然后显示窗口并绘图，接下来等待键盘输入并进入休眠状态。到这里为止没有任何问题。<br>然后我们在另外一个窗口中运行color.hrb，程序也顺利启动了，显示窗口并绘图，随后进入休眠状态。然而在这个时候，问题其实已经发生了。这是怎么回事呢？因为我们为color.hrb准备的1003号代码段和1004号数据段，被color2.hrb所用的段给覆盖掉了。<br>因此，当按下回车键唤醒color.hrb时，就会发生异常情况——明明应该去运行color.hrb的，结果却错误地运行了color2.hrb，这样当然会出错了。</p>
<h2 id="8-增加命令行窗口-4"><a href="#8-增加命令行窗口-4" class="headerlink" title="8.增加命令行窗口(4)"></a>8.增加命令行窗口(4)</h2><p>这次的修改也很简单，首先将原来task_cons[0]的地方改为key_wintask和shttask，这样一来，用键盘强制结束时会以当前输入窗口为对象，而用鼠标点击“×”按钮时会以被点击的窗口为对象。</p>
<h2 id="9-变得更像真正的操作系统-1"><a href="#9-变得更像真正的操作系统-1" class="headerlink" title="9.变得更像真正的操作系统(1)"></a>9.变得更像真正的操作系统(1)</h2><h2 id="10-变得更像真正的操作系统-2"><a href="#10-变得更像真正的操作系统-2" class="headerlink" title="10.变得更像真正的操作系统(2)"></a>10.变得更像真正的操作系统(2)</h2><p>这样肯定不行，因为命令行窗口任务的优先级比较低，只有当bootpack.c的HariMain休眠之后才会运行命令行窗口任务，而如果不运行这个任务的话，FIFO缓冲区就不会被初始化，这就相当于我们在向一个还没初始化的FIFO强行发送数据，于是造成fifo32_put混乱而导致重启。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（24）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8824%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY24-窗口操作"><a href="#DAY24-窗口操作" class="headerlink" title="DAY24_窗口操作"></a>DAY24_窗口操作</h1><h2 id="1-窗口切换-1"><a href="#1-窗口切换-1" class="headerlink" title="1.窗口切换(1)"></a>1.窗口切换(1)</h2><ul>
<li>目标：实现切换窗口顺序得功能。</li>
<li>先实现按下F11时，将最下面得那个窗口放到最上面。</li>
</ul>
<span id="more"></span>
<hr>
<p>修改bootpack.c<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (i == <span class="number">256</span> + <span class="number">0x57</span> &amp;&amp; shtctl-&gt;top &gt; <span class="number">2</span>) &#123; <span class="comment">/* F11 */</span> </span><br><span class="line">    sheet_updown(shtctl-&gt;sheets[<span class="number">1</span>], shtctl-&gt;top - <span class="number">1</span>); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="2-窗口切换-2"><a href="#2-窗口切换-2" class="headerlink" title="2. 窗口切换(2)"></a>2. 窗口切换(2)</h2><p>我们需要按照从上到下得顺序，判断鼠标得位置落在哪个图层得范围内，并且还需要确保该位置不是透明色区域。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (j = shtctl-&gt;top - <span class="number">1</span>; j &gt; <span class="number">0</span>; j--) &#123; </span><br><span class="line">     sht = shtctl-&gt;sheets[j]; </span><br><span class="line">     x = mx - sht-&gt;vx0; </span><br><span class="line">     y = my - sht-&gt;vy0; </span><br><span class="line">     <span class="keyword">if</span> (<span class="number">0</span> &lt;= x &amp;&amp; x &lt; sht-&gt;bxsize &amp;&amp; <span class="number">0</span> &lt;= y &amp;&amp; y &lt; sht-&gt;bysize) &#123; </span><br><span class="line">         <span class="keyword">if</span> (sht-&gt;buf[y * sht-&gt;bxsize + x] != sht-&gt;col_inv) &#123; </span><br><span class="line">             sheet_updown(sht, shtctl-&gt;top - <span class="number">1</span>); </span><br><span class="line">             <span class="keyword">break</span>; </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="3-移动窗口"><a href="#3-移动窗口" class="headerlink" title="3.移动窗口"></a>3.移动窗口</h2><p>当鼠标左键点击窗口时，如果点击位置位于窗口的标题栏区域，则进入“窗口移动模式”，使窗口的位置追随鼠标指针的移动，当放开鼠标左键时，退出“窗口移动模式”，返回通常模式。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (mmx &lt; <span class="number">0</span>) &#123; </span><br><span class="line">     <span class="comment">/*如果处于通常模式*/</span> </span><br><span class="line">     <span class="comment">/*按照从上到下的顺序寻找鼠标所指向的图层*/</span> </span><br><span class="line">     <span class="keyword">for</span> (j = shtctl-&gt;top - <span class="number">1</span>; j &gt; <span class="number">0</span>; j--) &#123; </span><br><span class="line">         sht = shtctl-&gt;sheets[j]; </span><br><span class="line">         x = mx - sht-&gt;vx0; </span><br><span class="line">         y = my - sht-&gt;vy0; </span><br><span class="line">         <span class="keyword">if</span> (<span class="number">0</span> &lt;= x &amp;&amp; x &lt; sht-&gt;bxsize &amp;&amp; <span class="number">0</span> &lt;= y &amp;&amp; y &lt; sht-&gt;bysize) &#123; </span><br><span class="line">            <span class="keyword">if</span> (sht-&gt;buf[y * sht-&gt;bxsize + x] != sht-&gt;col_inv) &#123; </span><br><span class="line">                sheet_updown(sht, shtctl-&gt;top - <span class="number">1</span>); </span><br><span class="line">                <span class="keyword">if</span> (<span class="number">3</span> &lt;= x &amp;&amp; x &lt; sht-&gt;bxsize - <span class="number">3</span> &amp;&amp; <span class="number">3</span> &lt;= y &amp;&amp; y &lt; <span class="number">21</span>) &#123; </span><br><span class="line">                    mmx = mx; <span class="comment">/*进入窗口移动模式*/</span> </span><br><span class="line">                    mmy = my; </span><br><span class="line">                &#125; </span><br><span class="line">            <span class="keyword">break</span>; </span><br><span class="line">            &#125; </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">&#125; <span class="keyword">else</span> &#123; </span><br><span class="line">     <span class="comment">/*如果处于窗口移动模式*/</span> </span><br><span class="line">     x = mx - mmx; <span class="comment">/*计算鼠标的移动距离*/</span> </span><br><span class="line">     y = my - mmy; </span><br><span class="line">     sheet_slide(sht, sht-&gt;vx0 + x, sht-&gt;vy0 + y); </span><br><span class="line">     mmx = mx; <span class="comment">/*更新为移动后的坐标*/</span> </span><br><span class="line">     mmy = my; </span><br><span class="line">     &#125; </span><br><span class="line">     &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">     <span class="comment">/*没有按下左键*/</span> </span><br><span class="line">    mmx = <span class="number">-1</span>; <span class="comment">/*返回通常模式*/</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="4-用鼠标关闭窗口"><a href="#4-用鼠标关闭窗口" class="headerlink" title="4.用鼠标关闭窗口"></a>4.用鼠标关闭窗口</h2><h2 id="5-将输入切换到应用程序窗口"><a href="#5-将输入切换到应用程序窗口" class="headerlink" title="5.将输入切换到应用程序窗口"></a>5.将输入切换到应用程序窗口</h2><p>按下Tab键时将键盘输入切换到当前输入窗口下面一层的窗口中，若当前窗口为最下层，则切换到最上层窗口。</p>
<hr>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (key_win == sht_win) &#123; <span class="comment">/*发送至任务A */</span> </span><br><span class="line"> <span class="keyword">if</span> (cursor_x &lt; <span class="number">128</span>) &#123; </span><br><span class="line"> <span class="comment">/*显示一个字符并将光标后移一位*/</span> </span><br><span class="line"> s[<span class="number">1</span>] = <span class="number">0</span>; </span><br><span class="line">putfonts8_asc_sht(sht_win, cursor_x, <span class="number">28</span>, COL8_000000, COL8_FFFFFF, s, <span class="number">1</span>); </span><br><span class="line"> cursor_x += <span class="number">8</span>;</span><br><span class="line"> &#125; </span><br><span class="line"> &#125; <span class="keyword">else</span> &#123; <span class="comment">/*发送至命令行窗口*/</span> </span><br><span class="line"> fifo32_put(&amp;key_win-&gt;task-&gt;fifo, s[<span class="number">0</span>] + <span class="number">256</span>); </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> (i == <span class="number">256</span> + <span class="number">0x0e</span>) &#123; <span class="comment">/*退格键*/</span> </span><br><span class="line"> <span class="keyword">if</span> (key_win == sht_win) &#123; <span class="comment">/*发送至任务A */</span> </span><br><span class="line"> <span class="keyword">if</span> (cursor_x &gt; <span class="number">8</span>) &#123; </span><br><span class="line"> <span class="comment">/*用空格擦除光标后将光标前移一位*/</span> </span><br><span class="line"> putfonts8_asc_sht(sht_win, cursor_x, <span class="number">28</span>, COL8_000000, COL8_FFFFFF, <span class="string">&quot; </span></span><br><span class="line"><span class="string"> &quot;</span>, <span class="number">1</span>); </span><br><span class="line"> cursor_x -= <span class="number">8</span>; </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; <span class="keyword">else</span> &#123; <span class="comment">/*发送至命令行窗口*/</span> </span><br><span class="line"> fifo32_put(&amp;key_win-&gt;task-&gt;fifo, <span class="number">8</span> + <span class="number">256</span>); </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> (i == <span class="number">256</span> + <span class="number">0x1c</span>) &#123; <span class="comment">/*回车键*/</span> </span><br><span class="line"> <span class="keyword">if</span> (key_win != sht_win) &#123; <span class="comment">/*发送至命令行窗口*/</span> </span><br><span class="line"> fifo32_put(&amp;key_win-&gt;task-&gt;fifo, <span class="number">10</span> + <span class="number">256</span>); </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> (i == <span class="number">256</span> + <span class="number">0x0f</span>) &#123; <span class="comment">/* Tab键*/</span> </span><br><span class="line"> cursor_c = keywin_off(key_win, sht_win, cursor_c, cursor_x); </span><br><span class="line"> j = key_win-&gt;height - <span class="number">1</span>; </span><br><span class="line"> <span class="keyword">if</span> (j == <span class="number">0</span>) &#123; </span><br><span class="line"> j = shtctl-&gt;top - <span class="number">1</span>; </span><br><span class="line"> &#125; </span><br><span class="line"> key_win = shtctl-&gt;sheets[j]; </span><br><span class="line"><span class="comment">/*到此结束*/</span> cursor_c = keywin_on(key_win, sht_win, cursor_c); </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="6-用鼠标切换输入窗口"><a href="#6-用鼠标切换输入窗口" class="headerlink" title="6.用鼠标切换输入窗口"></a>6.用鼠标切换输入窗口</h2><p>目标：让操作系统可以通过简单的点击就能完成输入切换。  </p>
<h2 id="7-定时器API"><a href="#7-定时器API" class="headerlink" title="7.定时器API"></a>7.定时器API</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">获取定时器（alloc）</span><br><span class="line">EDX=16 </span><br><span class="line">EAX=定时器句柄（由操作系统返回）</span><br><span class="line"></span><br><span class="line">设置定时器的发送数据（init）</span><br><span class="line">EDX=17 </span><br><span class="line">EBX=定时器句柄</span><br><span class="line">EAX=数据</span><br><span class="line"></span><br><span class="line">定时器时间设定（set）</span><br><span class="line">EDX=18 </span><br><span class="line">EBX=定时器句柄</span><br><span class="line">EAX=时间</span><br><span class="line"></span><br><span class="line">释放定时器（free）</span><br><span class="line">EDX=19 </span><br><span class="line">EBX=定时器句柄</span><br></pre></td></tr></table></figure>
<h2 id="8-取消定时器"><a href="#8-取消定时器" class="headerlink" title="8.取消定时器"></a>8.取消定时器</h2><p>问题：<br>应用程序设置了一个1秒的定时器，当定时器到达指定时间时会产生超时，并向任务发送事先设置的数据。问题是，如果这时应用程序已经结束了，定时器的数据就会被发送到命令行窗口，而命令行窗口肯定是一头雾水。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>「迁移学习简明手册」学习笔记（1）</title>
    <url>/201908/%E3%80%8C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E6%98%8E%E6%89%8B%E5%86%8C%E3%80%8D%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/</url>
    <content><![CDATA[<h1 id="1-迁移学习的基本概念"><a href="#1-迁移学习的基本概念" class="headerlink" title="1.迁移学习的基本概念"></a>1.迁移学习的基本概念</h1><h2 id="1-2-迁移学习基本概念"><a href="#1-2-迁移学习基本概念" class="headerlink" title="1.2 迁移学习基本概念"></a>1.2 迁移学习基本概念</h2><ul>
<li>核心问题：找到新问题和原问题之间的相似性，才可以顺利地实现知识的迁移。</li>
<li>定义：迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用在新领域的一种学习过程。</li>
</ul>
<h2 id="1-3-为什么要迁移学习"><a href="#1-3-为什么要迁移学习" class="headerlink" title="1.3 为什么要迁移学习"></a>1.3 为什么要迁移学习</h2><p>这个表格包括了1.3的所有内容，可以只看这个表格：</p>
<p><img src="https://s2.ax1x.com/2019/04/24/EVv4IS.jpg" alt="1.3"></p>
<span id="more"></span>
<ul>
<li>1.大数据与少标注之间的矛盾</li>
<li>2.大数据与弱计算之间的矛盾</li>
<li>3.普适化模型与个性化需求之间的矛盾<br>机器学习的目标是构建一个尽可能通用的模型，而人们的个性化需求五花八门，短期内根本无法用一个通用的模型去满足。</li>
<li>4.特定应用的需求<br>推荐系统的冷启动问题：一个新的推荐系统，没有足够的用户数据，如何进行精准的推荐；一个崭新的图片标注系统，没有足够的标签，如何进行精准的服务？</li>
</ul>
<p><strong>针对以上问题，迁移学习是如何解决的呢？</strong></p>
<ul>
<li>1.迁移数据标注</li>
<li>2.模型迁移（将那些大公司在大数据上训练好的模型，迁移到我们的任务中）</li>
<li>3.自适应学习（对普适化模型进行灵活的调整，以便完成我们的任务）</li>
<li>4.相似领域知识迁移</li>
</ul>
<h2 id="1-4-与已有概念的区别和联系"><a href="#1-4-与已有概念的区别和联系" class="headerlink" title="1.4 与已有概念的区别和联系"></a>1.4 与已有概念的区别和联系</h2><h3 id="1-迁移学习和机器学习"><a href="#1-迁移学习和机器学习" class="headerlink" title="1.迁移学习和机器学习"></a>1.迁移学习和机器学习</h3><p>迁移学习属于机器学习的一类<br><img src="https://s2.ax1x.com/2019/04/24/EVxMQA.jpg" alt="2"></p>
<h3 id="2-迁移学习和多任务学习"><a href="#2-迁移学习和多任务学习" class="headerlink" title="2.迁移学习和多任务学习"></a>2.迁移学习和多任务学习</h3><p>多任务学习指多个相关的任务一起协同学习。</p>
<h3 id="3-迁移学习和终身学习"><a href="#3-迁移学习和终身学习" class="headerlink" title="3.迁移学习和终身学习"></a>3.迁移学习和终身学习</h3><p>终身学习是在已经学习好若干个任务之后，面对新的任务可以继续学习而不遗忘之前学习的任务。</p>
<h3 id="4-迁移学习和领域自适应"><a href="#4-迁移学习和领域自适应" class="headerlink" title="4.迁移学习和领域自适应"></a>4.迁移学习和领域自适应</h3><h3 id="5-迁移学习和增量学习"><a href="#5-迁移学习和增量学习" class="headerlink" title="5.迁移学习和增量学习"></a>5.迁移学习和增量学习</h3><p>增量学习侧重解决数据不断到来，模型不断更新的问题。</p>
<h3 id="6-迁移学习和自我学习"><a href="#6-迁移学习和自我学习" class="headerlink" title="6.迁移学习和自我学习"></a>6.迁移学习和自我学习</h3><p>自我学习指的是模型不断地从自身处进行更新</p>
<h3 id="7-迁移学习和协方差漂移"><a href="#7-迁移学习和协方差漂移" class="headerlink" title="7.迁移学习和协方差漂移"></a>7.迁移学习和协方差漂移</h3><p>协方差漂移指数据地边缘概率分布发生变化</p>
<h2 id="1-5-负迁移（“东施效颦”）"><a href="#1-5-负迁移（“东施效颦”）" class="headerlink" title="1.5 负迁移（“东施效颦”）"></a>1.5 负迁移（“东施效颦”）</h2><p>如果两个领域之间不存在相似性，或者基本不相似，那么就会大大损害迁移学习地效果。这时候，我们可以说出现了==负迁移(Negative Transfer)==  </p>
<ul>
<li>定义：在源域上学习到的知识，对于目标域上的学习产生负面作用。</li>
<li>产生负迁移的原因：<ul>
<li>数据问题</li>
<li>方法问题：源域和目标域是相似的，但是迁移学习的方法不够好。</li>
</ul>
</li>
<li>传递迁移学习：传统迁移学习好比是踩着一块石头过河，传递迁移学习就是踩着连续的两块石头。当两个领域不相似时，传递迁移学习却可以利用处于这两个领域之间的若干领域，将知识传递式的完成迁移。</li>
</ul>
<h1 id="2-迁移学习的研究领域"><a href="#2-迁移学习的研究领域" class="headerlink" title="2.迁移学习的研究领域"></a>2.迁移学习的研究领域</h1><p>机器学习可分为有监督、半监督和无监督的机器学习三大类。迁移学习也可以进行这样的分类。<br><img src="https://s2.ax1x.com/2019/04/24/EZVW1P.jpg" alt="t8"></p>
<p>分类的四个准则：按目标域有无标签分、按学习方法分、按特征分、按在线形式分</p>
<h2 id="2-1-按目标域标签分"><a href="#2-1-按目标域标签分" class="headerlink" title="2.1 按目标域标签分"></a>2.1 按目标域标签分</h2><ul>
<li>1.监督迁移学习 Supervised Transfer Learning</li>
<li>2.半监督迁移学习 Semi-Supervised Transfer Learning</li>
<li>3.无监督迁移学习 Unsupervised Transfer Learning  </li>
</ul>
<p>显然，少标签或无标签的问题（半监督和无监督迁移学习）<br>，是研究的热点和难点。</p>
<h2 id="2-2-按学习方法分类"><a href="#2-2-按学习方法分类" class="headerlink" title="2.2 按学习方法分类"></a>2.2 按学习方法分类</h2><ul>
<li>1.基于样本的迁移学习方法(Instance based Transfer Learning)<br>通过权重重用，对源域和目标域的样例进行迁移</li>
<li>2.基于==特征==的迁移学习方法(Feature based Transfer Leaning)<br>意思是说，假设源域和目标域的特征<br>原来不在一个空间，或者说它们在原来那个空间上不相似，那我们就想办法把它们变换到一个空间里面，那这些特征不就相似了？</li>
<li>3.基于==模型==的迁移学习方法(Model based Transfer Leaning)<br>构建参数共享的模型</li>
<li>4.基于关系的迁移学习方法(Relation based Transfer Learning)<br>挖掘和利用关系进行类比迁移</li>
</ul>
<h2 id="2-3-按特征分类"><a href="#2-3-按特征分类" class="headerlink" title="2.3 按特征分类"></a>2.3 按特征分类</h2><ul>
<li>1.同构迁移学习(Homogeneous Transfer Learning)</li>
<li>2.异构迁移学习(Heterogeneous Transfer Learning)<br>如果特征语义和维度都相同，那么就是同构；反之，如果特征完全不相同，那么就是异构。举个例子来说，不同图片的迁移，就可以认为是同构；而图片到文本的迁移，则是异构的。</li>
</ul>
<h2 id="2-4-按离线与在线形式分"><a href="#2-4-按离线与在线形式分" class="headerlink" title="2.4 按离线与在线形式分"></a>2.4 按离线与在线形式分</h2><ul>
<li>1.离线迁移学习(Offline Transfer Learning)</li>
<li>2.在线迁移学习(Online Transfer Learning)</li>
</ul>
<p>目前，绝大多数的迁移学习方法，都采用了离线方式。即，源域和目标域均是给定的，<br>迁移一次即可。这种方式的缺点是显而易见的：算法无法对新加入的数据进行学习，模型也无法得到更新。与之相对的，是在线的方式。即随着数据的动态加入，迁移学习算法也可以不断地更新。</p>
<h1 id="3-迁移学习的应用"><a href="#3-迁移学习的应用" class="headerlink" title="3.迁移学习的应用"></a>3.迁移学习的应用</h1><p>计算机视觉、文本分类、行为识别、自然语言处理、室内定位、视频监控、舆情分析、人机交互</p>
<h2 id="3-1-计算机视觉"><a href="#3-1-计算机视觉" class="headerlink" title="3.1 计算机视觉"></a>3.1 计算机视觉</h2><p>同一类图片，不同的拍摄角度、不同光照、不同背景，都会造成特征分布发生改变。因此，使用迁移学习构建跨领域的鲁棒分类器是十分重要的。</p>
<h2 id="3-2-文本分类"><a href="#3-2-文本分类" class="headerlink" title="3.2 文本分类"></a>3.2 文本分类</h2><p>由于文本数据有其领域特殊性，因此，在一个领域上训练的分类器，不能直接拿来作用到另一个领域上。这就需要用到迁移学习。例如，在电影评论文本数据集上训练好的分类器，不能直接用于图书评论的预测。这就需要进行迁移学习。</p>
<h2 id="3-3-时间序列"><a href="#3-3-时间序列" class="headerlink" title="3.3 时间序列"></a>3.3 时间序列</h2><p>行为识别 (Activity Recognition) 主要通过佩戴在用户身体上的传感器，研究用户的行<br>为。行为数据是一种时间序列数据。不同用户、不同环境、不同位置、不同设备，都会导致时间序列数据的分布发生变化。</p>
<h2 id="3-4-医疗健康"><a href="#3-4-医疗健康" class="headerlink" title="3.4 医疗健康"></a>3.4 医疗健康</h2><p>医疗领域研究的难点问题是，无法获取足够有效的医疗数据。</p>
<h1 id="4-基础知识"><a href="#4-基础知识" class="headerlink" title="4.基础知识"></a>4.基础知识</h1><h2 id="4-1迁移学习的问题形式化"><a href="#4-1迁移学习的问题形式化" class="headerlink" title="4.1迁移学习的问题形式化"></a>4.1迁移学习的问题形式化</h2><h3 id="4-1-1-领域"><a href="#4-1-1-领域" class="headerlink" title="4.1.1 领域"></a>4.1.1 领域</h3><p>领域(Domain)是进行学习的主体。领域主要由两部分构成：数据和生成这些数据的概率分布。源领域：有知识、有大量数据标注的领域；目标域：我们最终要赋予知识、赋予标注的对象。</p>
<h3 id="4-1-2-任务"><a href="#4-1-2-任务" class="headerlink" title="4.1.2 任务"></a>4.1.2 任务</h3><p>任务(Task)：学习的目标。由两部分组成：标签和标签对应的函数。</p>
<h3 id="4-1-3-迁移学习"><a href="#4-1-3-迁移学习" class="headerlink" title="4.1.3 迁移学习"></a>4.1.3 迁移学习</h3><p>领域自适应(Domain Adaptation)</p>
<h2 id="4-2-总体思路"><a href="#4-2-总体思路" class="headerlink" title="4.2 总体思路"></a>4.2 总体思路</h2><p>开发算法来最大限度地利用有标注地领域地知识，来辅助目标领域的知识获取和学习。<br>找到相似性 (不变量)，是进行迁移学习的核心。<br>度量工作的目标有两点：</p>
<ul>
<li>一是很好地度量两个领域的相似性，不仅定性地告诉我们它们是否相似，更定量地给<br>出相似程度。</li>
<li>二是以度量为准则，通过我们所要采用的学习手段，增大两个领域之间的相似性，从而完成迁移学习。</li>
</ul>
<p>一句话总结： ==相似性是核心，度量准则是重要手段。==</p>
<h2 id="4-3-度量准则"><a href="#4-3-度量准则" class="headerlink" title="4.3 度量准则"></a>4.3 度量准则</h2><p>核心：衡量两个数据域的差异。</p>
<h3 id="4-3-1-常见的几种距离"><a href="#4-3-1-常见的几种距离" class="headerlink" title="4.3.1 常见的几种距离"></a>4.3.1 常见的几种距离</h3><ul>
<li>1.欧式距离</li>
<li>2.闵科夫斯基距离</li>
<li>3.马氏距离</li>
</ul>
<h3 id="4-3-2-相似度"><a href="#4-3-2-相似度" class="headerlink" title="4.3.2 相似度"></a>4.3.2 相似度</h3><ul>
<li>1.余弦相似度</li>
<li>2.互信息</li>
<li>3.皮尔逊相关系数</li>
<li>4.Jaccard相关系数</li>
</ul>
<h3 id="4-3-3-KL散度与JS距离"><a href="#4-3-3-KL散度与JS距离" class="headerlink" title="4.3.3 KL散度与JS距离"></a>4.3.3 KL散度与JS距离</h3><h3 id="4-3-4-最大均值差异MMD-Maximun-mean-discrepancy"><a href="#4-3-4-最大均值差异MMD-Maximun-mean-discrepancy" class="headerlink" title="4.3.4 最大均值差异MMD(Maximun mean discrepancy)"></a>4.3.4 最大均值差异MMD(Maximun mean discrepancy)</h3><h3 id="4-3-5-Principle-Angle"><a href="#4-3-5-Principle-Angle" class="headerlink" title="4.3.5 Principle Angle"></a>4.3.5 Principle Angle</h3><h3 id="4-3-6-A-distance"><a href="#4-3-6-A-distance" class="headerlink" title="4.3.6 A-distance"></a>4.3.6 A-distance</h3><h3 id="4-3-7-Hilbert-Schmidt-Independence-Criterion"><a href="#4-3-7-Hilbert-Schmidt-Independence-Criterion" class="headerlink" title="4.3.7 Hilbert-Schmidt Independence Criterion"></a>4.3.7 Hilbert-Schmidt Independence Criterion</h3><h3 id="4-3-8-Wasserstein-Distance"><a href="#4-3-8-Wasserstein-Distance" class="headerlink" title="4.3.8 Wasserstein Distance"></a>4.3.8 Wasserstein Distance</h3><h2 id="4-4-迁移学习的理论保证"><a href="#4-4-迁移学习的理论保证" class="headerlink" title="4.4 迁移学习的理论保证"></a>4.4 迁移学习的理论保证</h2><p>这一部分有些难度。当自己提出的算法需要理论证明时，可以借鉴这一部分。</p>
<h1 id="5-迁移学习的基本方法"><a href="#5-迁移学习的基本方法" class="headerlink" title="5.迁移学习的基本方法"></a>5.迁移学习的基本方法</h1><p>四种基本方法：基于样本的迁移，基于模型的迁移，基于特征的迁移，以及基于关系的迁移。</p>
<h2 id="5-1-基于样本的迁移学习方法-Instance-based-Transfer-Learning"><a href="#5-1-基于样本的迁移学习方法-Instance-based-Transfer-Learning" class="headerlink" title="5.1 基于样本的迁移学习方法(Instance based Transfer Learning)"></a>5.1 基于样本的迁移学习方法(Instance based Transfer Learning)</h2><p><img src="https://s2.ax1x.com/2019/04/25/Ee9XWT.jpg" alt="t8"><br>如图，在迁移时，为了最大限度地和目标域相似，我们可以人为地提高源域中属于狗这个类别地样本权重。<br>优缺点：虽然实例权重法具有较好的理论支撑、容易推导泛化误差上界，但这类方法通常只在领域间分布差异较小时有效，因此对自然语言处理、计算机视觉等任务效果并不理想。</p>
<h2 id="5-2-基于特征迁移"><a href="#5-2-基于特征迁移" class="headerlink" title="5.2 基于特征迁移"></a>5.2 基于特征迁移</h2><p>通过特征变换的方式互相迁移，来减少源域和目标域之间地差距；或者将源域和目标域的数据特征变换到统一特征空间中，然后利用传统的机器学习方法进行分类识别。根据特征的同构和异构性，又可以分为同构和异构迁移学习。<br><img src="https://s2.ax1x.com/2019/04/25/EePN8K.jpg" alt="t15"><br>这类方法通常假设源域和目标域间有一些交叉的特征。</p>
<h2 id="5-3-基于模型学习"><a href="#5-3-基于模型学习" class="headerlink" title="5.3 基于模型学习"></a>5.3 基于模型学习</h2><p>基于模型的迁移方法 (Parameter/Model based Transfer Learning) 是指从源域和目标域中找到他们之间共享的参数信息，以实现迁移的方法。这种迁移方式要求的假设条件是：源域中的数据与目标域中的数据可以共享一些模型的参数。<br><img src="https://s2.ax1x.com/2019/04/25/EeFT3V.jpg" alt="t16"></p>
<h2 id="5-4-基于关系迁移"><a href="#5-4-基于关系迁移" class="headerlink" title="5.4 基于关系迁移"></a>5.4 基于关系迁移</h2><p>这种方法比较关注源域和目标域的样本之间的关系。<br>这些文章都借助于马尔科夫逻辑网络 (Markov Logic Net)来挖掘不同领域之间的关系相似性。<br>我们将重点讨论基于特征和基于模型的迁移学习方法，这也是目前绝大多数研究工作的热点。<br><img src="https://s2.ax1x.com/2019/04/25/EekS9x.jpg" alt="t17"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>30天自制操作系统（23）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8823%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY23-图形处理相关"><a href="#DAY23-图形处理相关" class="headerlink" title="DAY23_图形处理相关"></a>DAY23_图形处理相关</h1><h2 id="1-编写malloc"><a href="#1-编写malloc" class="headerlink" title="1.编写malloc"></a>1.编写malloc</h2><p>如果api_malloc只是调用操作系统中的memman_alloc，并将分配到的内存空间地址返回给应用程序的话，是行不通的，因为通过memman_alloc所获得的内存空间并不位于应用程序的数据段范围内，应用程序是无法进行读写操作的。如果应用程序在不知情的情况下执行了读写操作，将会产生异常并强制结束。</p>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">memman初始化</span><br><span class="line">EDX=8 </span><br><span class="line">EBX=memman的地址</span><br><span class="line">EAX=memman所管理的内存空间的起始地址</span><br><span class="line">ECX=memman所管理的内存空间的字节数</span><br><span class="line">malloc</span><br><span class="line">EDX=9 </span><br><span class="line">EBX=memman的地址</span><br><span class="line">ECX=需要请求的字节数</span><br><span class="line">EAX=分配到的内存空间地址</span><br><span class="line">free</span><br><span class="line">EDX=10 </span><br><span class="line">EBX=memman的地址</span><br><span class="line">EAX=需要释放的内存空间地址</span><br><span class="line">ECX=需要释放的字节数</span><br></pre></td></tr></table></figure>
<h2 id="2-画点"><a href="#2-画点" class="headerlink" title="2.画点"></a>2.画点</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在窗口中画点</span><br><span class="line">EDX =11 </span><br><span class="line">EBX =窗口句柄</span><br><span class="line">ESI =显示位置的x坐标</span><br><span class="line">EDI =显示位置的y坐标</span><br><span class="line">EAX =色号</span><br></pre></td></tr></table></figure>
<p>画星星<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int api_openwin(char *buf, int xsiz, int ysiz, int col_inv, char *title); </span><br><span class="line">void api_boxfilwin(int win, int x0, int y0, int x1, int y1, int col); </span><br><span class="line">void api_initmalloc(void); </span><br><span class="line">char *api_malloc(int size); </span><br><span class="line">void api_point(int win, int x, int y, int col); </span><br><span class="line">void api_end(void); </span><br><span class="line">int rand(void); /*产生0～32767之间的随机数*/ </span><br><span class="line">void HariMain(void) </span><br><span class="line">&#123; </span><br><span class="line"> char *buf; </span><br><span class="line"> int win, i, x, y; </span><br><span class="line"> api_initmalloc(); </span><br><span class="line"> buf = api_malloc(150 * 100);</span><br><span class="line">  win = api_openwin(buf, 150, 100, -1, &quot;stars&quot;); </span><br><span class="line"> api_boxfilwin(win, 6, 26, 143, 93, 0 /*黑色*/); </span><br><span class="line"> for (i = 0; i &lt; 50; i++) &#123; </span><br><span class="line"> x = (rand() % 137) + 6; </span><br><span class="line"> y = (rand() % 67) + 26; </span><br><span class="line"> api_point(win, x, y, 3 /*黄色*/); </span><br><span class="line"> &#125; </span><br><span class="line"> api_end(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="3-刷新窗口"><a href="#3-刷新窗口" class="headerlink" title="3.刷新窗口"></a>3.刷新窗口</h2><p>在所有的窗口绘图命令中设置一个“不自动刷新”的选项，然后再编写一个仅用来刷新的API<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">刷新窗口</span><br><span class="line">EDX = 12 </span><br><span class="line">EBX = 窗口句柄</span><br><span class="line">EAX = x0 </span><br><span class="line">ECX = y0 </span><br><span class="line">ESI = x1 </span><br><span class="line">EDI = y1</span><br></pre></td></tr></table></figure></p>
<h2 id="4-画直线"><a href="#4-画直线" class="headerlink" title="4.画直线"></a>4.画直线</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for (i = 0; i &lt; len; i++) &#123; </span><br><span class="line"> api_point(win, x, y, col); </span><br><span class="line"> x += dx; </span><br><span class="line"> y += dy; </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-关闭窗口"><a href="#5-关闭窗口" class="headerlink" title="5.关闭窗口"></a>5.关闭窗口</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">关闭窗口</span><br><span class="line">EDX=14 </span><br><span class="line">EBX=窗口句柄</span><br></pre></td></tr></table></figure>
<h2 id="6-键盘输入API"><a href="#6-键盘输入API" class="headerlink" title="6.键盘输入API"></a>6.键盘输入API</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">键盘输入</span><br><span class="line">EDX = 15 </span><br><span class="line">EAX = 0……没有键盘输入时返回1，不休眠</span><br><span class="line"> = 1……休眠直到发生键盘输入</span><br><span class="line">EAX = 输入的字符编码</span><br></pre></td></tr></table></figure>
<h2 id="8-强制结束并关闭窗口"><a href="#8-强制结束并关闭窗口" class="headerlink" title="8.强制结束并关闭窗口"></a>8.强制结束并关闭窗口</h2><p>问题：在运行walk.hrb和lines.hrb时，如果不按回车键结束，而是按Shift+F1强制结束程序的话，窗口就会残留在画面上。<br>解决方法：在struct SHEET中添加一个用来存放task的成员，当应用程序结束时，查询所有的图层，如果图层的task为将要结束的应用程序任务，则关闭该图层。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（22）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8822%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY22-用C语言编写应用程序"><a href="#DAY22-用C语言编写应用程序" class="headerlink" title="DAY22_用C语言编写应用程序"></a>DAY22_用C语言编写应用程序</h1><h2 id="1-保护操作系统（5）"><a href="#1-保护操作系统（5）" class="headerlink" title="1.保护操作系统（5）"></a>1.保护操作系统（5）</h2><p>问题：在定时器上做手脚，光标闪烁变得异常缓慢，任务切换的速度也会变得缓慢。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[INSTRSET &quot;i486p&quot;] </span><br><span class="line">[BITS 32] </span><br><span class="line">    MOV AL,0x34 </span><br><span class="line">    OUT 0x43,AL </span><br><span class="line">    MOV AL,0xff</span><br><span class="line">    OUT 0x40,AL </span><br><span class="line">    MOV AL,0xff </span><br><span class="line">    OUT 0x40,AL</span><br><span class="line">    </span><br><span class="line">; 上述代码的功能与下面代码相当</span><br><span class="line">; io_out8(PIT_CTRL, 0x34); </span><br><span class="line">; io_out8(PIT_CNT0, 0xff); </span><br><span class="line">; io_out8(PIT_CNT0, 0xff); </span><br><span class="line"> </span><br><span class="line">    MOV EDX,4 </span><br><span class="line">    INT 0x40</span><br></pre></td></tr></table></figure></p>
<span id="more"></span>
<ul>
<li>执行CLI然后再HLT。由于不再产生定时器中断，任务切换也会停止，键盘和鼠标中断也停止响应。</li>
</ul>
<h2 id="2-帮助发现bug"><a href="#2-帮助发现bug" class="headerlink" title="2.帮助发现bug"></a>2.帮助发现bug</h2><p>CPU的异常处理功能，除了可以保护操作系统免遭应用程序的破坏，还可以帮助我们在编写应用程序时及早发现bug。</p>
<hr>
<p>对栈异常的处理：<br>要想让它发现bug，最好能知道引发异常的指令的地址。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int *inthandler0c(int *esp) </span><br><span class="line">&#123; </span><br><span class="line"> struct CONSOLE *cons = (struct CONSOLE *) *((int *) 0x0fec); </span><br><span class="line"> struct TASK *task = task_now(); </span><br><span class="line"> char s[30]; /*这里！*/ </span><br><span class="line"> cons_putstr0(cons, &quot;\nINT 0C :\n Stack Exception.\n&quot;); </span><br><span class="line"> sprintf(s, &quot;EIP = %08X\n&quot;, esp[11]); /*这里！*/ </span><br><span class="line"> cons_putstr0(cons, s); /*这里！*/ </span><br><span class="line"> return &amp;(task-&gt;tss.esp0); /*强制结束程序*/ </span><br><span class="line">&#125; </span><br><span class="line">int *inthandler0d(int *esp) </span><br><span class="line">&#123; </span><br><span class="line"> struct CONSOLE *cons = (struct CONSOLE *) *((int *) 0x0fec); </span><br><span class="line"> struct TASK *task = task_now(); </span><br><span class="line"> char s[30]; /*这里！*/ </span><br><span class="line"> cons_putstr0(cons, &quot;\nINT 0D :\n General Protected Exception.\n&quot;); </span><br><span class="line"> sprintf(s, &quot;EIP = %08X\n&quot;, esp[11]); /*这里！*/ </span><br><span class="line"> cons_putstr0(cons, s); /*这里！*/ </span><br><span class="line"> return &amp;(task-&gt;tss.esp0); /*强制结束程序*/ </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-强制结束应用程序"><a href="#3-强制结束应用程序" class="headerlink" title="3.强制结束应用程序"></a>3.强制结束应用程序</h2><ul>
<li>如何实现？<br>将某一个键设定为强制结束键，按一下就可以结束程序。<br>把强制结束处理写在其他的任务中，bootpack.c</li>
</ul>
<h2 id="4-用C语言显示字符串（1）"><a href="#4-用C语言显示字符串（1）" class="headerlink" title="4.用C语言显示字符串（1）"></a>4.用C语言显示字符串（1）</h2><p>已经做好了用来显示字符串的API，却没做可供C语言调用该API的函数。</p>
<h2 id="5-用C语言显示字符串（2）"><a href="#5-用C语言显示字符串（2）" class="headerlink" title="5.用C语言显示字符串（2）"></a>5.用C语言显示字符串（2）</h2><p>连接了.obj文件的bim2hrb认为“hello, world”这个字符串就应该存放在0x400这个地址中。<br>由bim2hrb生成的.hrb文件其实是由两个部分构成的。</p>
<ul>
<li>代码部分</li>
<li>数据部分</li>
</ul>
<p>修改console.c：</p>
<ul>
<li>文件中找不到“Hari”标志则报错。</li>
<li>数据段的大小根据.hrb文件中指定的值进行分配。</li>
<li>将.hrb文件中的数据部分先复制到数据段后再启动程序。</li>
</ul>
<h2 id="6-显示窗口"><a href="#6-显示窗口" class="headerlink" title="6.显示窗口"></a>6.显示窗口</h2><p>编写一个用来显示窗口的API<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EDX = 5 </span><br><span class="line">EBX = 窗口缓冲区</span><br><span class="line">ESI = 窗口在x轴方向上的大小（即窗口宽度）</span><br><span class="line">EDI = 窗口在y轴方向上的大小（即窗口高度）</span><br><span class="line">EAX = 透明色</span><br><span class="line">ECX = 窗口名称</span><br></pre></td></tr></table></figure></p>
<h2 id="7-在窗口中描绘字符和方"><a href="#7-在窗口中描绘字符和方" class="headerlink" title="7.在窗口中描绘字符和方"></a>7.在窗口中描绘字符和方</h2><p>显示字符的API：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EDX = 6 </span><br><span class="line">EBX = 窗口句柄</span><br><span class="line">ESI = 显示位置的x坐标</span><br><span class="line">EDI = 显示位置的y坐标</span><br><span class="line">EAX = 色号</span><br><span class="line">ECX = 字符串长度</span><br><span class="line">EBP = 字符串</span><br></pre></td></tr></table></figure></p>
<p>描绘方块的API：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">EDX = 7 </span><br><span class="line">EBX = 窗口句柄</span><br><span class="line">EAX = x0 </span><br><span class="line">ECX = y0 </span><br><span class="line">ESI = x1 </span><br><span class="line">EDI = y1 </span><br><span class="line">EBP = 色号</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（21）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8821%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY21-保护操作系统"><a href="#DAY21-保护操作系统" class="headerlink" title="DAY21_保护操作系统"></a>DAY21_保护操作系统</h1><h2 id="1-攻克难题——字符串显示API"><a href="#1-攻克难题——字符串显示API" class="headerlink" title="1.攻克难题——字符串显示API"></a>1.攻克难题——字符串显示API</h2><ul>
<li>我们需要在API中做个改动，使其能够将应用程序传递的地址解释为代码段内地址。</li>
</ul>
<span id="more"></span>
<h2 id="2-用C语言编写应用程序"><a href="#2-用C语言编写应用程序" class="headerlink" title="2.用C语言编写应用程序"></a>2.用C语言编写应用程序</h2><p>要实现C语言编写应用程序，需要在应用程序方面创建一个api_putchar函数。注意，这个函数不是创建在操作系统中。api_putchar函数需要用C语言来调用，功能是向EDX和AL赋值，并调用INT 0x40。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[FORMAT &quot;WCOFF&quot;] ; 生成对象文件的模式</span><br><span class="line">[INSTRSET &quot;i486p&quot;] ; 表示使用486兼容指令集</span><br><span class="line">[BITS 32] ; 生成32位模式机器语言</span><br><span class="line">[FILE &quot;a_nask.nas&quot;] ; 源文件名信息</span><br><span class="line"> </span><br><span class="line">    GLOBAL _api_putchar </span><br><span class="line"></span><br><span class="line">[SECTION .text] </span><br><span class="line">_api_putchar: ; void api_putchar(int c); </span><br><span class="line">    MOV EDX,1 </span><br><span class="line">    MOV AL,[ESP+4] ; c </span><br><span class="line">    INT 0x40 </span><br><span class="line">    RET</span><br></pre></td></tr></table></figure>
<p>这里的api_putchar需要与a.c的编译结果进行连接，因此我们使用对象文件模式</p>
<h2 id="3-保护操作系统（1）"><a href="#3-保护操作系统（1）" class="headerlink" title="3.保护操作系统（1）"></a>3.保护操作系统（1）</h2><p>操作系统需要运行各种应用程序，而这些应用程序有可能是操作系统开发者编写的，也有可能是用户、别的软件开发商或者是某个自由软件作者出于善意编写的。<br>所谓对操作系统的破坏，严重程度也不同，比如擅自删除重要文件、使其他任务的运行产生异常，或者造成操作系统死机而不得不重新启动等等。</p>
<h2 id="4-保护操作系统（2）"><a href="#4-保护操作系统（2）" class="headerlink" title="4.保护操作系统（2）"></a>4.保护操作系统（2）</h2><p>我们需要为应用程序提供专用的内存空间，并且禁止别的应用程序访问。<br>要做到这一点，我们可以创建应用程序专用的数据段，并在应用程序运行期间，将DS和SS指向该段地址。<br>这次我们还使用了以句点（.）开头的标签名，这是一种被称为本地标签的特殊标签。它基本上和普通的标签功能一样，区别在于即使标签名和其他函数中的标签重复，系统也能将它们区分开来。</p>
<h2 id="5-对异常的支持"><a href="#5-对异常的支持" class="headerlink" title="5.对异常的支持"></a>5.对异常的支持</h2><p>接下来我们要实现强制结束程序的功能。<br>要想强制结束程序，只要在中断号0x0d中注册一个函数即可。<br>这是因为在x86架构规范中，当应用程序试图破坏操作系统，或者试图违背操作系统的设置时，就会自动产生0x0d中断，因此该中断也被称为“异常”。</p>
<h2 id="6-保护操作系统（3）"><a href="#6-保护操作系统（3）" class="headerlink" title="6.保护操作系统（3）"></a>6.保护操作系统（3）</h2><p>可能出现的问题：操作系统会指定应用程序的DS，因此破坏行为会发生异常，那么如果忽略操作系统指定的DS，而是用汇编语言直接将操作系统用的段地址存入DS的话，就又可以干坏事了。</p>
<h2 id="7-保护操作系统（4）"><a href="#7-保护操作系统（4）" class="headerlink" title="7.保护操作系统（4）"></a>7.保护操作系统（4）</h2><ul>
<li>想法：让应用程序无法使用操作系统的段地址。</li>
<li>具体做法：x86架构有这样的功能。<br>在段定义的地方，如果将访问权限加上0x60的话，就可以将段设置为应用程序用。<br>当CS中的段地址为应用程序用段地址时，CPU会认为“当前正在运行应用程序”，这时如果存入操作系统用的段地址就会产生异常。  </li>
</ul>
<hr>
<p>在启动应用程序的时候我们需要让“操作系统向应用程序的段执行far-CALL”<br>解决方案：可以使用RETF</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>基于链接内容的社区发现算法（一）</title>
    <url>/201904/%E5%9F%BA%E4%BA%8E%E9%93%BE%E6%8E%A5%E5%86%85%E5%AE%B9%E7%9A%84%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Robust-Detection-of-Link-Communities-in-Large-Social-Network-by-Exploiting-Link-Semantics"><a href="#Robust-Detection-of-Link-Communities-in-Large-Social-Network-by-Exploiting-Link-Semantics" class="headerlink" title="Robust Detection of Link Communities in Large Social Network by Exploiting Link Semantics"></a>Robust Detection of Link Communities in Large Social Network by Exploiting Link Semantics</h1><p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/17345">Robust Detection of Link Communities in Large Social Network by Exploiting Link Semantics </a></p>
<p>这篇论文是我加入张老师实验室读的第一篇论文，寒假里草草读了一遍，感叹了自己垃圾的英文水平，上周除了上课和作业基本没做什么，一直在研读这篇论文。很幸运的是上周关于这篇论文的汇报我做的非常精彩，也不枉自己上周那么辛苦的肝了。  </p>
<p>这篇博客用来记录自己研读时候的思考和整理。  </p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7J9ts.png" alt="1.1"></p>
<p>整个论文的整体内容我将从四个方面介绍。分别是社区发现算法的背景和现存的方法、论文提出的模型和方法、试验和结论与讨论。</p>
<span id="more"></span>
<h2 id="1-Background"><a href="#1-Background" class="headerlink" title="1. Background"></a>1. Background</h2><p><img src="https://s2.ax1x.com/2019/04/11/A7GvnS.png" alt="1.2">  </p>
<h3 id="1-1-社交网络的发展"><a href="#1-1-社交网络的发展" class="headerlink" title="1.1 社交网络的发展"></a>1.1 社交网络的发展</h3><ul>
<li>社交对于世界各地各领域的人们来讲都越来越重要。随着社交网络的发展，越来越多的信息开始在互联网中聚集。</li>
<li>对于这些大数据的分析能够让我们更加熟悉网络的深层结构、了解用户行为和未来趋势。</li>
<li>社交网络中的一个重要的问题便是社区发现，通过社区发现我们能够为用户提供个性化推荐和异常行为的识别。</li>
<li>所谓的“社区发现”，就是将出现在社交网络中的用户节点划分成不同的组别。每个组的用户结点都有着某些相同的特征。</li>
</ul>
<h3 id="1-2-现存的方法"><a href="#1-2-现存的方法" class="headerlink" title="1.2 现存的方法"></a>1.2 现存的方法</h3><p><img src="https://s2.ax1x.com/2019/04/11/A7Jipq.png" alt="1.3"></p>
<ul>
<li>我们通常用一个图来表示社交网络。其中的点表示用户结点，其中的边表示用户之间的联系。</li>
<li>最初人们社区发现的算法是根据网络的<font color="FF0000">拓扑结构</font>，即让我们划分后的各个社区间的边的数量最少，社区内部点之间的边尽可能的多</li>
<li>之后，社区发现的算法得到改进，我们通过节点内容进行社区划分，即使得同一个社区内的结点内容尽可能多的相似。通过结点内容进行社区发现能够大大提升我们社区发现的效率。</li>
<li>同时我们发现，用户之间的链接，即图中的边也含有大量的信息。</li>
</ul>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JChn.png" alt="1.4"></p>
<p>这张图形象的表示了我们的方法和其他方法的区别。其中右边的图是基于结点内容进行社区发现的算法示意图，左边的图是我们基于链接内容进行社区发现的图。<br>我们可以看出现有的其他方法的问题：</p>
<ul>
<li>1.只考虑了节点内容。考虑节点内容进行社区发现在有些时候有很高的效率。以微博用户的社区发现为例，当我们提供的内容是用户简介时，基于节点内容进行社区发现是很可以的。但是当我们提供的内容是用户之间发送的消息时，这其实是一种“链接内容”，我们需要将链接内容转换成节点内容，比如用户A发送的所有消息算成用户A的节点内容。这时候势必导致社区划分的不准确。</li>
<li>2.假设网络拓扑社区和结点内容社区的用户结点是一样的。两个用户间联系紧密，构成一个拓扑社区，但是他们聊天的内容可能是很五花八门的，两个人可能被分到不同的节点内容社区中去，这个时候现有的方法社区发现的效率就会下降。</li>
<li>3.每个社区仅仅有一个话题。比如右边的图把Music和Movies混在一起当作一个话题，而我们的方法（左边）含有两个话题。</li>
<li>4.仅仅用单个词汇进行社区标签。有时候我们可能会不知所云。而我们的方法用句子进行标签，便于理解。</li>
</ul>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JF10.png" alt="1.5"></p>
<h2 id="2-The-Model-and-Method"><a href="#2-The-Model-and-Method" class="headerlink" title="2.The Model and Method"></a>2.The Model and Method</h2><h3 id="2-1综述"><a href="#2-1综述" class="headerlink" title="2.1综述"></a>2.1综述</h3><p>详见图片  </p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JVnU.png" alt="1.6"></p>
<h3 id="2-2-详细分析"><a href="#2-2-详细分析" class="headerlink" title="2.2 详细分析"></a>2.2 详细分析</h3><p>我们先来看看我们进行社区发现需要考虑哪一些因素：</p>
<ul>
<li>拓扑角度：结点、链接</li>
<li>内容角度：单词、句子、话题</li>
<li>社区和话题群聚(topic cluster)</li>
</ul>
<h4 id="变量介绍"><a href="#变量介绍" class="headerlink" title="变量介绍"></a>变量介绍</h4><p>详见图片(难理解的内容都已经用中文进行注释)  </p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JkcV.md.png" alt="1.7"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JZBF.md.png" alt="1.8"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7Je74.md.png" alt="1.9"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JQ91.md.png" alt="1.10"></p>
<p>所有变量的详细关系如下图所示  </p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JnAJ.png" alt="1.11"></p>
<p>为了便于理解，我自己又画了一个图。</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JGnO.md.png" alt="1.12"></p>
<p>图左半部分就是根据拓扑结构进行社区发现，右半部分是根据节点内容进行社区发现。</p>
<p>现在，我们的模型已经建立起来了，我们的目标为以下三点：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JKhR.png" alt="1.13"></p>
<h3 id="具体算法"><a href="#具体算法" class="headerlink" title="具体算法"></a>具体算法</h3><p>我们算法的整体思想是这样的：首先我们根据某标准把网络中的所有节点划分到不同的社区中（E-step），然后我们将提取每个社区中的关键词，来进行社区标注。（M-step）<br>我们再根据标注进行有监督的学习，对社区进行更精准的划分，以此来一遍遍迭代。  </p>
<p>下面我们运用了极大似然的思想进行EM算法。<br>E-step：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JuN9.md.png" alt="1.14"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7J1c6.md.png" alt="1.15"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7Ja4A.md.png" alt="1.16"></p>
<p>我们进行期望化的变量是p，p代表着链接<i,j>被分配到哪个社区中。<br>现在p的取值是Jensen不等式的取等条件。</p>
<p>M-step：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JJBD.png" alt="1.17"></p>
<p>下面我们要求式(3)的最大值，tau、 omega_ri、 y_rj都是可以通过直接求导求出来的。剩下的psai和fai的最大值我们再一次通过EM算法来求。引入变量p和h，运用JENSEN公式，p和h在取等条件时式子取到最大值。</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JYHe.md.png" alt="1.18"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7Jw9I.md.png" alt="1.19"></p>
<p>下面我们给出整个算法的伪代码，看懂这个图整个算法的思路就差不多了。</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7Jsu8.png" alt="1.20"></p>
]]></content>
      <categories>
        <category>社区发现</category>
      </categories>
      <tags>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>基于链接内容的社区发现算法（二）</title>
    <url>/201904/%E5%9F%BA%E4%BA%8E%E9%93%BE%E6%8E%A5%E5%86%85%E5%AE%B9%E7%9A%84%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Robust-Detection-of-Link-Communities-in-Large-Social-Network-by-Exploiting-Link-Semantics"><a href="#Robust-Detection-of-Link-Communities-in-Large-Social-Network-by-Exploiting-Link-Semantics" class="headerlink" title="Robust Detection of Link Communities in Large Social Network by Exploiting Link Semantics"></a>Robust Detection of Link Communities in Large Social Network by Exploiting Link Semantics</h1><div class="note primary">这一部分没什么难点，ppt里写的都很清楚了。。</div>

<h3 id="三、试验"><a href="#三、试验" class="headerlink" title="三、试验"></a>三、试验</h3><h4 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1.数据集"></a>1.数据集</h4><p>我们选择了两个数据集，包括美国安然能源公司内部的邮件内容（安然公司丑闻，加州能源危机）和Reddit新闻网站三天的的三个论坛的内容。如果用户A对用户B的帖子进行评论，就产生了一条从A到B的链接，链接内容为评论的内容。</p>
<span id="more"></span>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JUNd.md.png" alt="2.1"></p>
<p>那么如何判断我们社区发现的结果是正确的呢？<br>对于第一个数据集，伯克利大学的学生已经将这些用户节点分成了11个用户社区，我们可以直接将社区发现的结果与这十一个社区比对。对于第二个数据集，我们可以直接将发现的社区和三个论坛内容相比较。</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7J03t.png" alt="2.2"></p>
<h4 id="2-对比的方法"><a href="#2-对比的方法" class="headerlink" title="2.对比的方法"></a>2.对比的方法</h4><p>我们采取了8种最先进的社区发现算法，包括利用拓扑结构的、利用结点内容的、利用链接内容的、可重叠的、不可重叠的（可重叠的意思就是可以将一个用户结点放进多个社区里）等，如图：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JBgP.png" alt="2.3"></p>
<h4 id="3-测评参数"><a href="#3-测评参数" class="headerlink" title="3.测评参数"></a>3.测评参数</h4><p>F-score和Jaccard similarity，用于测评相似度的两个参数，结果两个参数越大，说明社区发现的结果越好。</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JgEQ.png" alt="2.4"></p>
<h4 id="4-结果"><a href="#4-结果" class="headerlink" title="4.结果"></a>4.结果</h4><p><img src="https://s2.ax1x.com/2019/04/11/A7JDjf.md.png" alt="2.5"></p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7J5vV.png" alt="2.6"></p>
<h4 id="5-个例研究"><a href="#5-个例研究" class="headerlink" title="5.个例研究"></a>5.个例研究</h4><p>我们选择了Reddit网站2012年8月27号的数据集进行分析，与我们的方法对比的是SCI</p>
<p>SCI方法的结果如下：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JyDS.png" alt="2.7"></p>
<p>我们的方法：<br><img src="https://s2.ax1x.com/2019/04/17/AxqfbT.jpg" alt="2.8"></p>
<p><img src="https://s2.ax1x.com/2019/04/17/Axq4VU.png" alt="2.9"></p>
<p>我们的方法还有一个好处，就是可以通过fai和Y找到社区的词云：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7JR4s.md.png" alt="2.10"></p>
<p>我们方法的应用建议：</p>
<p><img src="https://s2.ax1x.com/2019/04/11/A7Jh3q.png" alt="2.11"></p>
<h3 id="四、结论"><a href="#四、结论" class="headerlink" title="四、结论"></a>四、结论</h3><p><img src="https://s2.ax1x.com/2019/04/11/A7JfCn.md.png" alt="2.12"></p>
<p>这是文章的标题，下面我们对标题的关键词进行讨论和总结。<br>Robust:健壮性。在传统的方法中，当网络拓朴和话题群聚不重合的时候，方法的效率就会变得很低，而我们的方法将网络拓朴和话题群聚分开来讨论，具有一定的健壮性。</p>
<p>Detection of Link Communities：本论文的主要内容——社区发现。</p>
<p>Exploiting Link Semantics: 基于链接语义。</p>
]]></content>
      <categories>
        <category>社区发现</category>
      </categories>
      <tags>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>30天自制操作系统（20）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8820%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY20-API"><a href="#DAY20-API" class="headerlink" title="DAY20_API"></a>DAY20_API</h1><h3 id="1-程序整理"><a href="#1-程序整理" class="headerlink" title="1.程序整理"></a>1.程序整理</h3><p>目标：实现由应用程序对操作系统功能的调用（即API，也叫系统调用）。</p>
<h3 id="2-显示单个字符的API-1"><a href="#2-显示单个字符的API-1" class="headerlink" title="2.显示单个字符的API(1)"></a>2.显示单个字符的API(1)</h3><p>目标：显示单个字符的API。</p>
<span id="more"></span>
<ul>
<li>首先我们做一个测试用的应用程序，将要显示的字符编码存入AL寄存器，然后调用操作系<br>统的函数，字符就显示出来了。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[BITS 32] </span><br><span class="line">    MOV AL,&#x27;A&#x27; </span><br><span class="line">    CALL （cons_putchar的地址）</span><br><span class="line">fin: </span><br><span class="line">    HLT </span><br><span class="line">    JMP fin</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<p>bootpack.map文件<br>这是一个文本文件，用文本编辑器打开即可，其中应该可以找到这样一行：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x00000BE3 : _asm_cons_putchar</span><br></pre></td></tr></table></figure><br>这就是_asm_cons_putchar的地址了，因此，我们将地址填在应用程序中.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[BITS 32] </span><br><span class="line">    MOV AL,&#x27;A&#x27; </span><br><span class="line">    CALL 0xbe3 </span><br><span class="line">fin: </span><br><span class="line">    HLT </span><br><span class="line">    JMP fin</span><br></pre></td></tr></table></figure>
<h3 id="3-显示单个字符的API-2"><a href="#3-显示单个字符的API-2" class="headerlink" title="3.显示单个字符的API(2)"></a>3.显示单个字符的API(2)</h3><ul>
<li>应用程序对API执行CALL的时候，千万不能忘记加上段号。</li>
</ul>
<h3 id="4-结束应用程序"><a href="#4-结束应用程序" class="headerlink" title="4.结束应用程序"></a>4.结束应用程序</h3><ul>
<li>C语言中没有用来执行far-CALL的命令，我们只好来创建一个farcall函数<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">_farcall: ; void farcall(int eip, int cs); </span><br><span class="line">    CALL FAR [ESP+4] ; eip, cs </span><br><span class="line">    RET</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-不随操作系统版本而改变的-API"><a href="#5-不随操作系统版本而改变的-API" class="headerlink" title="5.不随操作系统版本而改变的 API"></a>5.不随操作系统版本而改变的 API</h3><h3 id="6-为应用程序自由命名"><a href="#6-为应用程序自由命名" class="headerlink" title="6.为应用程序自由命名"></a>6.为应用程序自由命名</h3><ul>
<li>目标：让系统支持其他应用程序名<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">cons_runcmd</span><span class="params">(<span class="type">char</span> *cmdline, <span class="keyword">struct</span> CONSOLE *cons, <span class="type">int</span> *fat, <span class="type">unsigned</span> <span class="type">int</span> memtotal)</span> </span><br><span class="line">&#123; </span><br><span class="line">     <span class="keyword">if</span> (<span class="built_in">strcmp</span>(cmdline, <span class="string">&quot;mem&quot;</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">        cmd_mem(cons, memtotal); </span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">strcmp</span>(cmdline, <span class="string">&quot;cls&quot;</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">        cmd_cls(cons); </span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">strcmp</span>(cmdline, <span class="string">&quot;dir&quot;</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">        cmd_dir(cons); </span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">strncmp</span>(cmdline, <span class="string">&quot;type &quot;</span>, <span class="number">5</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">        cmd_type(cons, fat, cmdline); </span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmdline[<span class="number">0</span>] != <span class="number">0</span>) &#123; <span class="comment">/*从此开始*/</span> </span><br><span class="line">     <span class="keyword">if</span> (cmd_app(cons, fat, cmdline) == <span class="number">0</span>) &#123; </span><br><span class="line">         <span class="comment">/*不是命令，不是应用程序，也不是空行*/</span> </span><br><span class="line">         putfonts8_asc_sht(cons-&gt;sht, <span class="number">8</span>, cons-&gt;cur_y, COL8_FFFFFF, COL8_000000, <span class="string">&quot;Bad command.&quot;</span>, </span><br><span class="line">         <span class="number">12</span>); </span><br><span class="line">         cons_newline(cons); </span><br><span class="line">         cons_newline(cons); </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; <span class="comment">/*到此结束 */</span> </span><br><span class="line">     <span class="keyword">return</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="7-当心寄存器"><a href="#7-当心寄存器" class="headerlink" title="7.当心寄存器"></a>7.当心寄存器</h3><ul>
<li>命名只显示一个h</li>
<li>给_asm_cons_putchar添上2行代码，就是PUSHAD和POPAD。</li>
</ul>
<h3 id="8-用API显示字符"><a href="#8-用API显示字符" class="headerlink" title="8.用API显示字符"></a>8.用API显示字符</h3><ul>
<li>从实际的应用程序开发角度来说，能显示字符串的API远比只能显示单个字符的API要来的方便，因为一次显示一串字符的情况比一次只显示一个字符的情况多得多。</li>
<li>一般有两种方式：<ul>
<li>种是显示一串字符，遇到字符编码0则结束；</li>
<li>先指定好要显示的字符串的长度再显示。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">功能号 1……显示单个字符（AL = 字符编码）</span><br><span class="line">功能号 2……显示字符串 0（EBX = 字符串地址）</span><br><span class="line">功能号 3……显示字符串 1（EBX = 字符串地址，ECX = 字符串长度）</span><br></pre></td></tr></table></figure>
<ul>
<li>将_asm_cons_putchar改写成一个新的函数。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">_asm_hrb_api:</span><br><span class="line">    STI</span><br><span class="line">    PUSHAD;</span><br><span class="line">    PUSHAD;</span><br><span class="line">    CALL _hrb_api</span><br><span class="line">    ADD ESP,32</span><br><span class="line">    POPAD</span><br><span class="line">    IRETD</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（19）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8819%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY19-应用程序"><a href="#DAY19-应用程序" class="headerlink" title="DAY19_应用程序"></a>DAY19_应用程序</h1><h3 id="1-type命令"><a href="#1-type命令" class="headerlink" title="1.type命令"></a>1.type命令</h3><ul>
<li>在Windows的命令行中，有一个叫做type的命令，输入“type 文件名”就会显示出文件的内容。</li>
</ul>
<span id="more"></span>
<hr>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">磁盘映像中的地址 = clustno * 512 + 0x003e00</span><br></pre></td></tr></table></figure>
<hr>
<ul>
<li>将s[0～10]这11个字节用空格的字符编码填充，然后读取cmdline[5～]并复制到s[0～]，在复制的同时，将其中的小写字母转换为大写字母。随后，当遇到句点时，则可以断定接下来的部分为扩展名，于是将复制的目标改为s[8～]。经过这样的转换，我们就得到了和磁盘内格式相同的文件名。</li>
<li>“寻找文件”这一段中，我们在磁盘中寻找与所输入的文件名相符的文件。如果成功找到指<br>定文件，则用break跳出for循环；如果找不到，则会在x到达224或者finfo[x].name[0]为0x00时结束循环。</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* type命令*/</span> </span><br><span class="line"> <span class="comment">/*准备文件名*/</span> </span><br><span class="line"> <span class="keyword">for</span> (y = <span class="number">0</span>; y &lt; <span class="number">11</span>; y++) &#123; </span><br><span class="line">    s[y] = <span class="string">&#x27; &#x27;</span>; </span><br><span class="line"> &#125; </span><br><span class="line"> y = <span class="number">0</span>; </span><br><span class="line"> <span class="keyword">for</span> (x = <span class="number">5</span>; y &lt; <span class="number">11</span> &amp;&amp; cmdline[x] != <span class="number">0</span>; x++) &#123; </span><br><span class="line">    <span class="keyword">if</span> (cmdline[x] == <span class="string">&#x27;.&#x27;</span> &amp;&amp; y &lt;= <span class="number">8</span>) &#123; </span><br><span class="line">    y = <span class="number">8</span>; </span><br><span class="line"> &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">    s[y] = cmdline[x]; </span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&#x27;a&#x27;</span> &lt;= s[y] &amp;&amp; s[y] &lt;= <span class="string">&#x27;z&#x27;</span>) &#123; </span><br><span class="line">        <span class="comment">/*将小写字母转换成大写字母 */</span> </span><br><span class="line">        s[y] -= <span class="number">0x20</span>; </span><br><span class="line">    &#125; </span><br><span class="line">    y++; </span><br><span class="line">    &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="comment">/*寻找文件*/</span> </span><br><span class="line"> <span class="keyword">for</span> (x = <span class="number">0</span>; x &lt; <span class="number">224</span>; ) &#123; </span><br><span class="line">    <span class="keyword">if</span> (finfo[x].name[<span class="number">0</span>] == <span class="number">0x00</span>) &#123; </span><br><span class="line">    <span class="keyword">break</span>; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> ((finfo[x].type &amp; <span class="number">0x18</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">    <span class="keyword">for</span> (y = <span class="number">0</span>; y &lt; <span class="number">11</span>; y++) &#123; </span><br><span class="line">    <span class="keyword">if</span> (finfo[x].name[y] != s[y]) &#123; </span><br><span class="line">        <span class="keyword">goto</span> type_next_file; </span><br><span class="line">    &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">break</span>; <span class="comment">/*找到文件*/</span> </span><br><span class="line"> &#125; </span><br><span class="line"> type_next_file: </span><br><span class="line"> x++; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> (x &lt; <span class="number">224</span> &amp;&amp; finfo[x].name[<span class="number">0</span>] != <span class="number">0x00</span>) &#123; </span><br><span class="line">    <span class="comment">/*找到文件的情况*/</span> </span><br><span class="line">    y = finfo[x].size;</span><br><span class="line">    p = (<span class="type">char</span> *) (finfo[x].clustno * <span class="number">512</span> + <span class="number">0x003e00</span> + ADR_DISKIMG); </span><br><span class="line">    cursor_x = <span class="number">8</span>; </span><br><span class="line"> <span class="keyword">for</span> (x = <span class="number">0</span>; x &lt; y; x++) &#123; </span><br><span class="line">    <span class="comment">/*逐字输出*/</span> </span><br><span class="line">    s[<span class="number">0</span>] = p[x]; </span><br><span class="line">    s[<span class="number">1</span>] = <span class="number">0</span>; </span><br><span class="line">    putfonts8_asc_sht(sheet, cursor_x, cursor_y, COL8_FFFFFF, COL8_000000, s, <span class="number">1</span>); </span><br><span class="line">     cursor_x += <span class="number">8</span>; </span><br><span class="line">    <span class="keyword">if</span> (cursor_x == <span class="number">8</span> + <span class="number">240</span>) &#123; <span class="comment">/*到达最右端后换行*/</span> </span><br><span class="line">    cursor_x = <span class="number">8</span>; </span><br><span class="line">    cursor_y = cons_newline(cursor_y, sheet); </span><br><span class="line">    &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> &#125; <span class="keyword">else</span> &#123; </span><br><span class="line"> <span class="comment">/*没有找到文件的情况*/</span> </span><br><span class="line"> putfonts8_asc_sht(sheet, <span class="number">8</span>, cursor_y, COL8_FFFFFF, COL8_000000, <span class="string">&quot;File </span></span><br><span class="line"><span class="string"> not found.&quot;</span>, <span class="number">15</span>); </span><br><span class="line"> cursor_y = cons_newline(cursor_y, sheet); </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-type命令改良"><a href="#2-type命令改良" class="headerlink" title="2.type命令改良"></a>2.type命令改良</h3><ul>
<li><p>目标：实现对换行的支持。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x09……制表符：显示空格直到 x 被 4 整除为止</span><br><span class="line">0x0a……换行符：换行</span><br><span class="line">0x0d……回车符：忽略</span><br></pre></td></tr></table></figure>
</li>
<li><p>我们这里所说的制表符也称为水平制表符（horizonal tab），因为对齐字符位置是在水平方向上移动。相对的，还有一种垂直制表符（vertical tab）</p>
</li>
<li>在Windows中换行的字符编码为“0x0d 0x0a”两个字节，而Linux中只有“0x0a”一个字节。<ul>
<li>字符编码0x0a原本代表折行（line feed）的意思，即只是移动到下一行。</li>
<li>0x0d，也就是回车符的文字编码，代表“让打印头（或者打字机的辊筒）回到行首”的意思，因此才被称为“回车”（carriage return）。</li>
</ul>
</li>
</ul>
<h3 id="3-对FAT的支持"><a href="#3-对FAT的支持" class="headerlink" title="3.对FAT的支持"></a>3.对FAT的支持</h3><ul>
<li>现在的type命令，肯定可以正确显示文件开头的512个字节的内容，但是如果遇到大于512个字节的文件，中间可能就会突然显示出其他文件的内容。</li>
<li>对于文件的下一段存放在哪里，在磁盘中是有记录的，我们只要分析这个记录，就可以正确读取文件内容了。</li>
<li>它位于从0柱面、0磁头、2扇区开始的9个扇区中，在磁盘映像中相当于0x000200～0x0013ff。这个记录被称为FAT，是“file allocation table”的缩写，翻译过来叫作“文件分配表”（即记录文件在磁盘中存放位置的表）。</li>
</ul>
<h3 id="4-代码整理"><a href="#4-代码整理" class="headerlink" title="4.代码整理"></a>4.代码整理</h3><ul>
<li>窗口相关函数 → window.c </li>
<li>命令行窗口相关函数 → console.c </li>
<li>文件相关函数 → file.c</li>
</ul>
<h3 id="5-第一个应用程序"><a href="#5-第一个应用程序" class="headerlink" title="5.第一个应用程序"></a>5.第一个应用程序</h3><h2 id=""><a href="#" class="headerlink" title=""></a><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[BITS 32] </span><br><span class="line">fin: </span><br><span class="line"> HLT </span><br><span class="line"> JMP fin</span><br></pre></td></tr></table></figure></h2><ul>
<li>像type命令一样，我们用file_loadfile将文件的内容读到内存中</li>
<li>应用程序不知道自己被读到哪个内存地址，这里暂且由ORG0来生成。因此，为了应用程序能够顺利运行，我们需要为其创建一个内存段。</li>
<li>段创建好之后，接下来只要goto到该段中的程序，程序应该就会开始运行了。要goto到其他的内存段，在汇编语言中用farjmp指令。<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (y = <span class="number">0</span>; y &lt; <span class="number">11</span>; y++) &#123; </span><br><span class="line">     s[y] = <span class="string">&#x27; &#x27;</span>; </span><br><span class="line"> &#125; </span><br><span class="line"> s[<span class="number">0</span>] = <span class="string">&#x27;H&#x27;</span>; </span><br><span class="line"> s[<span class="number">1</span>] = <span class="string">&#x27;L&#x27;</span>; </span><br><span class="line"> s[<span class="number">2</span>] = <span class="string">&#x27;T&#x27;</span>; </span><br><span class="line"> s[<span class="number">8</span>] = <span class="string">&#x27;H&#x27;</span>; </span><br><span class="line"> s[<span class="number">9</span>] = <span class="string">&#x27;R&#x27;</span>; </span><br><span class="line"> s[<span class="number">10</span>] = <span class="string">&#x27;B&#x27;</span>; </span><br><span class="line"> <span class="keyword">for</span> (x = <span class="number">0</span>; x &lt; <span class="number">224</span>; ) &#123; </span><br><span class="line">     <span class="keyword">if</span> (finfo[x].name[<span class="number">0</span>] == <span class="number">0x00</span>) &#123; </span><br><span class="line">     <span class="keyword">break</span>; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> ((finfo[x].type &amp; <span class="number">0x18</span>) == <span class="number">0</span>) &#123; </span><br><span class="line">     <span class="keyword">for</span> (y = <span class="number">0</span>; y &lt; <span class="number">11</span>; y++) &#123; </span><br><span class="line">         <span class="keyword">if</span> (finfo[x].name[y] != s[y]) &#123; </span><br><span class="line">         <span class="keyword">goto</span> hlt_next_file; </span><br><span class="line">         &#125; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">break</span>; <span class="comment">/*找到文件*/</span> </span><br><span class="line">     &#125; </span><br><span class="line">     hlt_next_file: </span><br><span class="line">     x++; </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">if</span> (x &lt; <span class="number">224</span> &amp;&amp; finfo[x].name[<span class="number">0</span>] != <span class="number">0x00</span>) &#123; </span><br><span class="line">     <span class="comment">/*找到文件的情况*/</span> </span><br><span class="line">     p = (<span class="type">char</span> *) memman_alloc_4k(memman, finfo[x].size); </span><br><span class="line">     file_loadfile(finfo[x].clustno, finfo[x].size, p, fat, (<span class="type">char</span> *) </span><br><span class="line">     (ADR_DISKIMG + <span class="number">0x003e00</span>)); </span><br><span class="line">     set_segmdesc(gdt + <span class="number">1003</span>, finfo[x].size - <span class="number">1</span>, (<span class="type">int</span>) p, AR_CODE32_ER); </span><br><span class="line">     farjmp(<span class="number">0</span>, <span class="number">1003</span> * <span class="number">8</span>); </span><br><span class="line">     memman_free_4k(memman, (<span class="type">int</span>) p, finfo[x].size); </span><br><span class="line"> &#125; <span class="keyword">else</span> &#123; </span><br><span class="line"> <span class="comment">/*没有找到文件的情况*/</span> </span><br><span class="line">     putfonts8_asc_sht(sheet, <span class="number">8</span>, cursor_y, COL8_FFFFFF, COL8_000000, <span class="string">&quot;File </span></span><br><span class="line"><span class="string">     not found.&quot;</span>, <span class="number">15</span>); </span><br><span class="line">     cursor_y = cons_newline(cursor_y, sheet); </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="comment">/*到此结束*/</span></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>循环赛赛程安排</title>
    <url>/201904/%E5%BE%AA%E7%8E%AF%E8%B5%9B%E8%B5%9B%E7%A8%8B%E5%AE%89%E6%8E%92/</url>
    <content><![CDATA[<h2 id="一、问题重述"><a href="#一、问题重述" class="headerlink" title="一、问题重述"></a>一、问题重述</h2><p>设有n个运动员要进行网球循环赛。设计一个满足下列条件的比赛日程表：</p>
<ul>
<li>每个选手必须与其他n-1个选手各赛一次；</li>
<li>每个选手一天只能赛一次；</li>
<li>当n是偶数时，循环赛进行n-1天。</li>
<li>当n是奇数时，循环赛进行n天。</li>
</ul>
<span id="more"></span>
<h2 id="二、问题分析"><a href="#二、问题分析" class="headerlink" title="二、问题分析"></a>二、问题分析</h2><h4 id="1-当n是2的次幂时"><a href="#1-当n是2的次幂时" class="headerlink" title="1.当n是2的次幂时"></a>1.当n是2的次幂时</h4><p> $ n=2^k,k=1,2,3,4… $时，此时问题比较简单。按照==分治==的策略，可将所有参赛的选手分为两部分，$ n＝2k $个选手的比赛日程表可以通过为 $ n/2＝2k-1 $ 个选手设计的比赛日程表来决定。递归地执行这种分割，直到只剩下 2 个选手时，比赛日程表的制定就变得很简单：只要让这 2 个选手进行比赛就可以了。再逐步合并子问题的解即可得到原问题的解。<br> 示意图如下：</p>
<p><img src="https://s2.ax1x.com/2019/04/13/ALTauj.jpg" alt="1.1"></p>
<p>此时的分治算法如下所示:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void tourna(int n) //基本的分治算法</span><br><span class="line">&#123;</span><br><span class="line">    if(n==1)&#123;a[0][0]=1;return;&#125;</span><br><span class="line">    tourna(n/2); //分治</span><br><span class="line">    copy(n); //合并</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void copy(int n)</span><br><span class="line">&#123;</span><br><span class="line">    int m=n/2;</span><br><span class="line">    for(int i=0;i&lt;m;i++)</span><br><span class="line">    for(int j=0;j&lt;m;j++)&#123;</span><br><span class="line">        //由左上角小块的值算出对应的右上角小块的值</span><br><span class="line">        a[i][j+m]=a[i][j]+m;</span><br><span class="line">        //由右上角小块的值算出对应的左下角小块的值</span><br><span class="line">        a[i+m][j]=a[i][j+m];</span><br><span class="line">        //由左上角小块的值算出对应的右下角小块的值</span><br><span class="line">        a[i+m][j+m]=a[i][j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>我们用a[i][j]表示第i支队伍在第j天遇到的对手。</p>
<h4 id="2-当n不是2的次幂时"><a href="#2-当n不是2的次幂时" class="headerlink" title="2.当n不是2的次幂时"></a>2.当n不是2的次幂时</h4><p>下面讨论当n不是2的次幂时的情况。<br>我们发现当n为奇数时，每天必定有一支队伍轮空。此时我们==假定还有一只不存在的队伍与轮空的队伍比赛==，将我们的奇偶数情况的模型统一。此时n的赛程表与偶数n+1时的赛程表是相似的。<br>比如，当n=4时<br>| 0 | 1 | 2 | 3 |<br>|—-|—-|—-|—-|<br>| 1 | 0 | 3 | 2 |<br>| 2 | 3 | 0 | 1 |<br>| 3 | 2 | 1 | 0 |</p>
<p>当n=3时<br>| 0 | 1 | 2 | / |<br>|—-|—-|—-|—-|<br>| 1 | 0 | / | 2 |<br>| 2 | / | 0 | 1 |<br>| / | 2 | 1 | 0 |</p>
<p>(删去最后一行)其中“/”表示轮空。</p>
<p>综上，当遇到n为奇数的情况，我们便可以转化为偶数来考虑。</p>
<p>接下来我们遇到问题的难点==矩阵的合并==<br>当n/2为偶数时，合并比较容易，就像$ n=2^k $那样。<br>下面我们来考虑n/2为奇数的情况。<br>此时合并的过程我参考了<a href="https://www.cnblogs.com/zhuyijie/p/6465812.html">猪一戒的博客</a></p>
<p>我们考虑当n=6时的情况。<br>我们先将6个人分成2组，每组3个人（[0，1,2],[3,4,5]），然后发现3是个奇数，然后在每组中+1个虚拟人：X和Y；这样，每组就变成了4个人，然后将这4个人在除以2，我们就得到了一个两两组合的小的组。</p>
<p>首先来看[0，1]; [2,x]</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>2</th>
<th>x</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>2</td>
</tr>
</tbody>
</table>
</div>
<p>将这两组合起来：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>x</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>x</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>x</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>x</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>这里要得到3个选手的比赛安排，所以，我们将假想的X去掉，并将它的位置以/代替：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>/</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>/</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>/</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
</div>
<p>然后我们也按照这个规律，安排[3,4,5]的日程，得到表格<br>| 3 | 4 | 5 | / |<br>|—-|—-|—-|—-|<br>| 4 | 3 | / | 5 |<br>| 5 | / | 3 | 4 |</p>
<p>我们得到了两个3x4的矩阵（其中第一列表示每个队伍，实际上只有三天），我们最终想得到6*6（其中第一列表示每个队伍，实际上只有五天）的矩阵。</p>
<p>我们先将上面两个矩阵合并</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>/</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>/</td>
<td>2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>/</td>
<td>0</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>5</td>
<td>/</td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>/</td>
<td>5</td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>/</td>
<td>3</td>
<td>4</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p> 前三天的比赛已经基本排完了，我们只需要在斜杠/的地方填上相应的比赛。很显然可以让每天轮空的两支队伍比赛。（在程序中没有斜杠表示，还是假想的队伍，方便进行监测）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>4</td>
<td>2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>0</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>5</td>
<td>0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>1</td>
<td>5</td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>上面的矩阵中[0,1,2]和[3,4,5]组内已经比完了，组间比了一次，剩下的只需要轮换两次即可得到后两天的比赛情况。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>4</td>
<td>2</td>
<td>5</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>0</td>
<td>1</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>5</td>
<td>0</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>1</td>
<td>5</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>于是我们便可以得到两个奇数矩阵的合并情况。</p>
<p>在程序中，我们的思路不是严格意义上的所谓的“合并”，而是“扩展”。比如对于“合并2个3x4的矩阵”，我们是“将1个3x4的矩阵扩展为6x6的矩阵”（因为这两个3x4的矩阵规格相同，排序顺序一样，所以只需要做一遍）</p>
<h2 id="三、代码展示"><a href="#三、代码展示" class="headerlink" title="三、代码展示"></a>三、代码展示</h2><p>（代码里有一些打印行号的printf语句，不知道为啥一去掉就过不了编译，所以没有删掉。。）<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;stdlib.h&gt;</span><br><span class="line">#include&quot;Check.cpp&quot;</span><br><span class="line"></span><br><span class="line">void copy(int n, int **a)//偶数情况</span><br><span class="line">&#123;</span><br><span class="line">	//printf(&quot;当前行号%05d\n&quot;,__LINE__);</span><br><span class="line">	int m=n/2;</span><br><span class="line">	for(int i=0;i&lt;m;i++)&#123;</span><br><span class="line">		for(int j=0;j&lt;m;j++)&#123;</span><br><span class="line">			//由左上角小块的值算出对应的右上角小块的值</span><br><span class="line">			a[i][j+m]=a[i][j]+m;</span><br><span class="line">			//由右上角小块的值算出对应的左下角小块的值</span><br><span class="line">			a[i+m][j]=a[i][j+m];</span><br><span class="line">			//由左上角小块的值算出对应的右下角小块的值</span><br><span class="line">			a[i+m][j+m]=a[i][j];</span><br><span class="line">		&#125;	</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void copyodd(int n, int **a) // n/2 为奇数时的合并算法</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;当前行号%05d\n&quot;,__LINE__);</span><br><span class="line">	int m=n/2;</span><br><span class="line">	int b[m];</span><br><span class="line">	for(int i=0;i&lt;m;i++)&#123;</span><br><span class="line">		b[i]=m+i;</span><br><span class="line">		b[m+i]=b[i];</span><br><span class="line">	&#125;</span><br><span class="line">	for(int i=0;i&lt;m;i++)&#123;</span><br><span class="line">		//由左上角小块的值算出相应的左下角小块的值</span><br><span class="line">		for(int j=0;j&lt;m+1;j++)&#123;</span><br><span class="line">			if(a[i][j]&gt;=m)&#123;</span><br><span class="line">				a[i][j]=b[i];</span><br><span class="line">				a[m+i][j]=(b[i]+m)%n;</span><br><span class="line">			&#125;	else a[m+i][j]=a[i][j]+m;</span><br><span class="line">		&#125;</span><br><span class="line">		//由左上角小块的值算出相应的右上角和右下角小块的值</span><br><span class="line">		for(int j=1;j&lt;m;j++)&#123;</span><br><span class="line">			a[i][m+j]=b[i+j];</span><br><span class="line">			a[b[i+j]][m+j]=i;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void merge(int n, int **a) //合并算法</span><br><span class="line">&#123;</span><br><span class="line">	if((n/2)&gt;1 &amp;&amp; (n/2)%2 == 1) copyodd(n,a); //n/2 为奇数时,注意是 (n/2)%2 == 1，n别忘了/2 </span><br><span class="line">	else copy(n,a);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void tournament(int n, int **a) //循环赛算法</span><br><span class="line">&#123;</span><br><span class="line">	printf(&quot;当前行号%05d\n&quot;,__LINE__);</span><br><span class="line">	if(n==1)&#123;a[0][0]=0;return;&#125;</span><br><span class="line">	if(n%2 == 1)	&#123;tournament(n+1,a);return;&#125; //n为奇数，分治</span><br><span class="line">	tournament(n/2,a); //n为偶数，分治</span><br><span class="line">	merge(n,a); //合并</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br><span class="line">&#123;</span><br><span class="line">	int n;</span><br><span class="line">	scanf(&quot;%d&quot;,&amp;n);</span><br><span class="line">	</span><br><span class="line">	//创建数组</span><br><span class="line">	int **a;</span><br><span class="line">	a = (int**)malloc(sizeof(int*)*n);</span><br><span class="line">	</span><br><span class="line">	if(n%2==1)&#123;</span><br><span class="line">		for(int i=0; i&lt;n+1; i++)	a[i] = (int*)malloc(sizeof(int)*(n+1));</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		for(int i=0; i&lt;n; i++)	a[i] = (int*)malloc(sizeof(int)*n);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	//生成循坏赛矩阵</span><br><span class="line">	tournament(n,a);</span><br><span class="line">	</span><br><span class="line">	//打印</span><br><span class="line">	printf(&quot;当前行号:%05d\n&quot;,__LINE__);</span><br><span class="line">	for(int i=0; i&lt;n; i++)&#123;</span><br><span class="line">		for(int j=1; j&lt;(n%2 == 1 ? n+1 : n); j++)&#123;</span><br><span class="line">			if(a[i][j]&lt;n)	printf(&quot;%d &quot;,a[i][j]);</span><br><span class="line">			else printf(&quot;x &quot;);</span><br><span class="line">		&#125;</span><br><span class="line">		printf(&quot;\n&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	//检验程序</span><br><span class="line">	if(Check(a,n)==1) printf(&quot;This gametable is availuable.\n&quot;);</span><br><span class="line">	else printf(&quot;This gametable is unavailuable.\n&quot;);</span><br><span class="line">	if(n%2 ==1)&#123;</span><br><span class="line">		for(int i=0; i&lt;n; i++)	free(a[i]);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		for(int i=0; i&lt;n+1; i++)	free(a[i]);</span><br><span class="line">	&#125;</span><br><span class="line">	free(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="四、测试程序"><a href="#四、测试程序" class="headerlink" title="四、测试程序"></a>四、测试程序</h2><p>测试程序对我们生成的矩阵进行检验。从两个角度进行。</p>
<ul>
<li>每个队伍都要和其他队伍进行一场比赛</li>
<li>每个队伍每天仅进行一场比赛</li>
</ul>
<p>测试程序代码如下<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int Check(int **a, int n)</span><br><span class="line">&#123;</span><br><span class="line">	int column;</span><br><span class="line">	if(n%2==1) column=n+1;</span><br><span class="line">	else column=n;</span><br><span class="line">	int flag=0;</span><br><span class="line">	int check=1;//check为0说明不符合条件，停止检验。 </span><br><span class="line">	//检验每个队伍都与其他队伍比赛 </span><br><span class="line">	for(int i=0; i&lt;n&amp;&amp;check==1; i++)&#123;</span><br><span class="line">		for(int k=0; k&lt;n&amp;&amp;check==1; k++)&#123;</span><br><span class="line">			flag=0;</span><br><span class="line">			for(int j=0;j&lt;column&amp;&amp;flag==0;j++)&#123;</span><br><span class="line">				if(a[i][j] == k) flag=1;</span><br><span class="line">			&#125;</span><br><span class="line">			if(flag==0) check=0;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	//检验某天是否有队伍重复比赛</span><br><span class="line">	int times[n];</span><br><span class="line">	for(int j=1; j&lt;column&amp;&amp;check==1; j++)&#123;</span><br><span class="line">		for(int w=0; w&lt;n; w++) times[w]=0;</span><br><span class="line">		for(int i=0; i&lt;n&amp;&amp;check==1; i++)&#123;</span><br><span class="line">			times[a[i][j]]++;</span><br><span class="line">			if(times[a[i][j]]&gt;=2) check==0;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; </span><br><span class="line">	if(check==1) return 1;</span><br><span class="line">	else return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="五、实验结果"><a href="#五、实验结果" class="headerlink" title="五、实验结果"></a>五、实验结果</h2><ul>
<li>当n=6时</li>
</ul>
<p><img src="https://s2.ax1x.com/2019/04/13/ALb4Vs.jpg" alt="1.2"></p>
<ul>
<li>当n=9时</li>
</ul>
<p><img src="https://s2.ax1x.com/2019/04/13/ALb5an.jpg" alt="1.3"></p>
<p>测试结果均正确。</p>
<p><em>参考文献</em><br><em>[1]王民川,田永轩.分治法在循环赛日程表设计中的应用[J].光盘技术,2009(05):45-46.</em></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分治法</tag>
      </tags>
  </entry>
  <entry>
    <title>30天自制操作系统（18）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8818%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY18-dir命令"><a href="#DAY18-dir命令" class="headerlink" title="DAY18_dir命令"></a>DAY18_dir命令</h1><h3 id="1-控制光标闪烁-1"><a href="#1-控制光标闪烁-1" class="headerlink" title="1.控制光标闪烁(1)"></a>1.控制光标闪烁(1)</h3><ul>
<li>在Windows中，只有可以接受键盘输入的窗口有光标闪烁，而其他的窗口中是不显示光标的。</li>
<li>对HariMain进行改写</li>
</ul>
<span id="more"></span>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">    <span class="comment">/*从此开始*/</span> <span class="keyword">if</span> (cursor_c &gt;= <span class="number">0</span>) &#123; </span><br><span class="line">        boxfill8(sht_win-&gt;buf, sht_win-&gt;bxsize, cursor_c, cursor_x, <span class="number">28</span>, cursor_x + <span class="number">7</span>, <span class="number">43</span>); </span><br><span class="line">    <span class="comment">/*到此结束*/</span> &#125; </span><br><span class="line">         sheet_refresh(sht_win, cursor_x, <span class="number">28</span>, cursor_x + <span class="number">8</span>, <span class="number">44</span>); </span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">512</span> &lt;= i &amp;&amp; i &lt;= <span class="number">767</span>) &#123; <span class="comment">/*鼠标数据*/</span> </span><br><span class="line">     （中略）</span><br><span class="line">     &#125; <span class="keyword">else</span> <span class="keyword">if</span> (i &lt;= <span class="number">1</span>) &#123; <span class="comment">/*光标用定时器*/</span> </span><br><span class="line">    <span class="comment">/*从此开始*/</span> <span class="keyword">if</span> (i != <span class="number">0</span>) &#123; </span><br><span class="line">         timer_init(timer, &amp;fifo, <span class="number">0</span>); <span class="comment">/*下次置0 */</span> </span><br><span class="line">     <span class="keyword">if</span> (cursor_c &gt;= <span class="number">0</span>) &#123; </span><br><span class="line">        cursor_c = COL8_000000; </span><br><span class="line">     &#125; </span><br><span class="line">     &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">         timer_init(timer, &amp;fifo, <span class="number">1</span>); <span class="comment">/*下次置1 */</span> </span><br><span class="line">         <span class="keyword">if</span> (cursor_c &gt;= <span class="number">0</span>) &#123; </span><br><span class="line">         cursor_c = COL8_FFFFFF; </span><br><span class="line">        &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     timer_settime(timer, <span class="number">50</span>); </span><br><span class="line">     <span class="keyword">if</span> (cursor_c &gt;= <span class="number">0</span>) &#123; </span><br><span class="line">     boxfill8(sht_win-&gt;buf, sht_win-&gt;bxsize, cursor_c, cursor_x, <span class="number">28</span>, cursor_x + </span><br><span class="line">     <span class="number">7</span>, <span class="number">43</span>); </span><br><span class="line">     sheet_refresh(sht_win, cursor_x, <span class="number">28</span>, cursor_x + <span class="number">8</span>, <span class="number">44</span>); </span><br><span class="line">    <span class="comment">/*到此结束*/</span> &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-控制光标闪烁-2"><a href="#2-控制光标闪烁-2" class="headerlink" title="2.控制光标闪烁(2)"></a>2.控制光标闪烁(2)</h3><ul>
<li>实现命令行窗口中光标闪烁的控制。</li>
<li>像传递按键编码一样，我们可以使用FIFO来实现。</li>
<li>我们先将光标开始闪烁定义为2，停止闪烁定义为3。</li>
</ul>
<hr>
<h3 id="3-对回车键的支持"><a href="#3-对回车键的支持" class="headerlink" title="3.对回车键的支持"></a>3.对回车键的支持</h3><ul>
<li>应该对输入的字符进行判断，然后执行相应的命令<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">    <span class="comment">/*从此开始*/</span> <span class="keyword">if</span> (i == <span class="number">256</span> + <span class="number">0x1c</span>) &#123; <span class="comment">/*回车键*/</span> </span><br><span class="line">     <span class="keyword">if</span> (key_to != <span class="number">0</span>) &#123; <span class="comment">/*发送至命令行窗口*/</span> </span><br><span class="line">        fifo32_put(&amp;task_cons-&gt;fifo, <span class="number">10</span> + <span class="number">256</span>); </span><br><span class="line"> &#125; </span><br><span class="line"><span class="comment">/*到此结束*/</span> &#125; </span><br><span class="line"> </span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-对窗口滚动的支持"><a href="#4-对窗口滚动的支持" class="headerlink" title="4.对窗口滚动的支持"></a>4.对窗口滚动的支持</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void console_task(struct SHEET *sheet) </span><br><span class="line">&#123; </span><br><span class="line"> （中略）</span><br><span class="line"> int x, y;</span><br><span class="line">  （中略）</span><br><span class="line"> for (;;) &#123; </span><br><span class="line">     io_cli(); </span><br><span class="line">     if (fifo32_status(&amp;task-&gt;fifo) == 0) &#123; </span><br><span class="line">     （中略）</span><br><span class="line"> &#125; else &#123; </span><br><span class="line">    （中略）</span><br><span class="line"> if (256 &lt;= i &amp;&amp; i &lt;= 511) &#123; /*键盘数据（通过任务A） */ </span><br><span class="line"> if (i == 8 + 256) &#123; </span><br><span class="line">     /*退格键*/ </span><br><span class="line">     （中略）</span><br><span class="line"> &#125; else if (i == 10 + 256) &#123; </span><br><span class="line">     /* Enter */ </span><br><span class="line">     /*用空格将光标擦除*/ </span><br><span class="line">     putfonts8_asc_sht(sheet, cursor_x, cursor_y, COL8_FFFFFF, COL8_000000, &quot; &quot;, 1); </span><br><span class="line">/*从此开始 */ if (cursor_y &lt; 28 + 112) &#123; </span><br><span class="line"> cursor_y += 16; /*换行*/ </span><br><span class="line"> &#125; else &#123; </span><br><span class="line">     /*滚动*/ </span><br><span class="line">     for (y = 28; y &lt; 28 + 112; y++) &#123; </span><br><span class="line">     for (x = 8; x &lt; 8 + 240; x++) &#123; </span><br><span class="line">     sheet-&gt;buf[x + y * sheet-&gt;bxsize] = sheet-&gt;buf[x + (y + 16) * </span><br><span class="line">     sheet-&gt;bxsize]; </span><br><span class="line">    &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> for (y = 28 + 112; y &lt; 28 + 128; y++) &#123; </span><br><span class="line">    for (x = 8; x &lt; 8 + 240; x++) &#123; </span><br><span class="line">        sheet-&gt;buf[x + y * sheet-&gt;bxsize] = COL8_000000; </span><br><span class="line">    &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> sheet_refresh(sheet, 8, 28, 8 + 240, 28 + 128); </span><br><span class="line"> &#125; </span><br><span class="line"> /*显示提示符*/ </span><br><span class="line"> putfonts8_asc_sht(sheet, 8, cursor_y, COL8_FFFFFF, COL8_000000, &quot;&gt;&quot;, 1); </span><br><span class="line">/*到此为止*/ cursor_x = 16; </span><br><span class="line"> &#125; else &#123; </span><br><span class="line"> /*一般字符*/ </span><br><span class="line"> （中略）</span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line"> （中略）</span><br><span class="line"> &#125; </span><br><span class="line"> &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-mem命令"><a href="#5-mem命令" class="headerlink" title="5.mem命令"></a>5.mem命令</h3><p>我们已经实现了屏幕滚动，现在该是到了让它执行命令的时候了。<br>mem命令就是memeory的缩写，也就是用来显示内存使用情况的命令。</p>
<hr>
<ul>
<li>介绍一下重点。首先我们添加了memtotal和memman两个变量，它们是执行mem命令所必需的。关于memtotal，我们采用和sheet相同的方法从HariMain传递过来，因此我们还要改写一下HariMain。</li>
<li>我们还添加了一个cmdline变量，也就是“命令行”（command line）的缩写。这个变量用来记录通过键盘输入的内容，在“键盘数据”处理的“一般字符”部分，将输入的内容顺次累积起来。</li>
</ul>
<h3 id="6-cls命令"><a href="#6-cls命令" class="headerlink" title="6.cls命令"></a>6.cls命令</h3><ul>
<li>这个命令的作用是清除屏幕上的内容，也就是“clear screen”（清屏）的缩写。顺便补充个小知识，在Linux中清屏命令是“clear”。<br>代码精简：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (c[0] == &#x27;m&#x27; &amp;&amp; c[1] == &#x27;e&#x27; &amp;&amp; c[2] == &#x27;m&#x27; &amp;&amp; c[3] == 0) &#123;</span><br></pre></td></tr></table></figure>
改成：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (strcmp(cmdline, &quot;mem&quot;) == 0) &#123;</span><br></pre></td></tr></table></figure>
strcmp这个函数，只要声明#include<string.h>即可使用，因此在bootpack.c中我们也要用它。</li>
</ul>
<h3 id="7-dir命令"><a href="#7-dir命令" class="headerlink" title="7. dir命令"></a>7. dir命令</h3><ul>
<li>我们的目标是制作可执行文件（比如.exe）来让它运行。</li>
<li>过在此之前，我们先来制作一个显示磁盘内文件名称的命令吧。</li>
<li>dir指令除了会显示文件名，还会显示文件的日期和大小。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（17）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8817%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY17-命令行窗口"><a href="#DAY17-命令行窗口" class="headerlink" title="DAY17_命令行窗口"></a>DAY17_命令行窗口</h1><h2 id="1-闲置任务"><a href="#1-闲置任务" class="headerlink" title="1.闲置任务"></a>1.闲置任务</h2><ul>
<li>即使不改写程序，也能自动在适当的LEVEL运行适当的任务，这样的操作系统才是优秀的操作系统</li>
<li>因此，一般情况下可以让任务休眠，但当所有LEVEL中都没有任务存在的时候，就需要HTL了。接下来我们就按照这个要求来改写mtask.c。</li>
<li>如果“所有LEVEL中都没有任务”就会出问题，那我们只要避免这种情况发生不就可以了吗？这类似于我们写定时器的时候所采用的“卫兵”的思路。</li>
</ul>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_idle(void) </span><br><span class="line">&#123; </span><br><span class="line">    for (;;) &#123; </span><br><span class="line">        io_hlt(); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>综上所述，我们完全不需要对task_sleep等代码进行任何改动，只需在task_init中将这个闲置任务放在最下层LEVEL中就可以了。</li>
</ul>
<h2 id="2-创建命令行窗口"><a href="#2-创建命令行窗口" class="headerlink" title="2.创建命令行窗口"></a>2.创建命令行窗口</h2><h2 id="3-切换输入窗口"><a href="#3-切换输入窗口" class="headerlink" title="3.切换输入窗口"></a>3.切换输入窗口</h2><ul>
<li>目标：我们要让系统在按下“Tab”键的时候，将输入窗口切换到命令行窗口上去。</li>
<li>我们先改变窗口标题栏的颜色。</li>
</ul>
<h2 id="4-实现字符输入"><a href="#4-实现字符输入" class="headerlink" title="4.实现字符输入"></a>4.实现字符输入</h2><ul>
<li>要实现字符的输入，只要在键盘被按下的时候向console_task的FIFO发送数据即可。</li>
<li>我们还是把struct FIFO放到struct TASK里面去吧。基本上没有什么任务是完全用不到FIFO的，因此我们把它们绑定起来</li>
<li>在向命令行窗口发送键盘数据的时候，并不是直接发送从键盘接收到的原始数据，而是发送经过keytable[]转换后的值。究其原因，是由于这样做可以省去在命令行窗口任务中将按键编码转换成字符编码的步骤<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void console_task(struct SHEET *sheet) </span><br><span class="line">&#123; </span><br><span class="line"> struct TIMER *timer; </span><br><span class="line"> struct TASK *task = task_now(); </span><br><span class="line"> int i, fifobuf[128], cursor_x = 16, cursor_c = COL8_000000; </span><br><span class="line"> char s[2]; </span><br><span class="line"> fifo32_init(&amp;task-&gt;fifo, 128, fifobuf, task); </span><br><span class="line"> timer = timer_alloc(); </span><br><span class="line"> timer_init(timer, &amp;task-&gt;fifo, 1); </span><br><span class="line"> timer_settime(timer, 50); </span><br><span class="line"> /*显示提示符*/ </span><br><span class="line"> putfonts8_asc_sht(sheet, 8, 28, COL8_FFFFFF, COL8_000000, &quot;&gt;&quot;, 1); </span><br><span class="line"> for (;;) &#123; </span><br><span class="line">    io_cli(); </span><br><span class="line">    if (fifo32_status(&amp;task-&gt;fifo) == 0) &#123; </span><br><span class="line">        task_sleep(task); </span><br><span class="line">        io_sti(); </span><br><span class="line">    &#125; else &#123; </span><br><span class="line">        i = fifo32_get(&amp;task-&gt;fifo); </span><br><span class="line">             io_sti(); </span><br><span class="line">             if (i &lt;= 1) &#123; /*光标用定时器*/ </span><br><span class="line">                if (i != 0) &#123; </span><br><span class="line">                    timer_init(timer, &amp;task-&gt;fifo, 0); /*接下来置0 */ </span><br><span class="line">                    cursor_c = COL8_FFFFFF; </span><br><span class="line">                &#125; else &#123; </span><br><span class="line">                    timer_init(timer, &amp;task-&gt;fifo, 1); /*接下来置1 */ </span><br><span class="line">                    cursor_c = COL8_000000; </span><br><span class="line">                &#125; </span><br><span class="line">                timer_settime(timer, 50); </span><br><span class="line">             &#125; </span><br><span class="line">             if (256 &lt;= i &amp;&amp; i &lt;= 511) &#123; /*键盘数据（通过任务A） */ </span><br><span class="line">                if (i == 8 + 256) &#123;</span><br><span class="line">                /*退格键*/ </span><br><span class="line">                if (cursor_x &gt; 16) &#123; </span><br><span class="line">                    /*用空白擦除光标后将光标前移一位*/ </span><br><span class="line">                    putfonts8_asc_sht(sheet, cursor_x, 28, COL8_FFFFFF, COL8_000000, &quot; &quot;, 1); </span><br><span class="line">                    cursor_x -= 8; </span><br><span class="line">                 &#125; </span><br><span class="line">             &#125; else &#123; </span><br><span class="line">                /*一般字符*/ </span><br><span class="line">                if (cursor_x &lt; 240) &#123; </span><br><span class="line">                    /*显示一个字符之后将光标后移一位 */ </span><br><span class="line">                    s[0] = i - 256; </span><br><span class="line">                    s[1] = 0; </span><br><span class="line">                    putfonts8_asc_sht(sheet, cursor_x, 28, COL8_FFFFFF, COL8_000000, s, 1); </span><br><span class="line">                    cursor_x += 8; </span><br><span class="line">                &#125; </span><br><span class="line">             &#125; </span><br><span class="line">             &#125; </span><br><span class="line">             /*重新显示光标*/ </span><br><span class="line">             boxfill8(sheet-&gt;buf, sheet-&gt;bxsize, cursor_c, cursor_x, 28, cursor_x + 7, 43); </span><br><span class="line">             sheet_refresh(sheet, cursor_x, 28, cursor_x + 8, 44); </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="5-符号的输入"><a href="#5-符号的输入" class="headerlink" title="5.符号的输入"></a>5.符号的输入</h2><ul>
<li>目标：实现！和%的输入</li>
<li>我们必须要处理shift键</li>
</ul>
<h2 id="6-大写字母和小写字母"><a href="#6-大写字母和小写字母" class="headerlink" title="6.大写字母和小写字母"></a>6.大写字母和小写字母</h2><ul>
<li>我们必须同时判断Shift键的状态和CapsLock的状态<ul>
<li>CapsLock 为 OFF &amp; Shift 键为 OFF → 小写英文字母</li>
<li>CapsLock 为 OFF &amp; Shift 键为 ON → 大写英文字母</li>
<li>CapsLock 为 ON &amp; Shift 键为 OFF → 大写英文字母</li>
<li>CapsLock 为 ON &amp; Shift 键为 ON → 小写英文字母</li>
</ul>
</li>
</ul>
<h2 id="7-对各种锁定键的支持"><a href="#7-对各种锁定键的支持" class="headerlink" title="7.对各种锁定键的支持"></a>7.对各种锁定键的支持</h2><ul>
<li>点亮/熄灭键盘上指示灯的方法</li>
<li>原理：<ul>
<li>对于NumLock和CapsLock等LED的控制，可采用下面的方法向键盘发送指令和数据。<ul>
<li>读取状态寄存器，等待 bit 1 的值变为 0。</li>
<li>向数据输出（0060）写入要发送的 1 个字节数据。</li>
<li>等待键盘返回 1 个字节的信息，这和等待键盘输入所采用的方法相同（用 IRQ等待或者用轮询状态寄存器 bit 1 的值直到其变为 0 都可以）。</li>
<li>返回的信息如果为 0xfa，表明 1 个字节的数据已成功发送给键盘。如为 0xfe则表明发送失败，需要返回第 1 步重新发送。</li>
</ul>
</li>
<li>要控制LED的状态，需要按上述方法执行两次，向键盘发送EDxx数据。其中，xx的bit 0代表ScrollLock，bit 1代表NumLock，bit2代表CapsLock（0表示熄灭，1表示点亮）。bit 3～7为保留位，置0即可。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#define KEYCMD_LED 0xed </span><br><span class="line">void HariMain(void) </span><br><span class="line">&#123; </span><br><span class="line">     （中略）</span><br><span class="line">     struct FIFO32 fifo, keycmd; </span><br><span class="line">     int fifobuf[128], keycmd_buf[32]; </span><br><span class="line">     （中略）</span><br><span class="line">     int key_to = 0, key_shift = 0, key_leds = (binfo-&gt;leds &gt;&gt; 4) &amp; 7, keycmd_wait = -1; </span><br><span class="line">     （中略）</span><br><span class="line">     fifo32_init(&amp;keycmd, 32, keycmd_buf, 0); </span><br><span class="line">     （中略）</span><br><span class="line">     </span><br><span class="line">     /*为了避免和键盘当前状态冲突，在一开始先进行设置*/ </span><br><span class="line">     fifo32_put(&amp;keycmd, KEYCMD_LED); </span><br><span class="line">     fifo32_put(&amp;keycmd, key_leds); </span><br><span class="line">     </span><br><span class="line">     for (;;) &#123; </span><br><span class="line">         if (fifo32_status(&amp;keycmd) &gt; 0 &amp;&amp; keycmd_wait &lt; 0) &#123; /*从此开始*/ </span><br><span class="line">             /*如果存在向键盘控制器发送的数据，则发送它 */ </span><br><span class="line">             keycmd_wait = fifo32_get(&amp;keycmd); </span><br><span class="line">             wait_KBC_sendready(); </span><br><span class="line">             io_out8(PORT_KEYDAT, keycmd_wait); </span><br><span class="line">         &#125; /*到此结束*/ </span><br><span class="line">         io_cli(); </span><br><span class="line">         if (fifo32_status(&amp;fifo) == 0) &#123; </span><br><span class="line">             task_sleep(task_a); </span><br><span class="line">             io_sti(); </span><br><span class="line">         &#125; else &#123; </span><br><span class="line">             i = fifo32_get(&amp;fifo); </span><br><span class="line">             io_sti(); </span><br><span class="line">             if (256 &lt;= i &amp;&amp; i &lt;= 511) &#123; /* 键盘数据 */ </span><br><span class="line">             （中略）</span><br><span class="line">            /*从此开始*/ if (i == 256 + 0x3a) &#123; /* CapsLock */ </span><br><span class="line">                 key_leds ^= 4; </span><br><span class="line">                 fifo32_put(&amp;keycmd, KEYCMD_LED); </span><br><span class="line">                 fifo32_put(&amp;keycmd, key_leds); </span><br><span class="line">             &#125; </span><br><span class="line">         if (i == 256 + 0x45) &#123; /* NumLock */ </span><br><span class="line">             key_leds ^= 2; </span><br><span class="line">             fifo32_put(&amp;keycmd, KEYCMD_LED); </span><br><span class="line">             fifo32_put(&amp;keycmd, key_leds); </span><br><span class="line">         &#125; </span><br><span class="line">         if (i == 256 + 0x46) &#123; /* ScrollLock */ </span><br><span class="line">             key_leds ^= 1; </span><br><span class="line">             fifo32_put(&amp;keycmd, KEYCMD_LED); </span><br><span class="line">             fifo32_put(&amp;keycmd, key_leds); </span><br><span class="line">         &#125; </span><br><span class="line">         if (i == 256 + 0xfa) &#123; /*键盘成功接收到数据*/ </span><br><span class="line">            keycmd_wait = -1; </span><br><span class="line">         &#125; </span><br><span class="line">         if (i == 256 + 0xfe) &#123; /*键盘没有成功接收到数据*/ </span><br><span class="line">            wait_KBC_sendready(); </span><br><span class="line">            io_out8(PORT_KEYDAT, keycmd_wait); </span><br><span class="line">            /*到此结束*/ &#125; </span><br><span class="line">         （中略）</span><br><span class="line">         &#125; else if (512 &lt;= i &amp;&amp; i &lt;= 767) &#123; /*鼠标数据*/ </span><br><span class="line">         （中略）</span><br><span class="line">         &#125; else if (i &lt;= 1) &#123; /*光标用定时器*/ </span><br><span class="line">         （中略）</span><br><span class="line">         &#125; </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>实现方法：<ul>
<li>创建了一个叫keycmd的FIFO缓冲区，它不是用来接收中断请求的，而是用来管理由任务A向键盘控制器发送数据的顺序的。如果有数据要发送到键盘控制器，首先会在这个keycmd中累积起来。</li>
<li>keycmd_wait变量，用来表示向键盘控制器发送数据的状态。当keycmd_wait的值为-1时，表示键盘控制器处于通常状态，可以发送指令；当值不为-1时，表示键盘控制器正在等待发送的数据，这时要发送的数据被保存在keycmd_wait变量中。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（16）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8816%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY16-多任务（2）"><a href="#DAY16-多任务（2）" class="headerlink" title="DAY16_多任务（2）"></a>DAY16_多任务（2）</h1><h2 id="1-任务管理自动化"><a href="#1-任务管理自动化" class="headerlink" title="1.任务管理自动化"></a>1.任务管理自动化</h2><ul>
<li>充分做好多任务机制的基础上，再利用多任务逐步完善操作系统本身。</li>
<li>如果我们想要运行三个任务的话，就必须改写mt_taskswitch的代码。如果能像当初定时器和窗口背景的做法一样更好。</li>
</ul>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct TASKCTL *taskctl; </span><br><span class="line">struct TIMER *task_timer; </span><br><span class="line">struct TASK *task_init(struct MEMMAN *memman) </span><br><span class="line">&#123; </span><br><span class="line">     int i; </span><br><span class="line">     struct TASK *task; </span><br><span class="line">     struct SEGMENT_DESCRIPTOR *gdt = (struct SEGMENT_DESCRIPTOR *) ADR_GDT; </span><br><span class="line">     taskctl = (struct TASKCTL *) memman_alloc_4k(memman, sizeof (struct TASKCTL)); </span><br><span class="line">     for (i = 0; i &lt; MAX_TASKS; i++) &#123; </span><br><span class="line">         taskctl-&gt;tasks0[i].flags = 0; </span><br><span class="line">         taskctl-&gt;tasks0[i].sel = (TASK_GDT0 + i) * 8; </span><br><span class="line">         set_segmdesc(gdt + TASK_GDT0 + i, 103, (int) &amp;taskctl-&gt;tasks0[i].tss, AR_TSS32); </span><br><span class="line">     &#125; </span><br><span class="line">     task = task_alloc();</span><br><span class="line">     task-&gt;flags = 2; /*活动中标志*/ </span><br><span class="line">     taskctl-&gt;running = 1; </span><br><span class="line">     taskctl-&gt;now = 0; </span><br><span class="line">     taskctl-&gt;tasks[0] = task; </span><br><span class="line">     load_tr(task-&gt;sel); </span><br><span class="line">     task_timer = timer_alloc(); </span><br><span class="line">     timer_settime(task_timer, 2); </span><br><span class="line">     return task; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>调用task_init，会返回一个内存地址，意思是==现在正在运行的这个程序，已经变成一个任务了==。可能大家不是很能理解这个说法，在调用init之后，所有程序的运行都会被当成任务来进行管理，而调用init的这个程序，我们也要让它所属于某个任务，这样一来，通过调用任务的设置函数，就可以对任务进行各种控制，比如说修改优先级等。</li>
</ul>
<h2 id="2-让任务休眠"><a href="#2-让任务休眠" class="headerlink" title="2.让任务休眠"></a>2.让任务休眠</h2><ul>
<li>给每个任务==分配不同的时间==——休眠+唤醒</li>
<li><p>休眠：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_sleep(struct TASK *task) </span><br><span class="line">&#123; </span><br><span class="line">     int i; </span><br><span class="line">     char ts = 0; </span><br><span class="line">     if (task-&gt;flags == 2) &#123; /*如果指定任务处于唤醒状态*/ </span><br><span class="line">         if (task == taskctl-&gt;tasks[taskctl-&gt;now]) &#123; </span><br><span class="line">            ts = 1; /*让自己休眠的话，稍后需要进行任务切换*/ </span><br><span class="line">         &#125; </span><br><span class="line">         /*寻找task所在的位置*/ </span><br><span class="line">         for (i = 0; i &lt; taskctl-&gt;running; i++) &#123; </span><br><span class="line">             if (taskctl-&gt;tasks[i] == task) &#123; </span><br><span class="line">                 /*在这里*/ </span><br><span class="line">                 break; </span><br><span class="line">             &#125; </span><br><span class="line">         &#125; </span><br><span class="line">         taskctl-&gt;running--; </span><br><span class="line">         if (i &lt; taskctl-&gt;now) &#123; </span><br><span class="line">            taskctl-&gt;now--; /*需要移动成员，要相应地处理*/ </span><br><span class="line">         &#125; </span><br><span class="line">         /*移动成员*/ </span><br><span class="line">         for (; i &lt; taskctl-&gt;running; i++) &#123; </span><br><span class="line">            taskctl-&gt;tasks[i] = taskctl-&gt;tasks[i + 1]; </span><br><span class="line">         &#125; </span><br><span class="line">         task-&gt;flags = 1; /*不工作的状态*/ </span><br><span class="line">         if (ts != 0) &#123; </span><br><span class="line">            /*任务切换*/ </span><br><span class="line">            if (taskctl-&gt;now &gt;= taskctl-&gt;running) &#123; </span><br><span class="line">                /*如果now的值出现异常，则进行修正*/ </span><br><span class="line">                taskctl-&gt;now = 0; </span><br><span class="line">            &#125; </span><br><span class="line">            farjmp(0, taskctl-&gt;tasks[taskctl-&gt;now]-&gt;sel); </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     return; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>唤醒：</p>
<ul>
<li>在FIFO中添加用于记录要唤醒任务的信息的成员。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct FIFO32 &#123; </span><br><span class="line">    int *buf; </span><br><span class="line">    int p, q, size, free, flags; </span><br><span class="line">    struct TASK *task; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="3-增加窗口数量"><a href="#3-增加窗口数量" class="headerlink" title="3.增加窗口数量"></a>3.增加窗口数量</h2></li>
</ul>
</li>
<li>形成任务A、任务B0、任务B1和任务B2的格局。</li>
<li>任务B0～B2各自拥有自己的窗口，它们的功能都一样，即进行计数，这有点像在Windows中启动了一个应用程序及其2个副本的感觉。</li>
</ul>
<h2 id="4-设定任务优先级（1）"><a href="#4-设定任务优先级（1）" class="headerlink" title="4.设定任务优先级（1）"></a>4.设定任务优先级（1）</h2><ul>
<li>改写mtask.c、task_switch<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_switch(void) </span><br><span class="line">&#123; </span><br><span class="line">     struct TASK *task; </span><br><span class="line">     taskctl-&gt;now++; </span><br><span class="line">     if (taskctl-&gt;now == taskctl-&gt;running) &#123; </span><br><span class="line">        taskctl-&gt;now = 0; </span><br><span class="line">     &#125; </span><br><span class="line">     task = taskctl-&gt;tasks[taskctl-&gt;now]; </span><br><span class="line">     timer_settime(task_timer, task-&gt;priority); </span><br><span class="line">     if (taskctl-&gt;running &gt;= 2) &#123; </span><br><span class="line">        farjmp(0, task-&gt;sel); </span><br><span class="line">     &#125;</span><br><span class="line">     return; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="5-设定任务优先级（2）"><a href="#5-设定任务优先级（2）" class="headerlink" title="5.设定任务优先级（2）"></a>5.设定任务优先级（2）</h2><ul>
<li>在操作系统中有一些处理，即使牺牲其他任务的性能也必须要尽快完成，否则会引起用户的不满，就比如这次对鼠标的处理。对于这类任务，我们可以让它在处理结束后马上休眠，而优先级则可以设置得非常高。</li>
<li>我们需要设计一种架构，使得即便高优先级的任务同时运行，也能够区分哪个更加优先。<br><img src="https://s2.ax1x.com/2019/04/07/AhpVk8.jpg" alt="16.1"></li>
<li>这种架构的工作原理是，最上层的LEVEL 0中只要存在哪怕一个任务，则完全忽略LEVEL 1和LEVEL 2中的任务，只在LEVEL 0的任务中进行任务切换。当LEVEL 0中的任务全部休眠，或者全部降到下层LEVEL，也就是当LEVEL 0中没有任何任务的时候，接下来开始轮到LEVEL 1中的任务进行任务切换。当LEVEL 0和LEVEL 1中都没有任务时，那就该轮到LEVEL2 出场了。<br>在这种架构下，只要把音乐播放任务设置在LEVEL 0中，就可以保证获得比鼠标更高的优先级。</li>
</ul>
<hr>
<ul>
<li>task_now 用于返回现在活动中的struct TASK的内存地址<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct TASK *task_now(void) </span><br><span class="line">&#123; </span><br><span class="line"> struct TASKLEVEL *tl = &amp;taskctl-&gt;level[taskctl-&gt;now_lv]; </span><br><span class="line"> return tl-&gt;tasks[tl-&gt;now]; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>task_add，用来向struct TASKLEVEL中添加一个任务<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_add(struct TASK *task) </span><br><span class="line">&#123; </span><br><span class="line"> struct TASKLEVEL *tl = &amp;taskctl-&gt;level[task-&gt;level]; </span><br><span class="line"> tl-&gt;tasks[tl-&gt;running] = task; </span><br><span class="line"> tl-&gt;running++; </span><br><span class="line"> task-&gt;flags = 2; /*活动中*/ </span><br><span class="line"> return; </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>task_remove</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_remove(struct TASK *task) </span><br><span class="line">&#123; </span><br><span class="line">     int i; </span><br><span class="line">     struct TASKLEVEL *tl = &amp;taskctl-&gt;level[task-&gt;level]; </span><br><span class="line">     /*寻找task所在的位置*/ </span><br><span class="line">     for (i = 0; i &lt; tl-&gt;running; i++) &#123; </span><br><span class="line">         if (tl-&gt;tasks[i] == task) &#123; </span><br><span class="line">             /*在这里 */ </span><br><span class="line">             break; </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     tl-&gt;running--; </span><br><span class="line">     if (i &lt; tl-&gt;now) &#123; </span><br><span class="line">        tl-&gt;now--; /*需要移动成员，要相应地处理 */ </span><br><span class="line">     &#125; </span><br><span class="line">     if (tl-&gt;now &gt;= tl-&gt;running) &#123; </span><br><span class="line">         /*如果now的值出现异常，则进行修正*/ </span><br><span class="line">         tl-&gt;now = 0; </span><br><span class="line">     &#125; </span><br><span class="line">     task-&gt;flags = 1; /* 休眠中 */ </span><br><span class="line">     /* 移动 */ </span><br><span class="line">     for (; i &lt; tl-&gt;running; i++) &#123;</span><br><span class="line">        tl-&gt;tasks[i] = tl-&gt;tasks[i + 1]; </span><br><span class="line">     &#125; </span><br><span class="line">     return; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>task_switchsub,用来在任务切换时决定接下来切换到哪个LEVEL</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_switchsub(void) </span><br><span class="line">&#123; </span><br><span class="line">     int i; </span><br><span class="line">     /*寻找最上层的LEVEL */ </span><br><span class="line">     for (i = 0; i &lt; MAX_TASKLEVELS; i++) &#123; </span><br><span class="line">     if (taskctl-&gt;level[i].running &gt; 0) &#123; </span><br><span class="line">     break; /*找到了*/ </span><br><span class="line">     &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     taskctl-&gt;now_lv = i; </span><br><span class="line">     taskctl-&gt;lv_change = 0; </span><br><span class="line">     return; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（15）</title>
    <url>/201904/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8815%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY15-多任务（1）"><a href="#DAY15-多任务（1）" class="headerlink" title="DAY15_多任务（1）"></a>DAY15_多任务（1）</h1><h2 id="1-挑战任务切换"><a href="#1-挑战任务切换" class="headerlink" title="1.挑战任务切换"></a>1.挑战任务切换</h2><ul>
<li><strong>多任务</strong>：多个应用程序同时运行的状态（也就是同时打开好几个窗口的状态）。</li>
<li>实际上这些程序==并没有在同时运行==，只是看上去好像是在同时运行一样。<br><img src="https://s2.ax1x.com/2019/04/07/Af2OaT.jpg" alt="15.1"></li>
</ul>
<span id="more"></span>
<ul>
<li>在一般的操作系统中，这个切换的动作每0.01～0.03秒就会进行一次。当然，切换的速度越快，让人觉得程序是在同时运行的效果也就越好。不过，CPU进行程序切换（我们称为“任务切换”）这个动作本身就需要消耗一定的时间，这个时间大约为0.0001秒左右，不同的CPU及操作系统所需的时间也有所不同。</li>
<li>CPU处理方式：当你向CPU发出任务切换的指令时，CPU会先把寄存器中的值全部写入内存中，这样做是为了当以后切换回这个程序的时候，可以从中断的地方继续运行。接下来，为了运行下一个程序，CPU会把所有寄存器中的值从内存中读取出来（当然，这个读取的地址和刚刚写入的地址一定是不同的，不然就相当于什么都没变嘛），这样就完成了一次切换。我们前面所说的任务切换所需要的时间，正是对内存进行写入和读取操作所消耗的时间。</li>
<li>TSS 任务状态段 task status segment</li>
<li>EIP 扩展指令指针寄存器 extended instruction pointer：CPU用来记录下一条需要执行的指令位于内存中哪个地址的寄存器，因此它才被称为“指令指针”。如果没有这个寄存器，记性不好的CPU就会忘记自己正在运行哪里的程序，于是程序就没办法正常运行了。每执行一条指令，EIP寄存器中的值就会自动累加，从而保证一直指向下一条指令所在的内存地址。</li>
</ul>
<h3 id="实际任务切换"><a href="#实际任务切换" class="headerlink" title="实际任务切换"></a>实际任务切换</h3><ul>
<li>创建两个TSS<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct TSS32 tss_a, tss_b;</span><br></pre></td></tr></table></figure></li>
<li>向它们的Idtr和iomap分别存入合适的值<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tss_a.ldtr = 0; </span><br><span class="line">tss_a.iomap = 0x40000000; </span><br><span class="line">tss_b.ldtr = 0; </span><br><span class="line">tss_b.iomap = 0x40000000;</span><br></pre></td></tr></table></figure></li>
<li><p>将它们两个在GDT中进行定义</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct SEGMENT_DESCRIPTOR *gdt = (struct SEGMENT_DESCRIPTOR *) ADR_GDT; </span><br><span class="line"> </span><br><span class="line">set_segmdesc(gdt + 3, 103, (int) &amp;tss_a, AR_TSS32); </span><br><span class="line">set_segmdesc(gdt + 4, 103, (int) &amp;tss_b, AR_TSS32);</span><br></pre></td></tr></table></figure>
</li>
<li><p>我们向TR寄存器存入3 * 8这个值，这是因为我们刚才把当前运行的任务定义为GDT的3号。</p>
</li>
<li>要进行任务切换，我们必须执行far模式的跳转指令</li>
</ul>
<hr>
<ul>
<li>在eip中，我们需要定义在切换到这个任务的时候，要从哪里开始运行。</li>
</ul>
<h2 id="2-任务切换进阶"><a href="#2-任务切换进阶" class="headerlink" title="2.任务切换进阶"></a>2.任务切换进阶</h2><ul>
<li>目标：从任务A切换到任务B，再切换回任务A</li>
</ul>
<h2 id="3-做个简单的多任务（1）"><a href="#3-做个简单的多任务（1）" class="headerlink" title="3.做个简单的多任务（1）"></a>3.做个简单的多任务（1）</h2><ul>
<li>目标：实现更快速的，来回交替的任务切换。这样我们就可以告别光标停住、鼠标卡死、键盘打不了字的情况，让两个任务看上去好像在同时运行一样。</li>
<li>把taskswitch写成一个函数<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">_farjmp: ; void farjmp(int eip, int cs); </span><br><span class="line"> JMP FAR [ESP+4] ; eip, cs </span><br><span class="line"> RET</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="4-做个简单的多任务（2）"><a href="#4-做个简单的多任务（2）" class="headerlink" title="4.做个简单的多任务（2）"></a>4.做个简单的多任务（2）</h2><h2 id="5-提高运行速度"><a href="#5-提高运行速度" class="headerlink" title="5.提高运行速度"></a>5.提高运行速度</h2><ul>
<li>因为我们的程序每计1个数就在画面上显示一次，但1秒钟之内刷新100次以上的话，人眼根本就分辨不出来，所以我们不需要计1个数就刷新一次，只要每隔0.01秒刷新一次就足够了。</li>
</ul>
<h2 id="6-测试运行速度"><a href="#6-测试运行速度" class="headerlink" title="6.测试运行速度"></a>6.测试运行速度</h2><p>向task_b_main添加代码测试运行速度<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void task_b_main(struct SHEET *sht_back) </span><br><span class="line">&#123; </span><br><span class="line">     struct FIFO32 fifo; </span><br><span class="line">     struct TIMER *timer_ts, *timer_put, *timer_1s; </span><br><span class="line">     int i, fifobuf[128], count = 0, count0 = 0; </span><br><span class="line">     char s[12]; </span><br><span class="line">     （中略）</span><br><span class="line">     timer_1s = timer_alloc(); </span><br><span class="line">     timer_init(timer_1s, &amp;fifo, 100); </span><br><span class="line">     timer_settime(timer_1s, 100); </span><br><span class="line">     for (;;) &#123; </span><br><span class="line">         count++; </span><br><span class="line">         io_cli(); </span><br><span class="line">         if (fifo32_status(&amp;fifo) == 0) &#123; </span><br><span class="line">            io_sti(); </span><br><span class="line">         &#125; else &#123; </span><br><span class="line">             i = fifo32_get(&amp;fifo);</span><br><span class="line">             io_sti(); </span><br><span class="line">             if (i == 1) &#123; </span><br><span class="line">                （中略）</span><br><span class="line">             &#125; else if (i == 2) &#123; </span><br><span class="line">                （中略）</span><br><span class="line">             &#125; else if (i == 100) &#123; </span><br><span class="line">                 sprintf(s, &quot;%11d&quot;, count - count0); </span><br><span class="line">                 putfonts8_asc_sht(sht_back, 0, 128, COL8_FFFFFF, COL8_008484, s, 11); </span><br><span class="line">                 count0 = count; </span><br><span class="line">                 timer_settime(timer_1s, 100); </span><br><span class="line">            &#125; </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="7-多任务进阶"><a href="#7-多任务进阶" class="headerlink" title="7.多任务进阶"></a>7.多任务进阶</h2><ul>
<li>真正的多任务，是要做到在程序本身不知道的情况下进行任务切换。</li>
<li>果使用这样的设计，即便在程序中不进行任务切换的处理（比如忘记写了，或者因为bug没能正常切换之类的），也一定会正常完成切换。之前那种多任务的话，如果任务B因为发生bug而无法进行切换，那么当切换到任务B以后，其他的任务就再也无法运行了，这样会造成无论是按键盘还是动鼠标都毫无反应的悲剧。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>插入排序（Insert Sort）、归并排序（Merge Sort）和快速排序（Quick Sort）</title>
    <url>/201904/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E5%92%8C%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<h2 id="一、算法简介"><a href="#一、算法简介" class="headerlink" title="一、算法简介"></a>一、算法简介</h2><h4 id="1-插入排序算法（Insert-Sort-Algorithm）"><a href="#1-插入排序算法（Insert-Sort-Algorithm）" class="headerlink" title="1.插入排序算法（Insert Sort Algorithm）"></a>1.插入排序算法（Insert Sort Algorithm）</h4><ul>
<li><strong>直接插入排序(Straight Insertion Sort)的基本思想是</strong>：<br>把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次==从无序表中取==出第一个元素，将它==插入到有序表中==的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。</li>
<li><strong>我们需要做的工作只有两个：</strong>   <ul>
<li>取出无序区中的第1个数，并找出它在有序区对应的位置。  </li>
<li>将无序区的数据插入到有序区；若有必要的话，则对有序区中的相关数据进行移位。</li>
</ul>
</li>
</ul>
<span id="more"></span>
<h4 id="2-归并排序算法（Merge-Sort-Algorithm）"><a href="#2-归并排序算法（Merge-Sort-Algorithm）" class="headerlink" title="2.归并排序算法（Merge Sort Algorithm）"></a>2.归并排序算法（Merge Sort Algorithm）</h4><ul>
<li><strong>归并排序的操作：</strong><br>将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。</li>
<li><strong>归并排序的应用场景：</strong><br>速度仅次于快速排序，为稳定排序算法，一般用于==对总体无序，但是各子项相对有序的数列==<h4 id="3-快速排序算法（Quick-Sort-Algorithm）"><a href="#3-快速排序算法（Quick-Sort-Algorithm）" class="headerlink" title="3.快速排序算法（Quick Sort Algorithm）"></a>3.快速排序算法（Quick Sort Algorithm）</h4></li>
<li><strong>快速排序的思想：</strong><br>通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</li>
<li><strong>适用场景：</strong><br>快速排序是==不稳定的==。它不需要额外的存储空间。它的应用场景是大规模的数据排序，并且实际性能要好于归并排序。</li>
</ul>
<h2 id="二、程序"><a href="#二、程序" class="headerlink" title="二、程序"></a>二、程序</h2><h3 id="Ⅰ、算法程序"><a href="#Ⅰ、算法程序" class="headerlink" title="Ⅰ、算法程序"></a>Ⅰ、算法程序</h3><h4 id="1-插入排序算法（Insert-Sort-Algorithm）-1"><a href="#1-插入排序算法（Insert-Sort-Algorithm）-1" class="headerlink" title="1.插入排序算法（Insert Sort Algorithm）"></a>1.插入排序算法（Insert Sort Algorithm）</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*Insertion Sorting*/</span></span><br><span class="line"><span class="comment">/*每次从无序的队列中选择一个插入，</span></span><br><span class="line"><span class="comment"> *直到所有元素都排序完成。*/</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">InsertSortUp</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> n)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</span><br><span class="line">		<span class="type">int</span> swap = A[i];</span><br><span class="line">		<span class="type">int</span> j;</span><br><span class="line">		<span class="keyword">for</span> (j = i<span class="number">-1</span> ; A[j] &gt; swap &amp;&amp; j &gt;= <span class="number">0</span>; j--)</span><br><span class="line">			A[j+<span class="number">1</span>] = A[j];</span><br><span class="line">		A[j+<span class="number">1</span>] = swap;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-归并排序算法（Merge-Sort-Algorithm）-1"><a href="#2-归并排序算法（Merge-Sort-Algorithm）-1" class="headerlink" title="2.归并排序算法（Merge Sort Algorithm）"></a>2.归并排序算法（Merge Sort Algorithm）</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*MergeSort*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Merge</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> p, <span class="type">int</span> q, <span class="type">int</span> r)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">//创造左右两个数组L、R，将已经排好的两部分放进去 </span></span><br><span class="line">	<span class="type">int</span> n1 = q - p + <span class="number">1</span>, n2 = r - q;</span><br><span class="line">	<span class="type">int</span> L[n1], R[n2];</span><br><span class="line">	<span class="type">int</span> i,j;</span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n1; i++)</span><br><span class="line">		L[i] = A[p + i];</span><br><span class="line">	<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n2; j++)</span><br><span class="line">		R[j] = A[q + <span class="number">1</span> + j];</span><br><span class="line">	</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	//开始对两个数组进行归并 </span><br><span class="line">	i = 0; j = 0;</span><br><span class="line">	for (int k = p; k &lt;= r; k++) &#123;</span><br><span class="line">		if(i == n1)&#123;//如果左边数组已经全放进去 </span><br><span class="line">			while(j &lt; n2)	A[k++] = R[j++];</span><br><span class="line">		&#125; else if ( j == n2)&#123;//如果右边数组已经全放进去 </span><br><span class="line">			while(i &lt; n1)	A[k++] = L[i++];</span><br><span class="line">		&#125; else&#123;//比较两个数组，把小的数放进A数组，指针后移 </span><br><span class="line">			if (L[i] &lt;= R[j]) &#123;</span><br><span class="line">				A[k] = L[i];</span><br><span class="line">				i++;</span><br><span class="line">			&#125;</span><br><span class="line">			else &#123;</span><br><span class="line">				A[k] = R[j];</span><br><span class="line">				j++;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void MergeSortUp(int A[], int p,int r)</span><br><span class="line">&#123;</span><br><span class="line">	if (p &lt; r) &#123;</span><br><span class="line">		int q = (p + r) / 2;</span><br><span class="line">		MergeSortUp(A, p, q);</span><br><span class="line">		MergeSortUp(A, q + 1, r);</span><br><span class="line">		Merge(A, p, q, r);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-快速排序算法（Quick-Sort-Algorithm）-1"><a href="#3-快速排序算法（Quick-Sort-Algorithm）-1" class="headerlink" title="3.快速排序算法（Quick Sort Algorithm）"></a>3.快速排序算法（Quick Sort Algorithm）</h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*QuickSort*/</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> i, <span class="type">int</span> j)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> x = A[i];</span><br><span class="line">	A[i] = A[j];</span><br><span class="line">	A[j] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">partition</span><span class="params">(<span class="type">int</span> A[], <span class="type">int</span> p, <span class="type">int</span> r)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> x = A[p];</span><br><span class="line">	<span class="type">int</span> i = p;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> j = p + <span class="number">1</span>; j &lt;= r; j++) &#123;</span><br><span class="line">		<span class="keyword">if</span> (A[j] &lt; x) &#123;</span><br><span class="line">			i = i + <span class="number">1</span>;</span><br><span class="line">			swap(A, i, j);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	swap(A, p, i);</span><br><span class="line">	<span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void QuickSortUp(int A[], int p, int r)</span><br><span class="line">&#123;</span><br><span class="line">	if (p &lt; r) &#123;</span><br><span class="line">		int q = partition(A, p, r);</span><br><span class="line">		QuickSortUp(A, p, q - 1);</span><br><span class="line">		QuickSortUp(A, q + 1, r);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Ⅱ、测试程序"><a href="#Ⅱ、测试程序" class="headerlink" title="Ⅱ、测试程序"></a>Ⅱ、测试程序</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*Test*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;ctime&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> size 10000 <span class="comment">//size为数据规模</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&quot;InsertSort.cpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&quot;MergeSort.cpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&quot;QuickSort.cpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> A[size];</span><br><span class="line"><span class="type">clock_t</span> start,finish;</span><br><span class="line"><span class="type">double</span> runtime_insert,runtime_merge,runtime_quick;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*Generating test data set*/</span><br><span class="line">void tstdata(int n)</span><br><span class="line">&#123;</span><br><span class="line">	FILE *fp;</span><br><span class="line">	if((fp = fopen(&quot;tstdata.txt&quot;,&quot;w+&quot;))== NULL)</span><br><span class="line">		printf(&quot;cant open the file.\n&quot;);</span><br><span class="line">	else&#123;</span><br><span class="line">		srand(time(NULL));</span><br><span class="line">		for (int i = 1; i &lt;= n; i++) &#123;</span><br><span class="line">			if(i!=n) fprintf(fp,&quot;%d &quot;,rand());</span><br><span class="line">	      else fprintf(fp,&quot;%d\n&quot;,rand());</span><br><span class="line">		&#125;</span><br><span class="line">		fclose(fp);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*output function*/</span><br><span class="line">int output(char *filename,int A[])</span><br><span class="line">&#123;</span><br><span class="line">    FILE * fp;</span><br><span class="line">    if((fp = fopen(filename,&quot;w+&quot;))==NULL)&#123;</span><br><span class="line">      printf(&quot;cant open the file.\n&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">	   for(int i=0;i&lt;size;i++)&#123;</span><br><span class="line">		   if(i!=size-1) fprintf(fp,&quot;%d &quot;,A[i]);</span><br><span class="line">		   else fprintf(fp,&quot;%d\n&quot;,A[i]);</span><br><span class="line">	   &#125;</span><br><span class="line">	   fclose(fp);</span><br><span class="line">	 &#125;</span><br><span class="line">    </span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main()</span><br><span class="line">&#123;</span><br><span class="line">	int i=0;</span><br><span class="line">	</span><br><span class="line">	/*generating test data*/</span><br><span class="line">	/*tstdata(size);</span><br><span class="line">	printf(&quot;Data set has been created.\n&quot;);*/</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	/*get the test data*/</span><br><span class="line">	FILE *fp;</span><br><span class="line">	if((fp = fopen(&quot;tstdata.txt&quot;,&quot;r&quot;))==NULL)&#123;</span><br><span class="line">		printf(&quot;cant open the file.\n&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">	while(fscanf(fp, &quot;%d&quot;, &amp;A[i]) != EOF) </span><br><span class="line">        i++;</span><br><span class="line">   fclose(fp);</span><br><span class="line">	 for(i=0;i&lt;size;i++)&#123;</span><br><span class="line">	 	printf(&quot;%d &quot;,A[i]);</span><br><span class="line">	 &#125; </span><br><span class="line">	 printf(&quot;\n&quot;);</span><br><span class="line">	 printf(&quot;Array has been created.\n&quot;);</span><br><span class="line">	   </span><br><span class="line">	    </span><br><span class="line">	/*copy the test data set*/</span><br><span class="line">	int A1[size],A2[size],A3[size];</span><br><span class="line">	for(int i=0;i&lt;size;i++)&#123;</span><br><span class="line">		A1[i]=A[i];</span><br><span class="line">		A2[i]=A[i];</span><br><span class="line">		A3[i]=A[i];</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    /*Insert Sorting*/</span><br><span class="line">	printf(&quot;Insert Sorting...\n&quot;);</span><br><span class="line">	</span><br><span class="line">	start = clock();</span><br><span class="line">	InsertSortUp(A1,size);</span><br><span class="line">	finish = clock();</span><br><span class="line">	</span><br><span class="line">	output(&quot;InsertSortUp.txt&quot;,A1);</span><br><span class="line">	runtime_insert = (double)(finish - start)/CLOCKS_PER_SEC;</span><br><span class="line">	printf(&quot;Insert Sort has been finished.\nTime Cost:%lf\n&quot;,runtime_insert);</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">    /*Merge Sorting*/</span><br><span class="line">	printf(&quot;Merge Sorting...\n&quot;);</span><br><span class="line">	</span><br><span class="line">	start = clock();</span><br><span class="line">	MergeSortUp(A2,0,size-1);</span><br><span class="line">	finish = clock();</span><br><span class="line">	</span><br><span class="line">	output(&quot;MergeSortUp.txt&quot;,A2);</span><br><span class="line">	runtime_merge = (double)(finish-start)/CLOCKS_PER_SEC;</span><br><span class="line">	printf(&quot;Merge Sort has been finished.\nTime Cost:%lf\n&quot;,runtime_merge);</span><br><span class="line"></span><br><span class="line">    /*Quick Sorting*/</span><br><span class="line">	printf(&quot;Quick Sorting...\n&quot;);</span><br><span class="line">	</span><br><span class="line">	start = clock();</span><br><span class="line">	QuickSortUp(A3,0,size-1);</span><br><span class="line">	finish = clock();</span><br><span class="line">	</span><br><span class="line">	output(&quot;QuickSortUp.txt&quot;,A3);</span><br><span class="line">	runtime_quick = (double)(finish-start)/CLOCKS_PER_SEC;</span><br><span class="line">	printf(&quot;Quick Sort has been finished.\nTime Cost:%lf\n&quot;,runtime_quick);</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="三、测试数据集生成及测试"><a href="#三、测试数据集生成及测试" class="headerlink" title="三、测试数据集生成及测试"></a>三、测试数据集生成及测试</h2><ul>
<li><strong>我为算法的测试准备了12个测试数据集，其中数据量分别为10,000\50,000\100,000</strong>  </li>
<li><strong>每个数据量下有==随机生成数据集（用于测试平均复杂度）==和==逆序数据集（用于测试最坏情况）==</strong>  </li>
<li><strong>为了减小误差，每个类型的数据集都准备了两个，这样便生成了3x2x2=12个数据集</strong></li>
<li><strong>算法的正确性测试在数据量很小的时候进行了手动验证，所以这里我们仅着重比较时间复杂度</strong></li>
</ul>
<h3 id="Ⅰ、测试数据集生成"><a href="#Ⅰ、测试数据集生成" class="headerlink" title="Ⅰ、测试数据集生成"></a>Ⅰ、测试数据集生成</h3><p>通过main函数中的/<em>generating test data</em>/部分生成“随机生成测试集”，详细测试数据见附件。<br>通过快速排序算法生成相应的“逆序数据集”进行排序算法的时间复杂度测试，详细数据见附件。</p>
<h3 id="Ⅱ、测试过程"><a href="#Ⅱ、测试过程" class="headerlink" title="Ⅱ、测试过程"></a>Ⅱ、测试过程</h3><p>测试结果如下表：（详见附件）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>data set</th>
<th>Insert Sort(s)</th>
<th>Merge Sort(s)</th>
<th>Quick Sort(s) </th>
</tr>
</thead>
<tbody>
<tr>
<td>S1:10,000\rand array(average condition)</td>
<td>0.082</td>
<td>0.001</td>
<td>0.002</td>
</tr>
<tr>
<td>S2:10,000\rand array(average condition)</td>
<td>0.069</td>
<td>0.002</td>
<td>0.001</td>
</tr>
<tr>
<td>S3:10,000\reserve array(worst condition)</td>
<td>0.469</td>
<td>0.003</td>
<td>0.554</td>
</tr>
<tr>
<td>S4:10,000\reserve array(worst condition)</td>
<td>0.463</td>
<td>0.003</td>
<td>0.546</td>
</tr>
<tr>
<td>S5:50,000\rand array(average condition)</td>
<td>1.718</td>
<td>0.009</td>
<td>0.009</td>
</tr>
<tr>
<td>S6:50,000\rand array(average condition)</td>
<td>1.881</td>
<td>0.01</td>
<td>0.009</td>
</tr>
<tr>
<td>S7:50,000\reserve array(worst condition)</td>
<td>8.54</td>
<td>0.015</td>
<td>/</td>
</tr>
<tr>
<td>S8:50,000\reserve array(worst condition)</td>
<td>7.956</td>
<td>0.015</td>
<td>/</td>
</tr>
<tr>
<td>S9:100,000\rand array(average condition)</td>
<td>7.023</td>
<td>0.022</td>
<td>0.017</td>
</tr>
<tr>
<td>S10:100,000\rand array(average condition)</td>
<td>6.86</td>
<td>0.02</td>
<td>0.018</td>
</tr>
<tr>
<td>S11:100,000\reserve array(worst condition)</td>
<td>31.549</td>
<td>0.027</td>
<td>/</td>
</tr>
<tr>
<td>S12:100,000\reserve array(worst condition)</td>
<td>30.989</td>
<td>0.029</td>
<td>/</td>
</tr>
</tbody>
</table>
</div>
<p><em>注：50,000和100,000数据量下，最坏情况下快速排序算法程序没法完成排序</em></p>
<h2 id="四、算法复杂度分析"><a href="#四、算法复杂度分析" class="headerlink" title="四、算法复杂度分析"></a>四、算法复杂度分析</h2><h4 id="1-插入排序算法（Insert-Sort-Algorithm）-2"><a href="#1-插入排序算法（Insert-Sort-Algorithm）-2" class="headerlink" title="1.插入排序算法（Insert Sort Algorithm）"></a>1.插入排序算法（Insert Sort Algorithm）</h4><ul>
<li>最优情况：<br>最少比较一次，移动两次。<br>Cmin = n-1；Mmin=（n-1）×2；</li>
<li>最坏情况：<br>最多比较i次，移动i＋2次（逆序）（i=1，2，…，n-1）<br>Cmax=1+2+…+（n-1）=（n2-n）/2<br>M max=3+4+…+（n+1）=（n2+3n-4）/2<br>Cave=（n2+n-2）/4<br>M ave=（n2+7n-8）/4</li>
<li>故直接插入排序的时间复杂度为O（n2），它的时间复杂度和待排序列的顺序有关。</li>
</ul>
<h4 id="2-归并排序算法（Merge-Sort-Algorithm）-2"><a href="#2-归并排序算法（Merge-Sort-Algorithm）-2" class="headerlink" title="2.归并排序算法（Merge Sort Algorithm）"></a>2.归并排序算法（Merge Sort Algorithm）</h4><p>通过迭代作图法可知，归并算法的算法复杂度为O(nlogn)，它的时间复杂度和待排序列的顺序无关。</p>
<h4 id="3-快速排序算法（Quick-Sort-Algorithm）-2"><a href="#3-快速排序算法（Quick-Sort-Algorithm）-2" class="headerlink" title="3.快速排序算法（Quick Sort Algorithm）"></a>3.快速排序算法（Quick Sort Algorithm）</h4><ul>
<li>最坏情况：<br>顺序或逆序时，一次partition只能解决一个元素的位置 排列，所以最坏情况下的时间复杂度为O(n^2)</li>
<li>平均情况：<br>O(logn),枢轴元素两边的待排序列分的越平均，时间复杂度越小。</li>
</ul>
<h2 id="五、算法优化"><a href="#五、算法优化" class="headerlink" title="五、算法优化"></a>五、算法优化</h2><h3 id="1-归并排序的“哨兵”"><a href="#1-归并排序的“哨兵”" class="headerlink" title="1.归并排序的“哨兵”"></a>1.归并排序的“哨兵”</h3><p>在归并排序中，将两个已经排号的序列整合在一起时，之前我们是这样做的：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if(i == n1)&#123;//如果左边数组已经全放进去 </span><br><span class="line">			while(j &lt; n2)	A[k++] = R[j++];</span><br><span class="line">		&#125; else if ( j == n2)&#123;//如果右边数组已经全放进去 </span><br><span class="line">			while(i &lt; n1)	A[k++] = L[i++];</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure><br>如果在待排的两个序列的最右端添加一个==哨兵==，即最大值MAX，就不用判断有序列已经选完了的问题，能够有效的减少判断的次数。</p>
<h3 id="2-快速排序枢轴元素pivot的选取"><a href="#2-快速排序枢轴元素pivot的选取" class="headerlink" title="2.快速排序枢轴元素pivot的选取"></a>2.快速排序枢轴元素pivot的选取</h3><p>pivot的选择对于快速排序时间复杂度的影响十分的大。从上面的“逆序测试数据”可知，如果每次选择的pivot都是最大/最小值，快速排序的复杂度可能会达到O(n^2)。<br>每次运行过程中，随机选取pivot, 通常能得到比较好的结果。<br>我采用了一种==三者取中==的方法，即选取第一个、最后一个以及中间的元素的中位数作为pivot，这样能够有效的避免“worst condition”的出现。<br>代码如下：(摘自csdn博客)<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//median-of-three pivot rule</span><br><span class="line">private static int choosePivotMedianOfThree(int[] a, int l, int r) &#123;	</span><br><span class="line">	int mid = 0;</span><br><span class="line">	if ((r-l+1) % 2 == 0) &#123;</span><br><span class="line">		mid = l + (r-l+1)/2 - 1;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		mid = l + (r-l+1)/2;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	//只需要找出中位数即可，不需要交换</span><br><span class="line">    //有的版本也可以进行交换</span><br><span class="line">	if (((a[l]-a[mid]) * (a[l]-a[r])) &lt;= 0) &#123;</span><br><span class="line">		return l;</span><br><span class="line">	&#125; else if (((a[mid]-a[l]) * (a[mid]-a[r])) &lt;= 0) 	&#123;</span><br><span class="line">		return mid;</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		return r;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">--------------------- </span><br><span class="line">/*作者：xinyuexy </span><br><span class="line"> *来源：CSDN </span><br><span class="line"> *原文：https://blog.csdn.net/qq_31903733/article/details/82945605 </span><br><span class="line"> *版权声明：本文为博主原创文章，转载请附上博文链接！*/</span><br></pre></td></tr></table></figure><br>再将选取的pivot与队列第一个元素交换即可。</p>
<h3 id="3-快速排序稳定性的改善"><a href="#3-快速排序稳定性的改善" class="headerlink" title="3.快速排序稳定性的改善"></a>3.快速排序稳定性的改善</h3><p>快速排序是“不稳定”的原因在于，partition的最后一步，pivot和指针i位置的元素交换。<br>举例：</p>
<ul>
<li>3  1  3’  5   2   6  1’(大小相同的元素用’区分)</li>
<li>3  1  2   5   3’  6  1’</li>
<li>3  1  2   1’  3’  6  5<br>(这时候还没问题)</li>
<li>1’ 1  2   3   3’  6  5<br>(最后一步1’和1的顺序发生变化)</li>
</ul>
<p>解决方法：每次partition的最后一步时，遍历待排数组A[i]之前的部分，将与A[i]大小相同的元素整体后移。</p>
<h2 id="六、实验心得"><a href="#六、实验心得" class="headerlink" title="六、实验心得"></a>六、实验心得</h2><ul>
<li>本次实验我学习了三种重要算法：插入排序算法、归并排序算法和快速排序算法，了解了它们的原理和适用的情景。</li>
<li>我认为相对于快速排序，归并排序更具有健壮性，它不会因为序列的顺序影响时间复杂度，而且它是一个稳定的排序。可能由于数据集不够大，我还没能充分体会到快速排序在时间上的优势。</li>
<li>最坏情况下的时间复杂度和平均时间复杂度相差非常大，在以后分析算法时要兼顾两者。</li>
</ul>
<h2 id="七、附录大纲"><a href="#七、附录大纲" class="headerlink" title="七、附录大纲"></a>七、附录大纲</h2><ul>
<li>Test.cpp<br>测试程序，包括数据集生成，待排序列输出等等。</li>
<li>InsertSort.cpp<br>插入排序算法</li>
<li>MergeSort.cpp<br>归并排序算法</li>
<li>QuickSort.cpp<br>快速排序算法</li>
<li>12个测试数据集txt</li>
<li>12个测试结果的截图</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>插入排序</tag>
        <tag>归并排序</tag>
        <tag>快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title>30天自制操作系统（14）</title>
    <url>/201903/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8814%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY14-高分辨率及键盘输入"><a href="#DAY14-高分辨率及键盘输入" class="headerlink" title="DAY14_高分辨率及键盘输入"></a>DAY14_高分辨率及键盘输入</h1><h2 id="1-继续测试性能"><a href="#1-继续测试性能" class="headerlink" title="1. 继续测试性能"></a>1. 继续测试性能</h2><ul>
<li>之前我们通过“消除位移处理”缩短时间，对于很多“位移”情况，改进才能看到效果。所以我们使用大量的定时器，然后对性能进行比较。</li>
</ul>
<h2 id="2-提高分辨率（1）"><a href="#2-提高分辨率（1）" class="headerlink" title="2.提高分辨率（1）"></a>2.提高分辨率（1）</h2><ul>
<li>由于画面切换中我们要使用BIOS，所以就需要改写asmhead.nas的“画面模式设定”部分了。</li>
</ul>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">; 设定画面模式</span><br><span class="line">     MOV BX,0x4101 ; VBE的640x480x8bi彩色</span><br><span class="line">     MOV AX,0x4f02 </span><br><span class="line">     INT 0x10 </span><br><span class="line">     MOV BYTE [VMODE],8 ; 记下画面模式（参考C语言）</span><br><span class="line">     MOV WORD [SCRNX],640 </span><br><span class="line">     MOV WORD [SCRNY],480 </span><br><span class="line">     MOV DWORD [VRAM],0xe0000000 </span><br></pre></td></tr></table></figure>
<h2 id="3-提高分辨率（2）"><a href="#3-提高分辨率（2）" class="headerlink" title="3.提高分辨率（2）"></a>3.提高分辨率（2）</h2><ul>
<li>将程序改写，使在真机上运行</li>
</ul>
<h2 id="4-键盘输入（1）"><a href="#4-键盘输入（1）" class="headerlink" title="4.键盘输入（1）"></a>4.键盘输入（1）</h2><ul>
<li>按照下表，在键盘按键的基础上加上0x80就可以得到键弹起时的数值<br><img src="https://s2.ax1x.com/2019/03/31/ArbywT.jpg" alt="14.1"></li>
</ul>
<h2 id="5-键盘输入（2）"><a href="#5-键盘输入（2）" class="headerlink" title="5.键盘输入（2）"></a>5.键盘输入（2）</h2><ul>
<li>问题：每一个按键都需要一个if，程序会变长，我们进行修改：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static char keytable[0x54] = &#123; </span><br><span class="line">     0, 0, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;0&#x27;, &#x27;-&#x27;, &#x27;^&#x27;, 0, 0, </span><br><span class="line">     &#x27;Q&#x27;, &#x27;W&#x27;, &#x27;E&#x27;, &#x27;R&#x27;, &#x27;T&#x27;, &#x27;Y&#x27;, &#x27;U&#x27;, &#x27;I&#x27;, &#x27;O&#x27;, &#x27;P&#x27;, &#x27;@&#x27;, &#x27;[&#x27;, 0, 0, &#x27;A&#x27;, &#x27;S&#x27;, </span><br><span class="line">     &#x27;D&#x27;, &#x27;F&#x27;, &#x27;G&#x27;, &#x27;H&#x27;, &#x27;J&#x27;, &#x27;K&#x27;, &#x27;L&#x27;, &#x27;;&#x27;, &#x27;:&#x27;, 0, 0, &#x27;]&#x27;, &#x27;Z&#x27;, &#x27;X&#x27;, &#x27;C&#x27;, &#x27;V&#x27;, </span><br><span class="line">     &#x27;B&#x27;, &#x27;N&#x27;, &#x27;M&#x27;, &#x27;,&#x27;, &#x27;.&#x27;, &#x27;/&#x27;, 0, &#x27;*&#x27;, 0, &#x27; &#x27;, 0, 0, 0, 0, 0, 0, </span><br><span class="line">     0, 0, 0, 0, 0, 0, 0, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;-&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;+&#x27;, &#x27;1&#x27;, </span><br><span class="line">     &#x27;2&#x27;, &#x27;3&#x27;, &#x27;0&#x27;, &#x27;.&#x27; </span><br><span class="line">     &#125;; </span><br><span class="line"> if (256 &lt;= i &amp;&amp; i &lt;= 511) &#123; /* 键盘数据 */ </span><br><span class="line">     sprintf(s, &quot;%02X&quot;, i - 256); </span><br><span class="line">     putfonts8_asc_sht(sht_back, 0, 16, COL8_FFFFFF, COL8_008484, s, 2); </span><br><span class="line">         if (i &lt; 256 + 0x54) &#123; </span><br><span class="line">             if (keytable[i - 256] != 0) &#123; </span><br><span class="line">             s[0] = keytable[i - 256]; </span><br><span class="line">             s[1] = 0; </span><br><span class="line">             putfonts8_asc_sht(sht_win, 40, 28, COL8_000000, COL8_C6C6C6, s, 1); </span><br><span class="line">             &#125; </span><br><span class="line">        &#125; </span><br><span class="line"> &#125; else if (512 &lt;= i &amp;&amp; i &lt;= 767) &#123; /* 鼠标数据 */ </span><br></pre></td></tr></table></figure>
<h2 id="6-追记内容（1）"><a href="#6-追记内容（1）" class="headerlink" title="6.追记内容（1）"></a>6.追记内容（1）</h2><p>==在窗口中添加一些画，改变鼠标和字符的显示位置以及颜色。按下BackSpace，还可以改写已经输入的字符==</p>
<h2 id="7-追记内容（2）"><a href="#7-追记内容（2）" class="headerlink" title="7.追记内容（2）"></a>7.追记内容（2）</h2><p>==使用鼠标移动窗口==<br>添加的程序<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if ((mdec.btn &amp; 0x01) != 0) &#123; </span><br><span class="line"> /* 按下左键、移动sht_win */</span><br><span class="line"> sheet_slide(sht_win, mx - 80, my - 8); </span><br><span class="line">/* 到这里结束！ */ &#125; </span><br></pre></td></tr></table></figure></p>
<ul>
<li>即使窗口跑到了画面外，也没有问题。因为我们已经针对鼠标指针提前采取了对策，这就如<br>同图层跑到了画面外面也可以动起来一样。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（13）</title>
    <url>/201903/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8813%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY13-定时器（2）"><a href="#DAY13-定时器（2）" class="headerlink" title="DAY13_定时器（2）"></a>DAY13_定时器（2）</h1><h2 id="1-简化字符串显示"><a href="#1-简化字符串显示" class="headerlink" title="1. 简化字符串显示"></a>1. 简化字符串显示</h2><ul>
<li>将“涂背景色、写字符、完成刷新”写进一个函数，更方便使用<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void putfonts8_asc_sht(struct SHEET *sht, int x, int y, int c, int b, char *s, int l) </span><br><span class="line">&#123; </span><br><span class="line">     boxfill8(sht-&gt;buf, sht-&gt;bxsize, b, x, y, x + l * 8 - 1, y + 15); </span><br><span class="line">     putfonts8_asc(sht-&gt;buf, sht-&gt;bxsize, x, y, c, s); </span><br><span class="line">     sheet_refresh(sht, x, y, x + l * 8, y + 16); </span><br><span class="line">     return; </span><br><span class="line">&#125; </span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x, y ...... 显示位置的坐标</span><br><span class="line">c ...... 字符颜色（color）</span><br><span class="line">b ...... 背景颜色（back color）</span><br><span class="line">s ...... 字符串（string）</span><br><span class="line">l ...... 字符串长度（length）</span><br></pre></td></tr></table></figure>
<h2 id="2-重新调整FIFO缓冲区（1）"><a href="#2-重新调整FIFO缓冲区（1）" class="headerlink" title="2.重新调整FIFO缓冲区（1）"></a>2.重新调整FIFO缓冲区（1）</h2><ul>
<li>将定时器用的多个FIFO缓冲区都集中成一个，往FIFO写入不同的数据，就能够正常地分辨出是哪个寄存器超时了。</li>
</ul>
<h2 id="3-测试性能"><a href="#3-测试性能" class="headerlink" title="3.测试性能"></a>3.测试性能</h2><ul>
<li>我们专注于定时器地改良，是因为在今后地开发中会经常使用定时器。</li>
<li>测试性能地方法：先对HariMain略加修改，恢复变量count，然后完全不显示计数，全力执行“count++；”语句。当到了10秒后超时的时候，再显示这个count值。</li>
</ul>
<h2 id="4-重新调整FIFO缓冲区（2）"><a href="#4-重新调整FIFO缓冲区（2）" class="headerlink" title="4.重新调整FIFO缓冲区（2）"></a>4.重新调整FIFO缓冲区（2）</h2><ul>
<li>把3个定时器全部归纳到一个FIFO缓冲区中，就可以把键盘和鼠标归纳起来，只用1个FIFO缓冲区。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0～ 1…………………光标闪烁用定时器</span><br><span class="line">3…………………3秒定时器</span><br><span class="line">10…………………10秒定时器</span><br><span class="line">256～ 511…………………键盘输入（从键盘控制器读入的值再加上256）</span><br><span class="line">512～ 767……鼠标输入（从键盘控制器读入的值再加上512）</span><br></pre></td></tr></table></figure>
<ul>
<li>此次我们改写最多的是HariMain。在HariMain里，执行“count++;”语句和查询FIFO缓冲区中是否有数据这两个操作，是多次交互进行的。这次修改以后，程序只需要看1个FIFO缓冲区就行了，而以前要看3个。也就是说，FIFO缓冲区的查询能够更快完成，从而使得“count++;”语句执行的次数更多。</li>
</ul>
<h2 id="5-加快中断处理（4）"><a href="#5-加快中断处理（4）" class="headerlink" title="5.加快中断处理（4）"></a>5.加快中断处理（4）</h2><ul>
<li>在FIFO里有一个取代移位处理的方法：读取一个数据以后不是让后面的数据向前靠齐，而是<br>改变下一次的数据读取地址。这是一个很巧妙的方法，但不适用于定时器。因为从timers[ ]中去除超时的中断时，这个方法虽然不错，但问题在于，用timer_settime登录中断时，后面的中断必须后移，在这一点上，以上方法不太好。</li>
<li><p>更好的方法：我们在结构体struct TIMER中加入next变量。这是个地址变量，用来存放下一个即将超时的定时器的地址。<br><img src="https://s2.ax1x.com/2019/03/31/ArHaKx.jpg" alt="13.1"></p>
</li>
<li><p>判断一下顺序，如果我们知道了插入的位置（即知道了在s和t中间插入的话），就可以像下图那样把数据重新连接起来。也就是仅仅改变s-&gt;next和timer-&gt;next的值就可以了。</p>
</li>
</ul>
<p><img src="https://s2.ax1x.com/2019/03/31/ArHgxI.jpg" alt="13.2"></p>
<h2 id="6-使用“哨兵”简化程序"><a href="#6-使用“哨兵”简化程序" class="headerlink" title="6.使用“哨兵”简化程序"></a>6.使用“哨兵”简化程序</h2><ul>
<li>我们来看看具体的做法。在进行初始化的时候，将时刻0xffffffff的定时器连到最后一个定时器上。虽然我们偷了点懒没有设定fifo等，但不必担心。反正无论如何都不可能到达这个时刻（在到达之前会修改时刻），所以不可能发生超时问题。它一直处于后面，只是个附带物，是个留下来看家的留守者。这个留守者正是“哨兵“。</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（12）</title>
    <url>/201903/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8812%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY12-定时器（1）"><a href="#DAY12-定时器（1）" class="headerlink" title="DAY12_定时器（1）"></a>DAY12_定时器（1）</h1><h2 id="1-使用定时器"><a href="#1-使用定时器" class="headerlink" title="1.使用定时器"></a>1.使用定时器</h2><p><font color="FF0000">介绍定时器的作用，添加定时器实现中断。</font></p>
<ul>
<li>定时器（Timer）对于操作系统十分重要，每隔一段时间就发送一个中断信号给CPU。有了定时器，CPU就不用辛苦地计量时间。</li>
<li>没有定时器，我们就没法使用HLT指令，意味着要浪费很多电能。</li>
<li>有了定时器中断，程序只需要以自己的步调处理自己的问题就可以了。至于到底经过了多少时间，只要在中断处理程序中数一数定时器中断发生的次数就可以了。</li>
</ul>
<span id="more"></span>
<hr>
<ul>
<li>要在电脑中管理定时器，只需要对PIT（Programmable Interval Timer可编程的间隔型定时器）进行设定就可以了。通过设定PIT，让定时器每隔多少秒就产生一次中断。</li>
<li>在电脑中PIT连接着IRQ（interrupt request）的0号，所以只要设定了PIT就可以设定IRQ0的中断间隔。</li>
<li>我们不清楚其中的详细原理，只知道只要执行3次OUT指令设定就完成了。将中断周期设定为11932的话，中断频率好像就是100Hz，也就是说1秒钟会发生100次中断。</li>
<li>IRQ0发生时所调用的中断处理程序几乎和键盘的中断处理程序一样。</li>
</ul>
<h2 id="2-计量时间"><a href="#2-计量时间" class="headerlink" title="2.计量时间"></a>2.计量时间</h2><p>==加入计时器显示时间==</p>
<ul>
<li>让中断执行下面的程序</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct TIMERCTL &#123; </span><br><span class="line">    unsigned int count; </span><br><span class="line">&#125;; </span><br></pre></td></tr></table></figure>
<ul>
<li>实现方法<ul>
<li>定义struct TIMERCTL结构体，在结构体内定义一个计数变量。</li>
<li>初始化PIT时，计数变量为0，每次发生定时器中断时，计数变量就以1递增。</li>
<li>即计数变量在HariMain中不进行加算，每1s也会增加100.</li>
</ul>
</li>
</ul>
<h2 id="3-超时功能"><a href="#3-超时功能" class="headerlink" title="3.超时功能"></a>3.超时功能</h2><p>==超时功能的定义，添加超时功能==</p>
<ul>
<li>我们可以计量处理所花费的时间。具体做法：处理前看一下时间并把它存放到一个变量变量里，处理结束后再看一下时间，做差即可。根据这个可以编制==基准测试程序==</li>
<li>超时（timeout）：过了一段时间，定时器提示操作系统。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct TIMERCTL &#123; </span><br><span class="line">     unsigned int count; </span><br><span class="line">     unsigned int timeout; </span><br><span class="line">     struct FIFO8 *fifo; </span><br><span class="line">     unsigned char data; </span><br><span class="line">&#125;; </span><br></pre></td></tr></table></figure>
<p>timeout用于记录离超时还有多长时间，当剩余时间到达0时，程序就往IFIFO缓冲区里发送数据。</p>
<h2 id="4-设定多个定时器"><a href="#4-设定多个定时器" class="headerlink" title="4.设定多个定时器"></a>4.设定多个定时器</h2><ul>
<li>在上一节做的超时功能，超时结束后如果再设定1000的话，那我们就可以让它每10秒显示一<br>次，或是让它一闪一灭地显示。</li>
<li>开发操作系统时，超时功能非常方便，所以在很多地方都可以使用它。比如可以让电子时钟<br>每隔1秒重新显示一次；演奏音乐时，可以用它计量音符的长短；也可以让它以0.1秒1次的频率来监视没有中断功能的装置；另外，还可以用它实现光标的闪烁功能。<br>为了简单地实现这些功能，我们要准备很多能够设定超时的定时器。</li>
</ul>
<h2 id="5-加快中断处理（1）"><a href="#5-加快中断处理（1）" class="headerlink" title="5.加快中断处理（1）"></a>5.加快中断处理（1）</h2><ul>
<li>问题：inthandler20中断花费了很长的时间</li>
<li>优化部分：现每次进行定时器中断处理的时候，都会对所有活动中的定时器进行“timerctl.timer[i].timeout—;”处理。也就是说，CPU要完成从内存中读取变量值，减去1，然后又往内存中写入的操作。</li>
<li>time[i].timeout不再是“所剩时间”而是“予定时刻”，将timerctl.count和timer[i].timeout进行比较，不用再经过内存计算。</li>
<li>问题：count设定成最大值，一段时间后需要重新启动操作系统。</li>
</ul>
<h2 id="6-加快中断处理（2）"><a href="#6-加快中断处理（2）" class="headerlink" title="6.加快中断处理（2）"></a>6.加快中断处理（2）</h2><p>==优化if语句==<br>解决方案：添加timerctl.next，让它记住下一个时刻</p>
<h2 id="7-加快中断处理（3）"><a href="#7-加快中断处理（3）" class="headerlink" title="7.加快中断处理（3）"></a>7.加快中断处理（3）</h2><ul>
<li>问题：到达next时刻和没到next时刻的定时器中断，它们的处理时间差别很大。<br>这样的程序结构不好。因为平常运行一直都很快的程序，会偶尔由于中断处理拖得太长，而搞得像是主程序要停了似的。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（11）</title>
    <url>/201903/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8811%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY11-制作窗口"><a href="#DAY11-制作窗口" class="headerlink" title="DAY11_制作窗口"></a>DAY11_制作窗口</h1><h2 id="1-鼠标显示问题"><a href="#1-鼠标显示问题" class="headerlink" title="1.鼠标显示问题"></a>1.鼠标显示问题</h2><ul>
<li>我们系统的鼠标不能够向右或向下移动到画面之外隐藏起来。为此我们修改HariMain</li>
</ul>
<span id="more"></span>
<p>将<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (mx &gt; binfo-&gt;scrnx - 16) &#123; </span><br><span class="line">    mx = binfo-&gt;scrnx - 16; </span><br><span class="line"> &#125; </span><br><span class="line"> if (my &gt; binfo-&gt;scrny - 16) &#123; </span><br><span class="line">    my = binfo-&gt;scrny - 16; </span><br><span class="line"> &#125; </span><br></pre></td></tr></table></figure><br>修改为<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (mx &gt; binfo-&gt;scrnx - 1) &#123; </span><br><span class="line">    mx = binfo-&gt;scrnx - 1; </span><br><span class="line"> &#125; </span><br><span class="line"> if (my &gt; binfo-&gt;scrny - 1) &#123; </span><br><span class="line">    my = binfo-&gt;scrny - 1; </span><br><span class="line"> &#125; </span><br></pre></td></tr></table></figure></p>
<h2 id="2-实现画面外的支持"><a href="#2-实现画面外的支持" class="headerlink" title="2.实现画面外的支持"></a>2.实现画面外的支持</h2><h2 id="3-shtctl的指定省略"><a href="#3-shtctl的指定省略" class="headerlink" title="3.shtctl的指定省略"></a>3.shtctl的指定省略</h2><p>仅仅是上下移动图层就必须指定ctl太麻烦了。修改将sheet_refresh、sheet_slide、sheet_free等函数，让它们不再指定ctl</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">sheet_refresh</span><span class="params">(<span class="keyword">struct</span> SHEET *sht, <span class="type">int</span> bx0, <span class="type">int</span> by0, <span class="type">int</span> bx1, <span class="type">int</span> by1)</span> </span><br><span class="line">&#123; </span><br><span class="line"> <span class="keyword">if</span> (sht-&gt;height &gt;= <span class="number">0</span>) &#123; <span class="comment">/* 如果正在显示，则按新图层的信息进行刷新*/</span> </span><br><span class="line"> sheet_refreshsub(sht-&gt;ctl, sht-&gt;vx0 + bx0, sht-&gt;vy0 + by0, sht-&gt;vx0 + bx1, sht-&gt;vy0 + by1); </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">return</span>; </span><br><span class="line">&#125; </span><br><span class="line"><span class="type">void</span> <span class="title function_">sheet_slide</span><span class="params">(<span class="keyword">struct</span> SHEET *sht, <span class="type">int</span> vx0, <span class="type">int</span> vy0)</span> </span><br><span class="line">&#123; </span><br><span class="line"> <span class="type">int</span> old_vx0 = sht-&gt;vx0, old_vy0 = sht-&gt;vy0; </span><br><span class="line"> sht-&gt;vx0 = vx0; </span><br><span class="line"> sht-&gt;vy0 = vy0; </span><br><span class="line"> <span class="keyword">if</span> (sht-&gt;height &gt;= <span class="number">0</span>) &#123; <span class="comment">/* 如果正在显示，则按新图层的信息进行刷新 */</span> </span><br><span class="line"> sheet_refreshsub(sht-&gt;ctl, old_vx0, old_vy0, old_vx0 + sht-&gt;bxsize, old_vy0 + </span><br><span class="line">sht-&gt;bysize); </span><br><span class="line"> sheet_refreshsub(sht-&gt;ctl, vx0, vy0, vx0 + sht-&gt;bxsize, vy0 + sht-&gt;bysize); </span><br><span class="line"> &#125; </span><br><span class="line"> <span class="keyword">return</span>; </span><br><span class="line">&#125; </span><br><span class="line"><span class="type">void</span> <span class="title function_">sheet_free</span><span class="params">(<span class="keyword">struct</span> SHEET *sht)</span> </span><br><span class="line">&#123; </span><br><span class="line"> <span class="keyword">if</span> (sht-&gt;height &gt;= <span class="number">0</span>) &#123; </span><br><span class="line"> sheet_updown(sht, <span class="number">-1</span>); <span class="comment">/* 如果正在显示，则先设置为隐藏 */</span> </span><br><span class="line"> &#125; </span><br><span class="line"> sht-&gt;flags = <span class="number">0</span>; <span class="comment">/* 未使用标记 */</span> </span><br><span class="line"> <span class="keyword">return</span>; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2 id="4-显示窗口"><a href="#4-显示窗口" class="headerlink" title="4.显示窗口"></a>4.显示窗口</h2><ul>
<li>先准备一张图层，然后在图层缓冲区内描绘一个貌似窗口的图就可以了。</li>
</ul>
<p>只是对graph.c的init_screen8函数稍微进行修改。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void make_window8(unsigned char *buf, int xsize, int ysize, char *title) </span><br><span class="line">&#123; </span><br><span class="line">     static char closebtn[14][16] = &#123; </span><br><span class="line">     &quot;OOOOOOOOOOOOOOO@&quot;, </span><br><span class="line">     &quot;OQQQQQQQQQQQQQ$@&quot;, </span><br><span class="line">     &quot;OQQQQQQQQQQQQQ$@&quot;, </span><br><span class="line">     &quot;OQQQ@@QQQQ@@QQ$@&quot;, </span><br><span class="line">     &quot;OQQQQ@@QQ@@QQQ$@&quot;, </span><br><span class="line">     &quot;OQQQQQ@@@@QQQQ$@&quot;, </span><br><span class="line">     &quot;OQQQQQQ@@QQQQQ$@&quot;, </span><br><span class="line">     &quot;OQQQQQ@@@@QQQQ$@&quot;, </span><br><span class="line">     &quot;OQQQQ@@QQ@@QQQ$@&quot;, </span><br><span class="line">     &quot;OQQQ@@QQQQ@@QQ$@&quot;, </span><br><span class="line">     &quot;OQQQQQQQQQQQQQ$@&quot;, </span><br><span class="line">     &quot;OQQQQQQQQQQQQQ$@&quot;, </span><br><span class="line">     &quot;O$$$$$$$$$$$$$$@&quot;, </span><br><span class="line">     &quot;@@@@@@@@@@@@@@@@&quot; </span><br><span class="line">     &#125;; </span><br><span class="line">     int x, y; </span><br><span class="line">     char c; </span><br><span class="line">     boxfill8(buf, xsize, COL8_C6C6C6, 0, 0, xsize - 1, 0 ); </span><br><span class="line">     boxfill8(buf, xsize, COL8_FFFFFF, 1, 1, xsize - 2, 1 ); </span><br><span class="line">     boxfill8(buf, xsize, COL8_C6C6C6, 0, 0, 0, ysize - 1); </span><br><span class="line">     boxfill8(buf, xsize, COL8_FFFFFF, 1, 1, 1, ysize - 2); </span><br><span class="line">     boxfill8(buf, xsize, COL8_848484, xsize - 2, 1, xsize - 2, ysize - 2); </span><br><span class="line">     boxfill8(buf, xsize, COL8_000000, xsize - 1, 0, xsize - 1, ysize - 1); </span><br><span class="line">     boxfill8(buf, xsize, COL8_C6C6C6, 2, 2, xsize - 3, ysize - 3); </span><br><span class="line">     boxfill8(buf, xsize, COL8_000084, 3, 3, xsize - 4, 20 ); </span><br><span class="line">     boxfill8(buf, xsize, COL8_848484, 1, ysize - 2, xsize - 2, ysize - 2); </span><br><span class="line">     boxfill8(buf, xsize, COL8_000000, 0, ysize - 1, xsize - 1, ysize - 1); </span><br><span class="line">     putfonts8_asc(buf, xsize, 24, 4, COL8_FFFFFF, title); </span><br><span class="line">     for (y = 0; y &lt; 14; y++) &#123; </span><br><span class="line">        for (x = 0; x &lt; 16; x++) &#123; </span><br><span class="line">            c = closebtn[y][x]; </span><br><span class="line">            if (c == &#x27;@&#x27;) &#123; </span><br><span class="line">                c = COL8_000000; </span><br><span class="line">            &#125; else if (c == &#x27;$&#x27;) &#123; </span><br><span class="line">            c = COL8_848484; </span><br><span class="line">            &#125; else if (c == &#x27;Q&#x27;) &#123; </span><br><span class="line">            c = COL8_C6C6C6; </span><br><span class="line">            &#125; else &#123; </span><br><span class="line">            c = COL8_FFFFFF; </span><br><span class="line">            &#125; </span><br><span class="line">            buf[(5 + y) * xsize + (xsize - 21 + x)] = c; </span><br><span class="line">        &#125;   </span><br><span class="line">     &#125; </span><br><span class="line">     return; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></p>
<h2 id="5-小实验"><a href="#5-小实验" class="headerlink" title="5.小实验"></a>5.小实验</h2><p>HariMain中有设置图层高度的地方，如果像下面这样，把窗口图层放在最上面，光标图层放在其次，会变成什么样呢？<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sheet_updown(sht_back, 0); </span><br><span class="line">sheet_updown(sht_mouse, 1); </span><br><span class="line">sheet_updown(sht_win, 2); </span><br></pre></td></tr></table></figure><br>鼠标会跑到窗口图层的下面。</p>
<h2 id="6-高速计数器"><a href="#6-高速计数器" class="headerlink" title="6.高速计数器"></a>6.高速计数器</h2><ul>
<li>我们要做一个能够计数，并且能够把计数结果显示出来的窗口。</li>
<li>但是在刷新的时候，总是先刷新refresh范围内的背景图层，然后再刷新窗口图层，导致数字闪烁。</li>
</ul>
<h2 id="7-消除闪烁（1）"><a href="#7-消除闪烁（1）" class="headerlink" title="7.消除闪烁（1）"></a>7.消除闪烁（1）</h2><ul>
<li>窗口图层刷新是因为窗口的内容有变化，所以要在画面上显示变化后的新内容。基本上来讲，可以认为其他图层的内容没有变化（如果其他图层的内容也变了，那么应该会随后执行该图层的刷新）。<br>既然如此，图层内容没有变化也进行刷新的话就太浪费了。如果只是窗口变了，那背景就不<br>用刷新了。假如上面有鼠标，但鼠标的图层没有变化，我们也必须要刷新。窗口的刷新，可能会覆盖鼠标的一部分显示区域。</li>
<li>在sheet_slide函数里，图层的移动有时会导致下面的图层露出，所以要从最下面开始刷新。<br>另一方面，在移动目标处，比新移来的图层位置还要低的图层没有什么变化，而且只是隐藏起来了，所以只要刷新移动的图层和它上面的图层就可以了。</li>
<li>但是修改代码后，鼠标放在数字区的时候，鼠标又开始闪烁。</li>
</ul>
<h2 id="8-消除闪烁（2）"><a href="#8-消除闪烁（2）" class="headerlink" title="8.消除闪烁（2）"></a>8.消除闪烁（2）</h2><ul>
<li>闪烁现象是由于一会儿描绘一会儿消除造成的。所以说要想消除闪烁，就要在刷新窗口时避开鼠标所在的地方对VRAM进行写入处理。</li>
<li><p>方法：先开辟一块儿内存，大小和VRAM一样，这块内存用来表示画面上的点是哪个图层的像素，相当于图层的地图。<br><img src="https://s2.ax1x.com/2019/03/24/AYhJwF.png" alt="d11.1"></p>
</li>
<li><p>今后程序会对照map内容来向VRAM中写入，所以有时没必要从下面开始一直刷新到最上面<br>一层。</p>
</li>
<li>在sheet_slide函数里，首先重写map，分别对应移动前后的图层，然后调用sheet_refreshsub函数。在移动前的地方，只针对上层图层移走之后而露出的下层图层进行重绘就可以了。在移动目的地处仅重绘了一张移动过去的图层。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（10）</title>
    <url>/201903/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%8810%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY10-叠加处理"><a href="#DAY10-叠加处理" class="headerlink" title="DAY10_叠加处理"></a>DAY10_叠加处理</h1><h2 id="1-内存管理（续）"><a href="#1-内存管理（续）" class="headerlink" title="1.内存管理（续）"></a>1.内存管理（续）</h2><span id="more"></span>
<ul>
<li>memory.c中增加了“向上舍入”的部分，即我们要编写一些总是以0x1000字节为单位进行内存分配和释放的函数，它们会把指定的内存大小按0x1000字节为单位向上舍入（ roundup）。</li>
<li>从向下舍入开始<br>要想把十六进制的某一位设置为0，同样只进行“与运算”就可以。</li>
<li>向上舍入：先向下舍入，再在它的结果上做个加法运算就可以了。（要先判断后几位是不是0）</li>
<li>更好的向上舍入的方法：i = (i + 0xfff) &amp; 0xfffff000; </li>
</ul>
<h2 id="2-叠加处理"><a href="#2-叠加处理" class="headerlink" title="2.叠加处理"></a>2.叠加处理</h2><ul>
<li>寻找一种方法，不仅适用于鼠标的叠加，还适用于窗口的叠加。</li>
<li>在程序中创建管理多重图层信息的结构SHTCTL</li>
<li>sheet_refresh函数：这个函数会从下到上描绘所有的图层。refresh是“刷新”的意思。电视屏幕就是在1秒内完成多帧的描绘才做出动画效果的，这个动作就被称为刷新。而这种对图层的刷新动作，与电视屏幕的动作有些相似，所以我们也给它起名字叫做刷新。</li>
<li>sheet_slide：不改变图层的高度而只上下左右移动图层的函数。</li>
<li>sheet_free释放已使用图层的内存的函数。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct SHTCTL *shtctl_init(struct MEMMAN *memman, unsigned char *vram, int xsize, int ysize) </span><br><span class="line">&#123; </span><br><span class="line">     struct SHTCTL *ctl; </span><br><span class="line">     int i; </span><br><span class="line">     ctl = (struct SHTCTL *) memman_alloc_4k(memman, sizeof (struct SHTCTL)); </span><br><span class="line">     if (ctl == 0) &#123; </span><br><span class="line">     goto err; </span><br><span class="line">     &#125; </span><br><span class="line">         ctl-&gt;vram = vram; </span><br><span class="line">         ctl-&gt;xsize = xsize; </span><br><span class="line">         ctl-&gt;ysize = ysize; </span><br><span class="line">         ctl-&gt;top = -1; /*一个SHEET没都有 */ </span><br><span class="line">         for (i = 0; i &lt; MAX_SHEETS; i++) &#123; </span><br><span class="line">         ctl-&gt;sheets0[i].flags = 0; /* 标记为未使用 */ </span><br><span class="line">        &#125; </span><br><span class="line">    err: </span><br><span class="line">     return ctl; </span><br><span class="line">&#125; </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>首先使用memman_alloc_4k来分配用于记忆图层控制变量的内存空间，这时必须指定该变量所占空间的大小，不过我们可以使用sizeof（struct SHTCTL）这种写法，让C编译器自动计算。只要写sizeof（变量型），C编译器就会计算出该变量型所需的字节数。<br>接着，我们给控制变量赋值，给其下的所有图层变量都加上“未使用”标签。</p>
<h2 id="3-提高叠加处理速度（1）"><a href="#3-提高叠加处理速度（1）" class="headerlink" title="3.提高叠加处理速度（1）"></a>3.提高叠加处理速度（1）</h2><ul>
<li>只需要重新描绘鼠标移动相关的部分，也就是移动前后的部分就可以了，即256×2=512个像素。这只是64 000像素的0.8%而已，所以有望提速很多。现在我们根据这个思路写一下程序。</li>
<li>要在画面上显示坐标等信息，结果又执行了sheet_refresh程序。所以我们要解决图层内文字显示的问题。</li>
</ul>
<h2 id="4-提高叠加处理速度（2）"><a href="#4-提高叠加处理速度（2）" class="headerlink" title="4.提高叠加处理速度（2）"></a>4.提高叠加处理速度（2）</h2><ul>
<li>使不写入像素内容，也要多次执行if语句。我们最初就应该把for语句的范围限定在刷新范围之内。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void sheet_refreshsub(struct SHTCTL *ctl, int vx0, int vy0, int vx1, int vy1) </span><br><span class="line">&#123; </span><br><span class="line">     int h, bx, by, vx, vy, bx0, by0, bx1, by1; </span><br><span class="line">     unsigned char *buf, c, *vram = ctl-&gt;vram; </span><br><span class="line">     struct SHEET *sht; </span><br><span class="line">     for (h = 0; h &lt;= ctl-&gt;top; h++) &#123; </span><br><span class="line">     sht = ctl-&gt;sheets[h]; </span><br><span class="line">     buf = sht-&gt;buf; </span><br><span class="line">     /* 使用vx0～vy1，对bx0～by1进行倒推 */ </span><br><span class="line">     bx0 = vx0 - sht-&gt;vx0; </span><br><span class="line">     by0 = vy0 - sht-&gt;vy0; </span><br><span class="line">     bx1 = vx1 - sht-&gt;vx0; </span><br><span class="line">     by1 = vy1 - sht-&gt;vy0; </span><br><span class="line">     if (bx0 &lt; 0) &#123; bx0 = 0; &#125; /* 说明(1) */ </span><br><span class="line">     if (by0 &lt; 0) &#123; by0 = 0; &#125; </span><br><span class="line">     if (bx1 &gt; sht-&gt;bxsize) &#123; bx1 = sht-&gt;bxsize; &#125; /* 说明(2) */ </span><br><span class="line">     if (by1 &gt; sht-&gt;bysize) &#123; by1 = sht-&gt;bysize; &#125; </span><br><span class="line">     for (by = by0; by &lt; by1; by++) &#123; </span><br><span class="line">        vy = sht-&gt;vy0 + by; </span><br><span class="line">        for (bx = bx0; bx &lt; bx1; bx++) &#123; </span><br><span class="line">            vx = sht-&gt;vx0 + bx; </span><br><span class="line">            c = buf[by * sht-&gt;bxsize + bx]; </span><br><span class="line">            if (c != sht-&gt;col_inv) &#123; </span><br><span class="line">            vram[vy * ctl-&gt;xsize + vx] = c; </span><br><span class="line">            &#125; </span><br><span class="line">        &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     return; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title>30天自制操作系统（9）</title>
    <url>/201903/30%E5%A4%A9%E8%87%AA%E5%88%B6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%889%EF%BC%89/</url>
    <content><![CDATA[<h1 id="DAY9-内存管理"><a href="#DAY9-内存管理" class="headerlink" title="DAY9_内存管理"></a>DAY9_内存管理</h1><h2 id="1-整理源文件"><a href="#1-整理源文件" class="headerlink" title="1.整理源文件"></a>1.整理源文件</h2><p><img src="https://s2.ax1x.com/2019/03/24/AYgbB4.md.png" alt="d9.1"></p>
<span id="more"></span>
<h2 id="2-内存容量检查"><a href="#2-内存容量检查" class="headerlink" title="2.内存容量检查"></a>2.内存容量检查</h2><ul>
<li>在最初启动时，BIOS肯定要检查内存容量，所以只要我们问一问BIOS，就能知道内存容量有多大。但是会很麻烦，我们选择自己动手检查内存。</li>
<li>做法：<ul>
<li>首先，暂时让486以后的CPU的高速缓存（cache）功能无效。<br>原理：内存检查时，要往内存里随便写入一个值，然后马上读取，来检查读取的值与写入的值是否相等。如果内存连接正常，则写入的值能够记在内存里。如果没连接上，则读出的值肯定是乱七八糟的。如果CPU里加上了缓存，写入和读出的不是内存，而是缓存。结果，所有的内存都“正常”，检查处理不能完成。<ul>
<li>通过HariMain识别3GB范围的内存</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3-内存容量检查（2）"><a href="#3-内存容量检查（2）" class="headerlink" title="3.内存容量检查（2）"></a>3.内存容量检查（2）</h2><ul>
<li>编译器对程序进行了优化，无法识别内存，于是我们选择用汇编来写。</li>
</ul>
<h2 id="4-挑战内存管理"><a href="#4-挑战内存管理" class="headerlink" title="4.挑战内存管理"></a>4.挑战内存管理</h2><h3 id="内存管理是什么，为什么要进行内存管理？"><a href="#内存管理是什么，为什么要进行内存管理？" class="headerlink" title="内存管理是什么，为什么要进行内存管理？"></a>内存管理是什么，为什么要进行内存管理？</h3><p>操作系统在工作中，有时需要分配一定大小的内存，用完以后又不再需要，这种事会频繁发生。为了应付这些需求，必须恰当管理好哪些内存可以使用（哪些内存空闲），哪些内存不可以使用（正在使用），这就是内存管理。如果不进行管理，系统会变得一塌糊涂，要么知道哪里可用，要么多个应用程序使用同一地址的内存。</p>
<h3 id="内存管理的方法"><a href="#内存管理的方法" class="headerlink" title="内存管理的方法"></a>内存管理的方法</h3><ul>
<li>创建相应数量的区域，用1和0表示该区域是否被使用。但是这种方法的缺点就是，在内存区域很多的情况下，管理表很大。</li>
<li>列表管理的方法：从xxx号开始，yyy字节的空间是空着的。优点：占用内存小。大块内存的分配和释放都非常迅速。<br>缺点：程序管理变复杂了；当可用空间零散的时候，空间管理信息可能会被用完。  </li>
<li>我们的操作系统使用的方法是，当MEMMAN用完的时候，将小的内存区域舍弃，先不去管它。</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>内存管理</tag>
      </tags>
  </entry>
</search>
